[{
  "history_id" : "9h0sv5xtn34",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1721364488180,
  "history_end_time" : 1721364488180,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "d2ip4va7trz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1721133289777,
  "history_end_time" : 1721156176103,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "4pvk8x6bei2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1720812753725,
  "history_end_time" : 1720812753725,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "eij0031zah9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1718636826231,
  "history_end_time" : 1718636826231,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "aujnfyme7p7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1718636745278,
  "history_end_time" : 1718636745278,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "11pnlk9n5vp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1718636565091,
  "history_end_time" : 1718636565091,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "k21ppr7zb9o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1718211173532,
  "history_end_time" : 1718211173532,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "19au08j55bq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717260625840,
  "history_end_time" : 1717260625840,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qhz5zni6h9i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717258417392,
  "history_end_time" : 1717260624664,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "hlrz8tl3e57",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717233644384,
  "history_end_time" : 1717258424633,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "y1oxtqfkm43",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717233051777,
  "history_end_time" : 1717233634235,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "h3pfyejd8fq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717183214967,
  "history_end_time" : 1717233633762,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "5by00k7321x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717182654880,
  "history_end_time" : 1717182654880,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vcw5644dh13",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716612552453,
  "history_end_time" : 1717233631798,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "bkk2wjssn4r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716611582531,
  "history_end_time" : 1716612551157,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ucbe1kdnq2a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716610207104,
  "history_end_time" : 1716611579211,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ttobgfdv10a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716606646657,
  "history_end_time" : 1716610196715,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "v8z69wb2rgq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716120710358,
  "history_end_time" : 1716610159515,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "vynxo933dus",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716068762993,
  "history_end_time" : 1716076012593,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "456dchr0fe4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716068608559,
  "history_end_time" : 1716068760867,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "g2tz4r8qau8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714808468670,
  "history_end_time" : 1714838057261,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "2kdqf2ja282",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714161440459,
  "history_end_time" : 1714161440459,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0vl2qcihyoc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713966604346,
  "history_end_time" : 1713966604346,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nqap71nnstj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713935811082,
  "history_end_time" : 1713935811082,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wp4a6r2lzse",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712452760504,
  "history_end_time" : 1712452760504,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3ch0zcgj2ms",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712452402388,
  "history_end_time" : 1712452749961,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "3udk469jl7m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712445947143,
  "history_end_time" : 1712445947143,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1fjtopg22k9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711723378019,
  "history_end_time" : 1711723378019,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "et6gvxb32ee",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711722163449,
  "history_end_time" : 1711723321975,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "0oqtr3exz87",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711203851070,
  "history_end_time" : 1712452724075,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "xhe4tfkllzq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711136729442,
  "history_end_time" : 1711136729442,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xem5x0gcevf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711136573117,
  "history_end_time" : 1711136662815,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "xojv0pu6kmv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709930548093,
  "history_end_time" : 1712452725018,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "h1ffwyq1hon",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709930050146,
  "history_end_time" : 1709930509960,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "cn03t3e4cw3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709444795633,
  "history_end_time" : 1712452725797,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "wxkg5f1hg4g",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709444438275,
  "history_end_time" : 1709444687347,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "60l2JbsF1gM0",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=20G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-10:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nfrom datetime import datetime, timedelta\nimport pandas as pd\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  \n\n  # Start date\n  start_date = datetime(2020, 7, 15)\n\n  # End date\n  end_date = datetime(2020, 7, 18)\n\n  # Define the step size for traversal\n  step = timedelta(days=1)\n  \n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\"\n\n  # Traverse the dates\n  current_date = start_date\n  while current_date <= end_date:\n      print(\"Preparing for date : \", current_date.strftime('%Y%m%d'))  # Print date in YYYYMMDD format\n      \n      training_end_date = current_date.strftime('%Y%m%d')\n      #training_end_date = \"20201030\" # the last day of the 7 day history\n      prepare_training_data(training_end_date, training_data_folder)\n      current_date += step\n      \n      file_path = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/20200715_time_series_with_window.csv\"\n\n      #file_path = \"/groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\"\n\n      df = pd.read_csv(file_path)\n\n      print(df.head())\n\n      # Assuming you want to calculate statistics of a column named 'column_name'\n      column_name = ' FRP'\n\n      # Basic statistics\n      stats = df[column_name].describe()\n      \n      if df[column_name].max() == 0:\n        print(\"The maximum value of the column is zero.\")\n        raise Exception(\"The maximum value of the column is zero.\")\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/60l2JbsF1gM0\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1616846\n/home/zsun/gw-workspace/60l2JbsF1gM0/gw-vC8lRLpPuKneA12SoC0LjaV5U7-60l2JbsF1gM0.sh: line 99: : No such file or directory\n/home/zsun/gw-workspace/60l2JbsF1gM0/gw-vC8lRLpPuKneA12SoC0LjaV5U7-60l2JbsF1gM0.sh: line 103: : No such file or directory\n/home/zsun/gw-workspace/60l2JbsF1gM0/gw-vC8lRLpPuKneA12SoC0LjaV5U7-60l2JbsF1gM0.sh: line 103: : No such file or directory\n/home/zsun/gw-workspace/60l2JbsF1gM0/gw-vC8lRLpPuKneA12SoC0LjaV5U7-60l2JbsF1gM0.sh: line 103: : No such file or directory\n/home/zsun/gw-workspace/60l2JbsF1gM0/gw-vC8lRLpPuKneA12SoC0LjaV5U7-60l2JbsF1gM0.sh: line 103: : No such file or directory\n0a1,32\n> Preparing for date :  20200715\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\n> File does not exist\n> preparing training data for  20200715\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200714\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n> preparing data for past date 20200713\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n> preparing data for past date 20200712\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n> preparing data for past date 20200711\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n> preparing data for past date 20200710\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n> preparing data for past date 20200709\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n> preparing data for past date 20200708\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n1a34,43\n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n43a44,114\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n>     LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -107.900002   0.0  ...    0.000000         0.0         0.0\n> 1  24.5 -107.799995   0.0  ...    0.000000         0.0         0.0\n> 2  24.5 -107.699997   0.0  ...    1.476188         0.0         0.0\n> 3  24.5 -107.599998   0.0  ...    0.000000         0.0         0.0\n> 4  24.5 -107.500000   0.0  ...    0.000000         0.0         0.0\n> \n> [5 rows x 46 columns]\n> Preparing for date :  20200716\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\n> File does not exist\n> preparing training data for  20200716\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200715\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n> preparing data for past date 20200714\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n> preparing data for past date 20200713\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n> preparing data for past date 20200712\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n> preparing data for past date 20200711\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n> preparing data for past date 20200710\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n> preparing data for past date 20200709\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n114a115,185\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n>     LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -107.900002   0.0  ...    0.000000         0.0         0.0\n> 1  24.5 -107.799995   0.0  ...    0.000000         0.0         0.0\n> 2  24.5 -107.699997   0.0  ...    1.476188         0.0         0.0\n> 3  24.5 -107.599998   0.0  ...    0.000000         0.0         0.0\n> 4  24.5 -107.500000   0.0  ...    0.000000         0.0         0.0\n> \n> [5 rows x 46 columns]\n> Preparing for date :  20200717\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\n> File does not exist\n> preparing training data for  20200717\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200716\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n> preparing data for past date 20200715\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n> preparing data for past date 20200714\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n> preparing data for past date 20200713\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n> preparing data for past date 20200712\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n> preparing data for past date 20200711\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n> preparing data for past date 20200710\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n185a186,256\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n>     LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -107.900002   0.0  ...    0.000000         0.0         0.0\n> 1  24.5 -107.799995   0.0  ...    0.000000         0.0         0.0\n> 2  24.5 -107.699997   0.0  ...    1.476188         0.0         0.0\n> 3  24.5 -107.599998   0.0  ...    0.000000         0.0         0.0\n> 4  24.5 -107.500000   0.0  ...    0.000000         0.0         0.0\n> \n> [5 rows x 46 columns]\n> Preparing for date :  20200718\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\n> File does not exist\n> preparing training data for  20200718\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200717\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n> preparing data for past date 20200716\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n> preparing data for past date 20200715\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n> preparing data for past date 20200714\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n> preparing data for past date 20200713\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n> preparing data for past date 20200712\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n> preparing data for past date 20200711\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n256a257,284\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n>     LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -107.900002   0.0  ...    0.000000         0.0         0.0\n> 1  24.5 -107.799995   0.0  ...    0.000000         0.0         0.0\n> 2  24.5 -107.699997   0.0  ...    1.476188         0.0         0.0\n> 3  24.5 -107.599998   0.0  ...    0.000000         0.0         0.0\n> 4  24.5 -107.500000   0.0  ...    0.000000         0.0         0.0\n> \n> [5 rows x 46 columns]\nJob 1616846 has finished with state: JobState=COMPLETED\nSlurm job (1616846) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1616846      fc_model_+  COMPLETED      0:0            2024-03-03T00:28:17 2024-03-03T00:42:01 \n1616846.bat+      batch  COMPLETED      0:0    519516K 2024-03-03T00:28:17 2024-03-03T00:42:01 \n1616846.ext+     extern  COMPLETED      0:0          0 2024-03-03T00:28:17 2024-03-03T00:42:01 \nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1709443695961,
  "history_end_time" : 1709444529184,
  "history_notes" : "now it should be right. Keep the row with non-zero and remote the rows that are all zeros",
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "xwyFsCQzoTD7",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=20G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-10:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nfrom datetime import datetime, timedelta\nimport pandas as pd\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  \n\n  # Start date\n  start_date = datetime(2020, 7, 15)\n\n  # End date\n  end_date = datetime(2020, 7, 18)\n\n  # Define the step size for traversal\n  step = timedelta(days=1)\n  \n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\"\n\n  # Traverse the dates\n  current_date = start_date\n  while current_date <= end_date:\n      print(\"Preparing for date : \", current_date.strftime('%Y%m%d'))  # Print date in YYYYMMDD format\n      \n      training_end_date = current_date.strftime('%Y%m%d')\n      #training_end_date = \"20201030\" # the last day of the 7 day history\n      prepare_training_data(training_end_date, training_data_folder)\n      current_date += step\n      \n      file_path = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/20200715_time_series_with_window.csv\"\n\n      #file_path = \"/groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\"\n\n      df = pd.read_csv(file_path)\n\n      print(df.head())\n\n      # Assuming you want to calculate statistics of a column named 'column_name'\n      column_name = ' FRP'\n\n      # Basic statistics\n      stats = df[column_name].describe()\n      \n      if df[column_name].max() == 0:\n        print(\"The maximum value of the column is zero.\")\n        raise Exception(\"The maximum value of the column is zero.\")\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/xwyFsCQzoTD7\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1616844\n/home/zsun/gw-workspace/xwyFsCQzoTD7/gw-vC8lRLpPuKneA12SoC0LjaV5U7-xwyFsCQzoTD7.sh: line 99: : No such file or directory\n/home/zsun/gw-workspace/xwyFsCQzoTD7/gw-vC8lRLpPuKneA12SoC0LjaV5U7-xwyFsCQzoTD7.sh: line 103: : No such file or directory\n/home/zsun/gw-workspace/xwyFsCQzoTD7/gw-vC8lRLpPuKneA12SoC0LjaV5U7-xwyFsCQzoTD7.sh: line 103: : No such file or directory\n/home/zsun/gw-workspace/xwyFsCQzoTD7/gw-vC8lRLpPuKneA12SoC0LjaV5U7-xwyFsCQzoTD7.sh: line 103: : No such file or directory\n/home/zsun/gw-workspace/xwyFsCQzoTD7/gw-vC8lRLpPuKneA12SoC0LjaV5U7-xwyFsCQzoTD7.sh: line 103: : No such file or directory\n0a1,10\n> Preparing for date :  20200715\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2//20200715_time_series_with_window.csv exists\n>     LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n1a12,16\n> [5 rows x 46 columns]\n> The maximum value of the column is zero.\n> Traceback (most recent call last):\n>   File \"<stdin>\", line 48, in <module>\n> Exception: The maximum value of the column is zero.\nJob 1616844 has finished with state: JobState=FAILED\nSlurm job (1616844) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1616844      fc_model_+     FAILED      1:0            2024-03-03T00:26:45 2024-03-03T00:27:19 \n1616844.bat+      batch     FAILED      1:0       484K 2024-03-03T00:26:45 2024-03-03T00:27:19 \n1616844.ext+     extern  COMPLETED      0:0          0 2024-03-03T00:26:45 2024-03-03T00:27:19 \nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1709443603146,
  "history_end_time" : 1709443644407,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "8iAi2Q1iihze",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=20G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-10:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nfrom datetime import datetime, timedelta\nimport pandas as pd\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  \n\n  # Start date\n  start_date = datetime(2020, 7, 15)\n\n  # End date\n  end_date = datetime(2020, 7, 18)\n\n  # Define the step size for traversal\n  step = timedelta(days=1)\n  \n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\"\n\n  # Traverse the dates\n  current_date = start_date\n  while current_date <= end_date:\n      print(\"Preparing for date : \", current_date.strftime('%Y%m%d'))  # Print date in YYYYMMDD format\n      \n      training_end_date = current_date.strftime('%Y%m%d')\n      #training_end_date = \"20201030\" # the last day of the 7 day history\n      prepare_training_data(training_end_date, training_data_folder)\n      current_date += step\n      \n      file_path = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/20200715_time_series_with_window.csv\"\n\n      #file_path = \"/groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\"\n\n      df = pd.read_csv(file_path)\n\n      print(df.head())\n\n      # Assuming you want to calculate statistics of a column named 'column_name'\n      column_name = ' FRP'\n\n      # Basic statistics\n      stats = df[column_name].describe()\n      \n      if df[column_name].max() == 0:\n        print(\"The maximum value of the column is zero.\")\n        raise Exception(\"The maximum value of the column is zero.\")\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/8iAi2Q1iihze\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1616840\n/home/zsun/gw-workspace/8iAi2Q1iihze/gw-vC8lRLpPuKneA12SoC0LjaV5U7-8iAi2Q1iihze.sh: line 99: : No such file or directory\n/home/zsun/gw-workspace/8iAi2Q1iihze/gw-vC8lRLpPuKneA12SoC0LjaV5U7-8iAi2Q1iihze.sh: line 103: : No such file or directory\n/home/zsun/gw-workspace/8iAi2Q1iihze/gw-vC8lRLpPuKneA12SoC0LjaV5U7-8iAi2Q1iihze.sh: line 103: : No such file or directory\n/home/zsun/gw-workspace/8iAi2Q1iihze/gw-vC8lRLpPuKneA12SoC0LjaV5U7-8iAi2Q1iihze.sh: line 103: : No such file or directory\n/home/zsun/gw-workspace/8iAi2Q1iihze/gw-vC8lRLpPuKneA12SoC0LjaV5U7-8iAi2Q1iihze.sh: line 103: : No such file or directory\n0a1,32\n> Preparing for date :  20200715\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\n> File does not exist\n> preparing training data for  20200715\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200714\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n> preparing data for past date 20200713\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n> preparing data for past date 20200712\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n> preparing data for past date 20200711\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n> preparing data for past date 20200710\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n> preparing data for past date 20200709\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n> preparing data for past date 20200708\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n1a34,43\n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n43a44,75\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n>     LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> The maximum value of the column is zero.\n> Traceback (most recent call last):\n>   File \"<stdin>\", line 48, in <module>\n> Exception: The maximum value of the column is zero.\nJob 1616840 has finished with state: JobState=FAILED\nSlurm job (1616840) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1616840      fc_model_+     FAILED      1:0            2024-03-03T00:15:29 2024-03-03T00:19:22 \n1616840.bat+      batch     FAILED      1:0    421752K 2024-03-03T00:15:29 2024-03-03T00:19:22 \n1616840.ext+     extern  COMPLETED      0:0          0 2024-03-03T00:15:29 2024-03-03T00:19:22 \nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1709442927274,
  "history_end_time" : 1709443169043,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ltoPnXKRl16W",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=20G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-10:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nfrom datetime import datetime, timedelta\nimport pandas as pd\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  \n\n  # Start date\n  start_date = datetime(2020, 7, 15)\n\n  # End date\n  end_date = datetime(2020, 7, 18)\n\n  # Define the step size for traversal\n  step = timedelta(days=1)\n  \n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\"\n\n  # Traverse the dates\n  current_date = start_date\n  while current_date <= end_date:\n      print(\"Preparing for date : \", current_date.strftime('%Y%m%d'))  # Print date in YYYYMMDD format\n      current_date += step\n      training_end_date = current_date.strftime('%Y%m%d')\n      #training_end_date = \"20201030\" # the last day of the 7 day history\n      prepare_training_data(training_end_date, training_data_folder)\n      \n      file_path = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/20200715_time_series_with_window.csv\"\n\n      #file_path = \"/groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\"\n\n      df = pd.read_csv(file_path)\n\n      print(df.head())\n\n      # Assuming you want to calculate statistics of a column named 'column_name'\n      column_name = ' FRP'\n\n      # Basic statistics\n      stats = df[column_name].describe()\n      \n      if df[column_name].max() == 0:\n        print(\"The maximum value of the column is zero.\")\n        raise Exception(\"The maximum value of the column is zero.\")\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/ltoPnXKRl16W\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1616837\n/home/zsun/gw-workspace/ltoPnXKRl16W/gw-vC8lRLpPuKneA12SoC0LjaV5U7-ltoPnXKRl16W.sh: line 98: : No such file or directory\n/home/zsun/gw-workspace/ltoPnXKRl16W/gw-vC8lRLpPuKneA12SoC0LjaV5U7-ltoPnXKRl16W.sh: line 102: : No such file or directory\n/home/zsun/gw-workspace/ltoPnXKRl16W/gw-vC8lRLpPuKneA12SoC0LjaV5U7-ltoPnXKRl16W.sh: line 102: : No such file or directory\n/home/zsun/gw-workspace/ltoPnXKRl16W/gw-vC8lRLpPuKneA12SoC0LjaV5U7-ltoPnXKRl16W.sh: line 102: : No such file or directory\n/home/zsun/gw-workspace/ltoPnXKRl16W/gw-vC8lRLpPuKneA12SoC0LjaV5U7-ltoPnXKRl16W.sh: line 102: : No such file or directory\n1c1,19\n< \n---\n> Preparing for date :  20200715\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2//20200716_time_series_with_window.csv exists\n> Traceback (most recent call last):\n>   File \"<stdin>\", line 35, in <module>\n>   File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n>     return func(*args, **kwargs)\n>   File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n>     return _read(filepath_or_buffer, kwds)\n>   File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 575, in _read\n>     parser = TextFileReader(filepath_or_buffer, **kwds)\n>   File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n>     self._engine = self._make_engine(f, self.engine)\n>   File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n>     self.handles = get_handle(  # type: ignore[call-overload]\n>   File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\", line 789, in get_handle\n>     handle = open(\n> FileNotFoundError: [Errno 2] No such file or directory: '/groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/20200715_time_series_with_window.csv'\nJob 1616837 has finished with state: JobState=FAILED\nSlurm job (1616837) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1616837      fc_model_+     FAILED      1:0            2024-03-03T00:10:24 2024-03-03T00:10:58 \n1616837.bat+      batch     FAILED      1:0          0 2024-03-03T00:10:24 2024-03-03T00:10:58 \n1616837.ext+     extern  COMPLETED      0:0          0 2024-03-03T00:10:24 2024-03-03T00:10:58 \nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1709442622659,
  "history_end_time" : 1709442663937,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "U9qGQUIDA3HU",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=20G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-10:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nfrom datetime import datetime, timedelta\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  \n\n  # Start date\n  start_date = datetime(2020, 7, 15)\n\n  # End date\n  end_date = datetime(2020, 7, 18)\n\n  # Define the step size for traversal\n  step = timedelta(days=1)\n  \n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\"\n\n  # Traverse the dates\n  current_date = start_date\n  while current_date <= end_date:\n      print(\"Preparing for date : \", current_date.strftime('%Y%m%d'))  # Print date in YYYYMMDD format\n      current_date += step\n      training_end_date = current_date.strftime('%Y%m%d')\n      #training_end_date = \"20201030\" # the last day of the 7 day history\n      prepare_training_data(training_end_date, training_data_folder)\n      \n      file_path = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/20200715_time_series_with_window.csv\"\n\n      #file_path = \"/groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\"\n\n      df = pd.read_csv(file_path)\n\n      print(df.head())\n\n      # Assuming you want to calculate statistics of a column named 'column_name'\n      column_name = ' FRP'\n\n      # Basic statistics\n      stats = df[column_name].describe()\n      \n      if df[column_name].max() == 0:\n        print(\"The maximum value of the column is zero.\")\n        raise Exception(\"The maximum value of the column is zero.\")\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/U9qGQUIDA3HU\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1616836\n/home/zsun/gw-workspace/U9qGQUIDA3HU/gw-vC8lRLpPuKneA12SoC0LjaV5U7-U9qGQUIDA3HU.sh: line 97: : No such file or directory\n/home/zsun/gw-workspace/U9qGQUIDA3HU/gw-vC8lRLpPuKneA12SoC0LjaV5U7-U9qGQUIDA3HU.sh: line 101: : No such file or directory\n/home/zsun/gw-workspace/U9qGQUIDA3HU/gw-vC8lRLpPuKneA12SoC0LjaV5U7-U9qGQUIDA3HU.sh: line 101: : No such file or directory\n/home/zsun/gw-workspace/U9qGQUIDA3HU/gw-vC8lRLpPuKneA12SoC0LjaV5U7-U9qGQUIDA3HU.sh: line 101: : No such file or directory\n/home/zsun/gw-workspace/U9qGQUIDA3HU/gw-vC8lRLpPuKneA12SoC0LjaV5U7-U9qGQUIDA3HU.sh: line 101: : No such file or directory\n1c1,26\n< \n---\n> Preparing for date :  20200715\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\n> File does not exist\n> preparing training data for  20200716\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200715\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n> preparing data for past date 20200714\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n> preparing data for past date 20200713\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n> preparing data for past date 20200712\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n> preparing data for past date 20200711\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n> preparing data for past date 20200710\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n> preparing data for past date 20200709\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n26a27,43\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n43a44,66\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Traceback (most recent call last):\n>   File \"<stdin>\", line 34, in <module>\n> NameError: name 'pd' is not defined\nJob 1616836 has finished with state: JobState=FAILED\nSlurm job (1616836) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1616836      fc_model_+     FAILED      1:0            2024-03-03T00:04:10 2024-03-03T00:08:03 \n1616836.bat+      batch     FAILED      1:0    421628K 2024-03-03T00:04:10 2024-03-03T00:08:03 \n1616836.ext+     extern  COMPLETED      0:0          0 2024-03-03T00:04:10 2024-03-03T00:08:03 \nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1709442249248,
  "history_end_time" : 1709442491014,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "9cZ6QWWQhUXa",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=20G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-10:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nfrom datetime import datetime, timedelta\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  \n\n  # Start date\n  start_date = datetime(2020, 7, 16)\n\n  # End date\n  end_date = datetime(2020, 7, 18)\n\n  # Define the step size for traversal\n  step = timedelta(days=1)\n  \n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\"\n\n  # Traverse the dates\n  current_date = start_date\n  while current_date <= end_date:\n      print(\"Preparing for date : \", current_date.strftime('%Y%m%d'))  # Print date in YYYYMMDD format\n      current_date += step\n      training_end_date = current_date.strftime('%Y%m%d')\n      #training_end_date = \"20201030\" # the last day of the 7 day history\n      prepare_training_data(training_end_date, training_data_folder)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/9cZ6QWWQhUXa\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1616788\n/home/zsun/gw-workspace/9cZ6QWWQhUXa/gw-vC8lRLpPuKneA12SoC0LjaV5U7-9cZ6QWWQhUXa.sh: line 79: : No such file or directory\n/home/zsun/gw-workspace/9cZ6QWWQhUXa/gw-vC8lRLpPuKneA12SoC0LjaV5U7-9cZ6QWWQhUXa.sh: line 83: : No such file or directory\n/home/zsun/gw-workspace/9cZ6QWWQhUXa/gw-vC8lRLpPuKneA12SoC0LjaV5U7-9cZ6QWWQhUXa.sh: line 83: : No such file or directory\n/home/zsun/gw-workspace/9cZ6QWWQhUXa/gw-vC8lRLpPuKneA12SoC0LjaV5U7-9cZ6QWWQhUXa.sh: line 83: : No such file or directory\n/home/zsun/gw-workspace/9cZ6QWWQhUXa/gw-vC8lRLpPuKneA12SoC0LjaV5U7-9cZ6QWWQhUXa.sh: line 83: : No such file or directory\n1c1,18\n< \n---\n> Preparing for date :  20200716\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder created: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\n> File does not exist\n> preparing training data for  20200717\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200716\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n> preparing data for past date 20200715\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n> preparing data for past date 20200714\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n18a19,43\n> preparing data for past date 20200713\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n> preparing data for past date 20200712\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n> preparing data for past date 20200711\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n> preparing data for past date 20200710\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n43a44,106\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200717\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\n> File does not exist\n> preparing training data for  20200718\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200717\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n> preparing data for past date 20200716\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n> preparing data for past date 20200715\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n> preparing data for past date 20200714\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n> preparing data for past date 20200713\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n> preparing data for past date 20200712\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n> preparing data for past date 20200711\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n106a107,152\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200718\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_2/\n> File does not exist\n> preparing training data for  20200719\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200718\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n> preparing data for past date 20200717\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n> preparing data for past date 20200716\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n> preparing data for past date 20200715\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n> preparing data for past date 20200714\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n> preparing data for past date 20200713\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n> preparing data for past date 20200712\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n152a153,169\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n169a170,189\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\nJob 1616788 has finished with state: JobState=COMPLETED\nSlurm job (1616788) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1616788      fc_model_+  COMPLETED      0:0            2024-03-02T23:47:31 2024-03-02T23:58:05 \n1616788.bat+      batch  COMPLETED      0:0    609688K 2024-03-02T23:47:31 2024-03-02T23:58:05 \n1616788.ext+     extern  COMPLETED      0:0          0 2024-03-02T23:47:31 2024-03-02T23:58:05 \nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1709441249018,
  "history_end_time" : 1709441891760,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "RRzyRQTEzdne",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=20G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-10:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nfrom datetime import datetime, timedelta\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  \n  # Start date\n  start_date = datetime(2020, 7, 16)\n\n  # End date\n  end_date = datetime(2020, 7, 18)\n\n  # Define the step size for traversal\n  step = timedelta(days=1)\n  \n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_v2/\"\n\n  # Traverse the dates\n  current_date = start_date\n  while current_date <= end_date:\n      print(\"Preparing for date : \", current_date.strftime('%Y%m%d'))  # Print date in YYYYMMDD format\n      current_date += step\n      training_end_date = current_date.strftime('%Y%m%d')\n      #training_end_date = \"20201030\" # the last day of the 7 day history\n      prepare_training_data(training_end_date, training_data_folder)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/RRzyRQTEzdne\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1616731\n/home/zsun/gw-workspace/RRzyRQTEzdne/gw-mOxXxFQDAvJ5N4aJF02mtsMFwJ-RRzyRQTEzdne.sh: line 78: : No such file or directory\n/home/zsun/gw-workspace/RRzyRQTEzdne/gw-mOxXxFQDAvJ5N4aJF02mtsMFwJ-RRzyRQTEzdne.sh: line 82: : No such file or directory\n/home/zsun/gw-workspace/RRzyRQTEzdne/gw-mOxXxFQDAvJ5N4aJF02mtsMFwJ-RRzyRQTEzdne.sh: line 82: : No such file or directory\n/home/zsun/gw-workspace/RRzyRQTEzdne/gw-mOxXxFQDAvJ5N4aJF02mtsMFwJ-RRzyRQTEzdne.sh: line 82: : No such file or directory\n/home/zsun/gw-workspace/RRzyRQTEzdne/gw-mOxXxFQDAvJ5N4aJF02mtsMFwJ-RRzyRQTEzdne.sh: line 82: : No such file or directory\n1c1,14\n< \n---\n> Preparing for date :  20200716\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder created: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_v2/\n> File does not exist\n> preparing training data for  20200717\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200716\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n14a15,43\n> preparing data for past date 20200715\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n> preparing data for past date 20200714\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n> preparing data for past date 20200713\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n> preparing data for past date 20200712\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n> preparing data for past date 20200711\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n> preparing data for past date 20200710\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n43a44,106\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200717\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_v2/\n> File does not exist\n> preparing training data for  20200718\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200717\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n> preparing data for past date 20200716\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n> preparing data for past date 20200715\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n> preparing data for past date 20200714\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n> preparing data for past date 20200713\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n> preparing data for past date 20200712\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n> preparing data for past date 20200711\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n106a107,169\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200718\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_v2/\n> File does not exist\n> preparing training data for  20200719\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200718\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n> preparing data for past date 20200717\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n> preparing data for past date 20200716\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n> preparing data for past date 20200715\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n> preparing data for past date 20200714\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n> preparing data for past date 20200713\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n> preparing data for past date 20200712\n> Reading original file:  /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n169a170,189\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\nJob 1616731 has finished with state: JobState=COMPLETED\nSlurm job (1616731) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1616731      fc_model_+  COMPLETED      0:0            2024-03-02T21:27:59 2024-03-02T21:38:31 \n1616731.bat+      batch  COMPLETED      0:0    498988K 2024-03-02T21:27:59 2024-03-02T21:38:31 \n1616731.ext+     extern  COMPLETED      0:0          0 2024-03-02T21:27:59 2024-03-02T21:38:31 \nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1709432878844,
  "history_end_time" : 1709433521603,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "aFGdESTwY1Z6",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=20G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-10:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nfrom datetime import datetime, timedelta\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  \n\n  # Start date\n  start_date = datetime(2020, 7, 16)\n\n  # End date\n  end_date = datetime(2020, 10, 30)\n\n  # Define the step size for traversal\n  step = timedelta(days=1)\n  \n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new/\"\n\n  # Traverse the dates\n  current_date = start_date\n  while current_date <= end_date:\n      print(\"Preparing for date : \", current_date.strftime('%Y%m%d'))  # Print date in YYYYMMDD format\n      current_date += step\n      training_end_date = current_date.strftime('%Y%m%d')\n      #training_end_date = \"20201030\" # the last day of the 7 day history\n      prepare_training_data(training_end_date, training_data_folder)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/aFGdESTwY1Z6\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1611138\n/home/zsun/gw-workspace/aFGdESTwY1Z6/gw-DQtTTeyH5y4iwcADckwBHVNV4Y-aFGdESTwY1Z6.sh: line 79: : No such file or directory\n/home/zsun/gw-workspace/aFGdESTwY1Z6/gw-DQtTTeyH5y4iwcADckwBHVNV4Y-aFGdESTwY1Z6.sh: line 83: : No such file or directory\n/home/zsun/gw-workspace/aFGdESTwY1Z6/gw-DQtTTeyH5y4iwcADckwBHVNV4Y-aFGdESTwY1Z6.sh: line 83: : No such file or directory\n/home/zsun/gw-workspace/aFGdESTwY1Z6/gw-DQtTTeyH5y4iwcADckwBHVNV4Y-aFGdESTwY1Z6.sh: line 83: : No such file or directory\n/home/zsun/gw-workspace/aFGdESTwY1Z6/gw-DQtTTeyH5y4iwcADckwBHVNV4Y-aFGdESTwY1Z6.sh: line 83: : No such file or directory\n1c1,44\n< \n---\n> Preparing for date :  20200716\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200717_time_series_with_window.csv exists\n> Preparing for date :  20200717\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200718_time_series_with_window.csv exists\n> Preparing for date :  20200718\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200719_time_series_with_window.csv exists\n> Preparing for date :  20200719\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200720_time_series_with_window.csv exists\n> Preparing for date :  20200720\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200721_time_series_with_window.csv exists\n> Preparing for date :  20200721\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200722_time_series_with_window.csv exists\n> Preparing for date :  20200722\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200723_time_series_with_window.csv exists\n> Preparing for date :  20200723\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200724_time_series_with_window.csv exists\n> Preparing for date :  20200724\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200725_time_series_with_window.csv exists\n> Preparing for date :  20200725\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200726_time_series_with_window.csv exists\n> Preparing for date :  20200726\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200727_time_series_with_window.csv exists\n44a45,107\n> Preparing for date :  20200727\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200728_time_series_with_window.csv exists\n> Preparing for date :  20200728\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200729_time_series_with_window.csv exists\n> Preparing for date :  20200729\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200730_time_series_with_window.csv exists\n> Preparing for date :  20200730\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200731_time_series_with_window.csv exists\n> Preparing for date :  20200731\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200801_time_series_with_window.csv exists\n> Preparing for date :  20200801\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200802_time_series_with_window.csv exists\n> Preparing for date :  20200802\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells_new//20200803_time_series_with_window.csv exists\n> Preparing for date :  20200803\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200804\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200803\n> preparing data for past date 20200802\n> preparing data for past date 20200801\n> preparing data for past date 20200731\n> preparing data for past date 20200730\n> preparing data for past date 20200729\n> preparing data for past date 20200728\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n107a108,162\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200804\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200805\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200804\n> preparing data for past date 20200803\n> preparing data for past date 20200802\n> preparing data for past date 20200801\n> preparing data for past date 20200731\n> preparing data for past date 20200730\n> preparing data for past date 20200729\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n162a163,199\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200805\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200806\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200805\n> preparing data for past date 20200804\n> preparing data for past date 20200803\n> preparing data for past date 20200802\n> preparing data for past date 20200801\n> preparing data for past date 20200731\n199a200,217\n> preparing data for past date 20200730\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n217a218,272\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200806\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200807\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200806\n> preparing data for past date 20200805\n> preparing data for past date 20200804\n> preparing data for past date 20200803\n> preparing data for past date 20200802\n> preparing data for past date 20200801\n> preparing data for past date 20200731\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n272a273,327\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200807\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200808\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200807\n> preparing data for past date 20200806\n> preparing data for past date 20200805\n> preparing data for past date 20200804\n> preparing data for past date 20200803\n> preparing data for past date 20200802\n> preparing data for past date 20200801\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n327a328,382\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200808\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200809\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200808\n> preparing data for past date 20200807\n> preparing data for past date 20200806\n> preparing data for past date 20200805\n> preparing data for past date 20200804\n> preparing data for past date 20200803\n> preparing data for past date 20200802\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n382a383,419\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200809\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200810\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200809\n> preparing data for past date 20200808\n> preparing data for past date 20200807\n> preparing data for past date 20200806\n> preparing data for past date 20200805\n> preparing data for past date 20200804\n419a420,437\n> preparing data for past date 20200803\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n437a438,492\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200810\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200811\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200810\n> preparing data for past date 20200809\n> preparing data for past date 20200808\n> preparing data for past date 20200807\n> preparing data for past date 20200806\n> preparing data for past date 20200805\n> preparing data for past date 20200804\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n492a493,547\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200811\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200812\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200811\n> preparing data for past date 20200810\n> preparing data for past date 20200809\n> preparing data for past date 20200808\n> preparing data for past date 20200807\n> preparing data for past date 20200806\n> preparing data for past date 20200805\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n547a548,602\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200812\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200813\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200812\n> preparing data for past date 20200811\n> preparing data for past date 20200810\n> preparing data for past date 20200809\n> preparing data for past date 20200808\n> preparing data for past date 20200807\n> preparing data for past date 20200806\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n602a603,640\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200813\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200814\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200813\n> preparing data for past date 20200812\n> preparing data for past date 20200811\n> preparing data for past date 20200810\n> preparing data for past date 20200809\n> preparing data for past date 20200808\n> preparing data for past date 20200807\n640a641,657\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n657a658,712\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200814\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200815\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200814\n> preparing data for past date 20200813\n> preparing data for past date 20200812\n> preparing data for past date 20200811\n> preparing data for past date 20200810\n> preparing data for past date 20200809\n> preparing data for past date 20200808\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n712a713,767\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200815\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200816\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200815\n> preparing data for past date 20200814\n> preparing data for past date 20200813\n> preparing data for past date 20200812\n> preparing data for past date 20200811\n> preparing data for past date 20200810\n> preparing data for past date 20200809\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n767a768,803\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200816\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200817\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200816\n> preparing data for past date 20200815\n> preparing data for past date 20200814\n> preparing data for past date 20200813\n> preparing data for past date 20200812\n803a804,822\n> preparing data for past date 20200811\n> preparing data for past date 20200810\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n822a823,877\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200817\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200818\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200817\n> preparing data for past date 20200816\n> preparing data for past date 20200815\n> preparing data for past date 20200814\n> preparing data for past date 20200813\n> preparing data for past date 20200812\n> preparing data for past date 20200811\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n877a878,914\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200818\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200819\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200818\n> preparing data for past date 20200817\n> preparing data for past date 20200816\n> preparing data for past date 20200815\n> preparing data for past date 20200814\n> preparing data for past date 20200813\n914a915,932\n> preparing data for past date 20200812\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n932a933,987\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200819\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200820\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200819\n> preparing data for past date 20200818\n> preparing data for past date 20200817\n> preparing data for past date 20200816\n> preparing data for past date 20200815\n> preparing data for past date 20200814\n> preparing data for past date 20200813\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n987a988,1042\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200820\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200821\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200820\n> preparing data for past date 20200819\n> preparing data for past date 20200818\n> preparing data for past date 20200817\n> preparing data for past date 20200816\n> preparing data for past date 20200815\n> preparing data for past date 20200814\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1042a1043,1097\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200821\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200822\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200821\n> preparing data for past date 20200820\n> preparing data for past date 20200819\n> preparing data for past date 20200818\n> preparing data for past date 20200817\n> preparing data for past date 20200816\n> preparing data for past date 20200815\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1097a1098,1152\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200822\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200823\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200822\n> preparing data for past date 20200821\n> preparing data for past date 20200820\n> preparing data for past date 20200819\n> preparing data for past date 20200818\n> preparing data for past date 20200817\n> preparing data for past date 20200816\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1152a1153,1190\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200823\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200824\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200823\n> preparing data for past date 20200822\n> preparing data for past date 20200821\n> preparing data for past date 20200820\n> preparing data for past date 20200819\n> preparing data for past date 20200818\n> preparing data for past date 20200817\n1190a1191,1207\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1207a1208,1262\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200824\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200825\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200824\n> preparing data for past date 20200823\n> preparing data for past date 20200822\n> preparing data for past date 20200821\n> preparing data for past date 20200820\n> preparing data for past date 20200819\n> preparing data for past date 20200818\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1262a1263,1300\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200825\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200826\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200825\n> preparing data for past date 20200824\n> preparing data for past date 20200823\n> preparing data for past date 20200822\n> preparing data for past date 20200821\n> preparing data for past date 20200820\n> preparing data for past date 20200819\n1300a1301,1317\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1317a1318,1372\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200826\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200827\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200826\n> preparing data for past date 20200825\n> preparing data for past date 20200824\n> preparing data for past date 20200823\n> preparing data for past date 20200822\n> preparing data for past date 20200821\n> preparing data for past date 20200820\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1372a1373,1427\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200827\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200828\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200827\n> preparing data for past date 20200826\n> preparing data for past date 20200825\n> preparing data for past date 20200824\n> preparing data for past date 20200823\n> preparing data for past date 20200822\n> preparing data for past date 20200821\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1427a1428,1482\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200828\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200829\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200828\n> preparing data for past date 20200827\n> preparing data for past date 20200826\n> preparing data for past date 20200825\n> preparing data for past date 20200824\n> preparing data for past date 20200823\n> preparing data for past date 20200822\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1482a1483,1537\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200829\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200830\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200829\n> preparing data for past date 20200828\n> preparing data for past date 20200827\n> preparing data for past date 20200826\n> preparing data for past date 20200825\n> preparing data for past date 20200824\n> preparing data for past date 20200823\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1537a1538,1574\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200830\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200831\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200830\n> preparing data for past date 20200829\n> preparing data for past date 20200828\n> preparing data for past date 20200827\n> preparing data for past date 20200826\n> preparing data for past date 20200825\n1574a1575,1592\n> preparing data for past date 20200824\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1592a1593,1647\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200831\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200901\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200831\n> preparing data for past date 20200830\n> preparing data for past date 20200829\n> preparing data for past date 20200828\n> preparing data for past date 20200827\n> preparing data for past date 20200826\n> preparing data for past date 20200825\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1647a1648,1702\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200901\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200902\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200901\n> preparing data for past date 20200831\n> preparing data for past date 20200830\n> preparing data for past date 20200829\n> preparing data for past date 20200828\n> preparing data for past date 20200827\n> preparing data for past date 20200826\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1702a1703,1757\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200902\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200903\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200902\n> preparing data for past date 20200901\n> preparing data for past date 20200831\n> preparing data for past date 20200830\n> preparing data for past date 20200829\n> preparing data for past date 20200828\n> preparing data for past date 20200827\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1757a1758,1795\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200903\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200904\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200903\n> preparing data for past date 20200902\n> preparing data for past date 20200901\n> preparing data for past date 20200831\n> preparing data for past date 20200830\n> preparing data for past date 20200829\n> preparing data for past date 20200828\n1795a1796,1812\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1812a1813,1867\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200904\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200905\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200904\n> preparing data for past date 20200903\n> preparing data for past date 20200902\n> preparing data for past date 20200901\n> preparing data for past date 20200831\n> preparing data for past date 20200830\n> preparing data for past date 20200829\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1867a1868,1922\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200905\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200906\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200905\n> preparing data for past date 20200904\n> preparing data for past date 20200903\n> preparing data for past date 20200902\n> preparing data for past date 20200901\n> preparing data for past date 20200831\n> preparing data for past date 20200830\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1922a1923,1977\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200906\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200907\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200906\n> preparing data for past date 20200905\n> preparing data for past date 20200904\n> preparing data for past date 20200903\n> preparing data for past date 20200902\n> preparing data for past date 20200901\n> preparing data for past date 20200831\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1977a1978,2014\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200907\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200908\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200907\n> preparing data for past date 20200906\n> preparing data for past date 20200905\n> preparing data for past date 20200904\n> preparing data for past date 20200903\n> preparing data for past date 20200902\n2014a2015,2032\n> preparing data for past date 20200901\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2032a2033,2087\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200908\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200909\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200908\n> preparing data for past date 20200907\n> preparing data for past date 20200906\n> preparing data for past date 20200905\n> preparing data for past date 20200904\n> preparing data for past date 20200903\n> preparing data for past date 20200902\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2087a2088,2125\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200909\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200910\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200909\n> preparing data for past date 20200908\n> preparing data for past date 20200907\n> preparing data for past date 20200906\n> preparing data for past date 20200905\n> preparing data for past date 20200904\n> preparing data for past date 20200903\n2125a2126,2142\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2142a2143,2197\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200910\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200911\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200910\n> preparing data for past date 20200909\n> preparing data for past date 20200908\n> preparing data for past date 20200907\n> preparing data for past date 20200906\n> preparing data for past date 20200905\n> preparing data for past date 20200904\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2197a2198,2252\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200911\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200912\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200911\n> preparing data for past date 20200910\n> preparing data for past date 20200909\n> preparing data for past date 20200908\n> preparing data for past date 20200907\n> preparing data for past date 20200906\n> preparing data for past date 20200905\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2252a2253,2290\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200912\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200913\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200912\n> preparing data for past date 20200911\n> preparing data for past date 20200910\n> preparing data for past date 20200909\n> preparing data for past date 20200908\n> preparing data for past date 20200907\n> preparing data for past date 20200906\n2290a2291,2307\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2307a2308,2362\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200913\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200914\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200913\n> preparing data for past date 20200912\n> preparing data for past date 20200911\n> preparing data for past date 20200910\n> preparing data for past date 20200909\n> preparing data for past date 20200908\n> preparing data for past date 20200907\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2362a2363,2400\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200914\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200915\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200914\n> preparing data for past date 20200913\n> preparing data for past date 20200912\n> preparing data for past date 20200911\n> preparing data for past date 20200910\n> preparing data for past date 20200909\n> preparing data for past date 20200908\n2400a2401,2417\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2417a2418,2472\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200915\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200916\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200915\n> preparing data for past date 20200914\n> preparing data for past date 20200913\n> preparing data for past date 20200912\n> preparing data for past date 20200911\n> preparing data for past date 20200910\n> preparing data for past date 20200909\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2472a2473,2510\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200916\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200917\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200916\n> preparing data for past date 20200915\n> preparing data for past date 20200914\n> preparing data for past date 20200913\n> preparing data for past date 20200912\n> preparing data for past date 20200911\n> preparing data for past date 20200910\n2510a2511,2527\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2527a2528,2582\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200917\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200918\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200917\n> preparing data for past date 20200916\n> preparing data for past date 20200915\n> preparing data for past date 20200914\n> preparing data for past date 20200913\n> preparing data for past date 20200912\n> preparing data for past date 20200911\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2582a2583,2637\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200918\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200919\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200918\n> preparing data for past date 20200917\n> preparing data for past date 20200916\n> preparing data for past date 20200915\n> preparing data for past date 20200914\n> preparing data for past date 20200913\n> preparing data for past date 20200912\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2637a2638,2692\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200919\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200920\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200919\n> preparing data for past date 20200918\n> preparing data for past date 20200917\n> preparing data for past date 20200916\n> preparing data for past date 20200915\n> preparing data for past date 20200914\n> preparing data for past date 20200913\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2692a2693,2747\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200920\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200921\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200920\n> preparing data for past date 20200919\n> preparing data for past date 20200918\n> preparing data for past date 20200917\n> preparing data for past date 20200916\n> preparing data for past date 20200915\n> preparing data for past date 20200914\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2747a2748,2802\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200921\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200922\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200921\n> preparing data for past date 20200920\n> preparing data for past date 20200919\n> preparing data for past date 20200918\n> preparing data for past date 20200917\n> preparing data for past date 20200916\n> preparing data for past date 20200915\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2802a2803,2857\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200922\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200923\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200922\n> preparing data for past date 20200921\n> preparing data for past date 20200920\n> preparing data for past date 20200919\n> preparing data for past date 20200918\n> preparing data for past date 20200917\n> preparing data for past date 20200916\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2857a2858,2912\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200923\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200924\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200923\n> preparing data for past date 20200922\n> preparing data for past date 20200921\n> preparing data for past date 20200920\n> preparing data for past date 20200919\n> preparing data for past date 20200918\n> preparing data for past date 20200917\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2912a2913,2967\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200924\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200925\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200924\n> preparing data for past date 20200923\n> preparing data for past date 20200922\n> preparing data for past date 20200921\n> preparing data for past date 20200920\n> preparing data for past date 20200919\n> preparing data for past date 20200918\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n2967a2968,3022\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200925\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200926\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200925\n> preparing data for past date 20200924\n> preparing data for past date 20200923\n> preparing data for past date 20200922\n> preparing data for past date 20200921\n> preparing data for past date 20200920\n> preparing data for past date 20200919\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3022a3023,3077\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200926\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200927\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200926\n> preparing data for past date 20200925\n> preparing data for past date 20200924\n> preparing data for past date 20200923\n> preparing data for past date 20200922\n> preparing data for past date 20200921\n> preparing data for past date 20200920\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3077a3078,3132\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200927\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200928\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200927\n> preparing data for past date 20200926\n> preparing data for past date 20200925\n> preparing data for past date 20200924\n> preparing data for past date 20200923\n> preparing data for past date 20200922\n> preparing data for past date 20200921\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3132a3133,3187\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200928\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200929\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200928\n> preparing data for past date 20200927\n> preparing data for past date 20200926\n> preparing data for past date 20200925\n> preparing data for past date 20200924\n> preparing data for past date 20200923\n> preparing data for past date 20200922\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3187a3188,3242\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200929\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200930\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200929\n> preparing data for past date 20200928\n> preparing data for past date 20200927\n> preparing data for past date 20200926\n> preparing data for past date 20200925\n> preparing data for past date 20200924\n> preparing data for past date 20200923\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3242a3243,3297\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200930\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201001\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200930\n> preparing data for past date 20200929\n> preparing data for past date 20200928\n> preparing data for past date 20200927\n> preparing data for past date 20200926\n> preparing data for past date 20200925\n> preparing data for past date 20200924\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3297a3298,3352\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201001\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201002\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201001\n> preparing data for past date 20200930\n> preparing data for past date 20200929\n> preparing data for past date 20200928\n> preparing data for past date 20200927\n> preparing data for past date 20200926\n> preparing data for past date 20200925\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3352a3353,3407\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201002\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201003\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201002\n> preparing data for past date 20201001\n> preparing data for past date 20200930\n> preparing data for past date 20200929\n> preparing data for past date 20200928\n> preparing data for past date 20200927\n> preparing data for past date 20200926\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3407a3408,3462\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201003\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201004\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201003\n> preparing data for past date 20201002\n> preparing data for past date 20201001\n> preparing data for past date 20200930\n> preparing data for past date 20200929\n> preparing data for past date 20200928\n> preparing data for past date 20200927\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3462a3463,3517\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201004\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201005\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201004\n> preparing data for past date 20201003\n> preparing data for past date 20201002\n> preparing data for past date 20201001\n> preparing data for past date 20200930\n> preparing data for past date 20200929\n> preparing data for past date 20200928\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3517a3518,3572\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201005\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201006\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201005\n> preparing data for past date 20201004\n> preparing data for past date 20201003\n> preparing data for past date 20201002\n> preparing data for past date 20201001\n> preparing data for past date 20200930\n> preparing data for past date 20200929\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3572a3573,3627\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201006\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201007\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201006\n> preparing data for past date 20201005\n> preparing data for past date 20201004\n> preparing data for past date 20201003\n> preparing data for past date 20201002\n> preparing data for past date 20201001\n> preparing data for past date 20200930\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3627a3628,3682\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201007\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201008\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201007\n> preparing data for past date 20201006\n> preparing data for past date 20201005\n> preparing data for past date 20201004\n> preparing data for past date 20201003\n> preparing data for past date 20201002\n> preparing data for past date 20201001\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3682a3683,3737\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201008\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201009\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201008\n> preparing data for past date 20201007\n> preparing data for past date 20201006\n> preparing data for past date 20201005\n> preparing data for past date 20201004\n> preparing data for past date 20201003\n> preparing data for past date 20201002\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3737a3738,3792\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201009\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201010\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201009\n> preparing data for past date 20201008\n> preparing data for past date 20201007\n> preparing data for past date 20201006\n> preparing data for past date 20201005\n> preparing data for past date 20201004\n> preparing data for past date 20201003\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3792a3793,3847\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201010\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201011\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201010\n> preparing data for past date 20201009\n> preparing data for past date 20201008\n> preparing data for past date 20201007\n> preparing data for past date 20201006\n> preparing data for past date 20201005\n> preparing data for past date 20201004\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3847a3848,3902\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201011\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201012\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201011\n> preparing data for past date 20201010\n> preparing data for past date 20201009\n> preparing data for past date 20201008\n> preparing data for past date 20201007\n> preparing data for past date 20201006\n> preparing data for past date 20201005\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3902a3903,3937\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201012\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201013\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201012\n> preparing data for past date 20201011\n> preparing data for past date 20201010\n> preparing data for past date 20201009\n3937a3938,3957\n> preparing data for past date 20201008\n> preparing data for past date 20201007\n> preparing data for past date 20201006\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n3957a3958,4012\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201013\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201014\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201013\n> preparing data for past date 20201012\n> preparing data for past date 20201011\n> preparing data for past date 20201010\n> preparing data for past date 20201009\n> preparing data for past date 20201008\n> preparing data for past date 20201007\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n4012a4013,4067\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201014\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201015\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201014\n> preparing data for past date 20201013\n> preparing data for past date 20201012\n> preparing data for past date 20201011\n> preparing data for past date 20201010\n> preparing data for past date 20201009\n> preparing data for past date 20201008\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n4067a4068,4122\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201015\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201016\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201015\n> preparing data for past date 20201014\n> preparing data for past date 20201013\n> preparing data for past date 20201012\n> preparing data for past date 20201011\n> preparing data for past date 20201010\n> preparing data for past date 20201009\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n4122a4123,4177\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201016\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201017\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201016\n> preparing data for past date 20201015\n> preparing data for past date 20201014\n> preparing data for past date 20201013\n> preparing data for past date 20201012\n> preparing data for past date 20201011\n> preparing data for past date 20201010\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n4177a4178,4232\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201017\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201018\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201017\n> preparing data for past date 20201016\n> preparing data for past date 20201015\n> preparing data for past date 20201014\n> preparing data for past date 20201013\n> preparing data for past date 20201012\n> preparing data for past date 20201011\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n4232a4233,4287\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201018\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201019\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201018\n> preparing data for past date 20201017\n> preparing data for past date 20201016\n> preparing data for past date 20201015\n> preparing data for past date 20201014\n> preparing data for past date 20201013\n> preparing data for past date 20201012\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n4287a4288,4342\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201019\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201020\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201019\n> preparing data for past date 20201018\n> preparing data for past date 20201017\n> preparing data for past date 20201016\n> preparing data for past date 20201015\n> preparing data for past date 20201014\n> preparing data for past date 20201013\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n4342a4343,4397\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201020\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201021\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201020\n> preparing data for past date 20201019\n> preparing data for past date 20201018\n> preparing data for past date 20201017\n> preparing data for past date 20201016\n> preparing data for past date 20201015\n> preparing data for past date 20201014\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n4397a4398,4452\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201021\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201022\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201021\n> preparing data for past date 20201020\n> preparing data for past date 20201019\n> preparing data for past date 20201018\n> preparing data for past date 20201017\n> preparing data for past date 20201016\n> preparing data for past date 20201015\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n4452a4453,4507\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20201022\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20201023\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201022\n> preparing data for past date 20201021\n> preparing data for past date 20201020\n> preparing data for past date 20201019\n> preparing data for past date 20201018\n> preparing data for past date 20201017\n> preparing data for past date 20201016\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n",
  "history_begin_time" : 1709336646112,
  "history_end_time" : 1709391437422,
  "history_notes" : "Geoweaver is terminated by hopper but the job finished. From July 16 to Oct 30. All data is collected.",
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "jLg54vKWKRGv",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=20G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-18:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nfrom datetime import datetime, timedelta\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  \n\n  # Start date\n  start_date = datetime(2020, 7, 16)\n\n  # End date\n  end_date = datetime(2020, 10, 30)\n\n  # Define the step size for traversal\n  step = timedelta(days=1)\n  \n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new/\"\n\n  # Traverse the dates\n  current_date = start_date\n  while current_date <= end_date:\n      print(\"Preparing for date : \", current_date.strftime('%Y%m%d'))  # Print date in YYYYMMDD format\n      current_date += step\n      training_end_date = current_date.strftime('%Y%m%d')\n      #training_end_date = \"20201030\" # the last day of the 7 day history\n      prepare_training_data(training_end_date, training_data_folder)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/jLg54vKWKRGv\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\nsbatch: error: Batch job submission failed: Requested time limit is invalid (missing or exceeds some limit)\njob_id=\njob id is empty. something wrong with the slurm job submission.\n",
  "history_begin_time" : 1709336627628,
  "history_end_time" : 1709336628711,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "8EKM6zBcft2g",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=20G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-22:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nfrom datetime import datetime, timedelta\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  \n\n  # Start date\n  start_date = datetime(2020, 7, 16)\n\n  # End date\n  end_date = datetime(2020, 10, 30)\n\n  # Define the step size for traversal\n  step = timedelta(days=1)\n  \n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new/\"\n\n  # Traverse the dates\n  current_date = start_date\n  while current_date <= end_date:\n      print(\"Preparing for date : \", current_date.strftime('%Y%m%d'))  # Print date in YYYYMMDD format\n      current_date += step\n      training_end_date = current_date.strftime('%Y%m%d')\n      #training_end_date = \"20201030\" # the last day of the 7 day history\n      prepare_training_data(training_end_date, training_data_folder)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/8EKM6zBcft2g\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\nsbatch: error: Batch job submission failed: Requested time limit is invalid (missing or exceeds some limit)\njob_id=\njob id is empty. something wrong with the slurm job submission.\n",
  "history_begin_time" : 1709336606917,
  "history_end_time" : 1709336608017,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "HLXlPG7KAooh",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nfrom datetime import datetime, timedelta\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  \n\n  # Start date\n  start_date = datetime(2020, 7, 16)\n\n  # End date\n  end_date = datetime(2020, 10, 30)\n\n  # Define the step size for traversal\n  step = timedelta(days=1)\n  \n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new/\"\n\n  # Traverse the dates\n  current_date = start_date\n  while current_date <= end_date:\n      print(\"Preparing for date : \", current_date.strftime('%Y%m%d'))  # Print date in YYYYMMDD format\n      current_date += step\n      training_end_date = current_date.strftime('%Y%m%d')\n      #training_end_date = \"20201030\" # the last day of the 7 day history\n      prepare_training_data(training_end_date, training_data_folder)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/HLXlPG7KAooh\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1606063\n/home/zsun/gw-workspace/HLXlPG7KAooh/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-HLXlPG7KAooh.sh: line 79: : No such file or directory\n/home/zsun/gw-workspace/HLXlPG7KAooh/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-HLXlPG7KAooh.sh: line 83: : No such file or directory\n/home/zsun/gw-workspace/HLXlPG7KAooh/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-HLXlPG7KAooh.sh: line 83: : No such file or directory\n/home/zsun/gw-workspace/HLXlPG7KAooh/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-HLXlPG7KAooh.sh: line 83: : No such file or directory\n/home/zsun/gw-workspace/HLXlPG7KAooh/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-HLXlPG7KAooh.sh: line 83: : No such file or directory\n1c1,15\n< \n---\n> Preparing for date :  20200716\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder created: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200717\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200716\n> preparing data for past date 20200715\n> preparing data for past date 20200714\n> preparing data for past date 20200713\n15a16,35\n> preparing data for past date 20200712\n> preparing data for past date 20200711\n> preparing data for past date 20200710\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n35a36,90\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200717\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200718\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200717\n> preparing data for past date 20200716\n> preparing data for past date 20200715\n> preparing data for past date 20200714\n> preparing data for past date 20200713\n> preparing data for past date 20200712\n> preparing data for past date 20200711\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n90a91,145\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200718\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200719\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200718\n> preparing data for past date 20200717\n> preparing data for past date 20200716\n> preparing data for past date 20200715\n> preparing data for past date 20200714\n> preparing data for past date 20200713\n> preparing data for past date 20200712\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n145a146,200\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200719\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200720\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200719\n> preparing data for past date 20200718\n> preparing data for past date 20200717\n> preparing data for past date 20200716\n> preparing data for past date 20200715\n> preparing data for past date 20200714\n> preparing data for past date 20200713\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n200a201,255\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200720\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200721\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200720\n> preparing data for past date 20200719\n> preparing data for past date 20200718\n> preparing data for past date 20200717\n> preparing data for past date 20200716\n> preparing data for past date 20200715\n> preparing data for past date 20200714\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n255a256,310\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200721\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200722\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200721\n> preparing data for past date 20200720\n> preparing data for past date 20200719\n> preparing data for past date 20200718\n> preparing data for past date 20200717\n> preparing data for past date 20200716\n> preparing data for past date 20200715\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n310a311,348\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200722\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200723\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200722\n> preparing data for past date 20200721\n> preparing data for past date 20200720\n> preparing data for past date 20200719\n> preparing data for past date 20200718\n> preparing data for past date 20200717\n> preparing data for past date 20200716\n348a349,365\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n365a366,403\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200723\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200724\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200723\n> preparing data for past date 20200722\n> preparing data for past date 20200721\n> preparing data for past date 20200720\n> preparing data for past date 20200719\n> preparing data for past date 20200718\n> preparing data for past date 20200717\n403a404,420\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n420a421,475\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200724\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200725\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200724\n> preparing data for past date 20200723\n> preparing data for past date 20200722\n> preparing data for past date 20200721\n> preparing data for past date 20200720\n> preparing data for past date 20200719\n> preparing data for past date 20200718\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n475a476,530\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200725\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200726\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200725\n> preparing data for past date 20200724\n> preparing data for past date 20200723\n> preparing data for past date 20200722\n> preparing data for past date 20200721\n> preparing data for past date 20200720\n> preparing data for past date 20200719\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n530a531,585\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200726\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200727\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200726\n> preparing data for past date 20200725\n> preparing data for past date 20200724\n> preparing data for past date 20200723\n> preparing data for past date 20200722\n> preparing data for past date 20200721\n> preparing data for past date 20200720\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n585a586,640\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200727\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200728\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200727\n> preparing data for past date 20200726\n> preparing data for past date 20200725\n> preparing data for past date 20200724\n> preparing data for past date 20200723\n> preparing data for past date 20200722\n> preparing data for past date 20200721\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n640a641,695\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200728\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200729\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200728\n> preparing data for past date 20200727\n> preparing data for past date 20200726\n> preparing data for past date 20200725\n> preparing data for past date 20200724\n> preparing data for past date 20200723\n> preparing data for past date 20200722\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n695a696,750\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200729\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200730\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200729\n> preparing data for past date 20200728\n> preparing data for past date 20200727\n> preparing data for past date 20200726\n> preparing data for past date 20200725\n> preparing data for past date 20200724\n> preparing data for past date 20200723\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n750a751,805\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200730\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200731\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200730\n> preparing data for past date 20200729\n> preparing data for past date 20200728\n> preparing data for past date 20200727\n> preparing data for past date 20200726\n> preparing data for past date 20200725\n> preparing data for past date 20200724\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n805a806,860\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200731\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200801\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200731\n> preparing data for past date 20200730\n> preparing data for past date 20200729\n> preparing data for past date 20200728\n> preparing data for past date 20200727\n> preparing data for past date 20200726\n> preparing data for past date 20200725\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n860a861,915\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200801\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200802\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200801\n> preparing data for past date 20200731\n> preparing data for past date 20200730\n> preparing data for past date 20200729\n> preparing data for past date 20200728\n> preparing data for past date 20200727\n> preparing data for past date 20200726\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n915a916,970\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200802\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200803\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200802\n> preparing data for past date 20200801\n> preparing data for past date 20200731\n> preparing data for past date 20200730\n> preparing data for past date 20200729\n> preparing data for past date 20200728\n> preparing data for past date 20200727\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n970a971,1007\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> Preparing for date :  20200803\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new/\n> File does not exist\n> preparing training data for  20200804\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200803\n> preparing data for past date 20200802\n> preparing data for past date 20200801\n> preparing data for past date 20200731\n> preparing data for past date 20200730\n> preparing data for past date 20200729\n1007a1008,1025\n> preparing data for past date 20200728\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n1025a1026\n> slurmstepd-hop043: error: *** JOB 1606063 ON hop043 CANCELLED AT 2024-03-01T16:48:09 DUE TO TIME LIMIT ***\nJob 1606063 has finished with state: JobState=TIMEOUT\nSlurm job (1606063) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1606063      fc_model_+    TIMEOUT      0:0            2024-03-01T15:47:55 2024-03-01T16:48:09 \n1606063.bat+      batch  CANCELLED     0:15    618464K 2024-03-01T15:47:55 2024-03-01T16:48:10 \n1606063.ext+     extern  COMPLETED      0:0          0 2024-03-01T15:47:55 2024-03-01T16:48:09 \nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1709326073818,
  "history_end_time" : 1709329692542,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "tTyqJO1lmZdv",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nfrom datetime import datetime, timedelta\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  \n\n  # Start date\n  start_date = datetime(2020, 7, 16)\n\n  # End date\n  end_date = datetime(2020, 10, 30)\n\n  # Define the step size for traversal\n  step = timedelta(days=1)\n  \n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells/\"\n\n  # Traverse the dates\n  current_date = start_date\n  while current_date <= end_date:\n      print(\"Preparing for date : \", current_date.strftime('%Y%m%d'))  # Print date in YYYYMMDD format\n      current_date += step\n      training_end_date = current_date.strftime('%Y%m%d')\n      #training_end_date = \"20201030\" # the last day of the 7 day history\n      prepare_training_data(training_end_date, training_data_folder)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/tTyqJO1lmZdv\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1606061\n/home/zsun/gw-workspace/tTyqJO1lmZdv/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-tTyqJO1lmZdv.sh: line 79: : No such file or directory\n/home/zsun/gw-workspace/tTyqJO1lmZdv/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-tTyqJO1lmZdv.sh: line 83: : No such file or directory\n/home/zsun/gw-workspace/tTyqJO1lmZdv/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-tTyqJO1lmZdv.sh: line 83: : No such file or directory\n/home/zsun/gw-workspace/tTyqJO1lmZdv/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-tTyqJO1lmZdv.sh: line 83: : No such file or directory\n/home/zsun/gw-workspace/tTyqJO1lmZdv/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-tTyqJO1lmZdv.sh: line 83: : No such file or directory\n1c1,16\n< \n---\n> Preparing for date :  20200716\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200717_time_series_with_window.csv exists\n> Preparing for date :  20200717\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200718_time_series_with_window.csv exists\n> Preparing for date :  20200718\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200719_time_series_with_window.csv exists\n> Preparing for date :  20200719\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200720_time_series_with_window.csv exists\n16a17,60\n> Preparing for date :  20200720\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200721_time_series_with_window.csv exists\n> Preparing for date :  20200721\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200722_time_series_with_window.csv exists\n> Preparing for date :  20200722\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200723_time_series_with_window.csv exists\n> Preparing for date :  20200723\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200724_time_series_with_window.csv exists\n> Preparing for date :  20200724\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200725_time_series_with_window.csv exists\n> Preparing for date :  20200725\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200726_time_series_with_window.csv exists\n> Preparing for date :  20200726\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200727_time_series_with_window.csv exists\n> Preparing for date :  20200727\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200728_time_series_with_window.csv exists\n> Preparing for date :  20200728\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200729_time_series_with_window.csv exists\n> Preparing for date :  20200729\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200730_time_series_with_window.csv exists\n> Preparing for date :  20200730\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200731_time_series_with_window.csv exists\n60a61,95\n> Preparing for date :  20200731\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File does not exist\n> preparing training data for  20200801\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200731\n> preparing data for past date 20200730\n> preparing data for past date 20200729\n> preparing data for past date 20200728\n> preparing data for past date 20200727\n> preparing data for past date 20200726\n> preparing data for past date 20200725\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n",
  "history_begin_time" : 1709325958871,
  "history_end_time" : 1709326060427,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "ToqyjpHIzPxJ",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  training_end_date = \"20201030\" # the last day of the 7 day history\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells/\"\n  prepare_training_data(training_end_date, training_data_folder)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/ToqyjpHIzPxJ\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1606057\n/home/zsun/gw-workspace/ToqyjpHIzPxJ/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-ToqyjpHIzPxJ.sh: line 59: : No such file or directory\n/home/zsun/gw-workspace/ToqyjpHIzPxJ/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-ToqyjpHIzPxJ.sh: line 63: : No such file or directory\n/home/zsun/gw-workspace/ToqyjpHIzPxJ/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-ToqyjpHIzPxJ.sh: line 63: : No such file or directory\n/home/zsun/gw-workspace/ToqyjpHIzPxJ/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-ToqyjpHIzPxJ.sh: line 63: : No such file or directory\n/home/zsun/gw-workspace/ToqyjpHIzPxJ/gw-T4Jwr2KJ0wkGJn3MsEMawzIB5E-ToqyjpHIzPxJ.sh: line 63: : No such file or directory\n1c1,4\n< \n---\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File does not exist\n> preparing training data for  20201030\n4a5,34\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20201029\n> preparing data for past date 20201028\n> preparing data for past date 20201027\n> preparing data for past date 20201026\n> preparing data for past date 20201025\n> preparing data for past date 20201024\n> preparing data for past date 20201023\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n",
  "history_begin_time" : 1709325709350,
  "history_end_time" : 1709325951288,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "9MYhIFv4Oq7p",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  training_end_date = \"20200715\" # the last day of the 7 day history\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells/\"\n  prepare_training_data(training_end_date, training_data_folder)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/9MYhIFv4Oq7p\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1449440\n/home/zsun/gw-workspace/9MYhIFv4Oq7p/gw-TGSXqM1xDyUpgmWBHAP4KZQ0EE-9MYhIFv4Oq7p.sh: line 59: : No such file or directory\n/home/zsun/gw-workspace/9MYhIFv4Oq7p/gw-TGSXqM1xDyUpgmWBHAP4KZQ0EE-9MYhIFv4Oq7p.sh: line 63: : No such file or directory\n/home/zsun/gw-workspace/9MYhIFv4Oq7p/gw-TGSXqM1xDyUpgmWBHAP4KZQ0EE-9MYhIFv4Oq7p.sh: line 63: : No such file or directory\n/home/zsun/gw-workspace/9MYhIFv4Oq7p/gw-TGSXqM1xDyUpgmWBHAP4KZQ0EE-9MYhIFv4Oq7p.sh: line 63: : No such file or directory\n/home/zsun/gw-workspace/9MYhIFv4Oq7p/gw-TGSXqM1xDyUpgmWBHAP4KZQ0EE-9MYhIFv4Oq7p.sh: line 63: : No such file or directory\n1c1,3\n< \n---\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File /groups/ESS3/zsun/firecasting/data/train/all_cells//20200715_time_series_with_window.csv exists\nJob 1449440 has finished with state: JobState=COMPLETED\nSlurm job (1449440) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1449440      fc_model_+  COMPLETED      0:0            2024-01-20T20:46:39 2024-01-20T20:47:14 \n1449440.bat+      batch  COMPLETED      0:0          0 2024-01-20T20:46:39 2024-01-20T20:47:14 \n1449440.ext+     extern  COMPLETED      0:0          0 2024-01-20T20:46:39 2024-01-20T20:47:14 \nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1705801597947,
  "history_end_time" : 1705801639199,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "6RrzXHTBMtto",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython -u << INNER_EOF\n\nfrom fc_train_data_preprocess import prepare_training_data\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  training_end_date = \"20200715\" # the last day of the 7 day history\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells/\"\n  prepare_training_data(training_end_date, training_data_folder)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nfile_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\nprevious_content=$(<\"${file_name}\")\nwhile true; do\n    # Capture the current content\n    file_name=$(find /scratch/zsun -name '*'${job_id}'.out' -print -quit)\n    current_content=$(<\"${file_name}\")\n\n    # Compare current content with previous content\n    diff_result=$(diff <(echo \"$previous_content\") <(echo \"$current_content\"))\n    # Check if there is new content\n    if [ -n \"$diff_result\" ]; then\n        echo \"$diff_result\"\n    fi\n    # Update previous content\n    previous_content=\"$current_content\"\n\n\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\n#find /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/6RrzXHTBMtto\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1449432\n/home/zsun/gw-workspace/6RrzXHTBMtto/gw-TGSXqM1xDyUpgmWBHAP4KZQ0EE-6RrzXHTBMtto.sh: line 59: : No such file or directory\n/home/zsun/gw-workspace/6RrzXHTBMtto/gw-TGSXqM1xDyUpgmWBHAP4KZQ0EE-6RrzXHTBMtto.sh: line 63: : No such file or directory\n/home/zsun/gw-workspace/6RrzXHTBMtto/gw-TGSXqM1xDyUpgmWBHAP4KZQ0EE-6RrzXHTBMtto.sh: line 63: : No such file or directory\n/home/zsun/gw-workspace/6RrzXHTBMtto/gw-TGSXqM1xDyUpgmWBHAP4KZQ0EE-6RrzXHTBMtto.sh: line 63: : No such file or directory\n/home/zsun/gw-workspace/6RrzXHTBMtto/gw-TGSXqM1xDyUpgmWBHAP4KZQ0EE-6RrzXHTBMtto.sh: line 63: : No such file or directory\n1c1,4\n< \n---\n> The file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\n> Folder created: /groups/ESS3/zsun/firecasting/data/train/all_cells/\n> File does not exist\n> preparing training data for  20200715\n4a5,34\n> Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n>        'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n>        'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n>        'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n>        'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> preparing data for past date 20200714\n> preparing data for past date 20200713\n> preparing data for past date 20200712\n> preparing data for past date 20200711\n> preparing data for past date 20200710\n> preparing data for past date 20200709\n> preparing data for past date 20200708\n>     LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n> 0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n> 1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n> 2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n> 3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n> 4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n> \n> [5 rows x 22 columns]\n> nearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n>        'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n>        'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n>        'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n>        'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> df.shape:  (156861, 22)\n> df.iloc[100] =  0.0\n> nearest_columns length:  24\n34a35,55\n> new_df.shape =  (156861, 24)\n> df.shape =  (156861, 22)\n> New time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n> 0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n> 1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n> 2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n> 3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n> 4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n> \n> [5 rows x 46 columns]\n> all feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n>        ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n>        ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n>        ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n>        'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n>        'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n>        'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n>        'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n>        'Nearest_22', 'Nearest_23', 'Nearest_24'],\n>       dtype='object')\n> drop rows where the previous day has no fire on that pixel\nJob 1449432 has finished with state: JobState=COMPLETED\nSlurm job (1449432) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1449432      fc_model_+  COMPLETED      0:0            2024-01-20T20:40:38 2024-01-20T20:44:38 \n1449432.bat+      batch  COMPLETED      0:0    410892K 2024-01-20T20:40:38 2024-01-20T20:44:38 \n1449432.ext+     extern  COMPLETED      0:0          0 2024-01-20T20:40:38 2024-01-20T20:44:38 \nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1705801236966,
  "history_end_time" : 1705801488749,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "sNzjT0V0Q9Zl",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom data_preparation_utils import create_grid_to_window_mapper\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  # From now on, `target_day` will be Day_0. \n  # So remember to change all the `Dayx` columents to `FRP_{i+1}_days_ago` \n  # to eliminate the confusion. \n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(\"preparing data for past date\", past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_{i+1}_days_ago'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP_1_days_ago\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(train_file_path):\n    print(f\"File {train_file_path} exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n    \n    print(\"all feature names: \", df.columns)\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    print(\"drop rows where the previous day has no fire on that pixel\")\n    df = df[df[' FRP'] != 0]\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  training_end_date = \"20200715\" # the last day of the 7 day history\n  prepare_training_data(training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/sNzjT0V0Q9Zl\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/sNzjT0V0Q9Zl/gw-hd31SON6toc7MsQzG5ISLVbGxX-sNzjT0V0Q9Zl.sh: line 15: target_day: command not found\n/home/zsun/gw-workspace/sNzjT0V0Q9Zl/gw-hd31SON6toc7MsQzG5ISLVbGxX-sNzjT0V0Q9Zl.sh: line 15: Dayx: command not found\n/home/zsun/gw-workspace/sNzjT0V0Q9Zl/gw-hd31SON6toc7MsQzG5ISLVbGxX-sNzjT0V0Q9Zl.sh: line 15: FRP_{i+1}_days_ago: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1415523\nJob 1415523 has finished with state: JobState=COMPLETED\nSlurm job (1415523) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1415523                             fc_model_data_preprocessing  COMPLETED      0:0            2024-01-12T16:24:36 2024-01-12T16:28:23 \n1415523.bat+                                              batch  COMPLETED      0:0    469780K 2024-01-12T16:24:36 2024-01-12T16:28:23 \n1415523.ext+                                             extern  COMPLETED      0:0          0 2024-01-12T16:24:36 2024-01-12T16:28:23 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFile does not exist\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\npreparing data for past date 20200714\npreparing data for past date 20200713\npreparing data for past date 20200712\npreparing data for past date 20200711\npreparing data for past date 20200710\npreparing data for past date 20200709\npreparing data for past date 20200708\n    LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n[5 rows x 22 columns]\nnearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ndf.shape:  (156861, 22)\ndf.iloc[100] =  0.0\nnearest_columns length:  24\nnew_df.shape =  (156861, 24)\ndf.shape =  (156861, 22)\nNew time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n[5 rows x 46 columns]\nall feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago', 'Nearest_1',\n       'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6',\n       'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10', 'Nearest_11',\n       'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15', 'Nearest_16',\n       'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20', 'Nearest_21',\n       'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ndrop rows where the previous day has no fire on that pixel\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1705094675059,
  "history_end_time" : 1705094906572,
  "history_notes" : "this works with all the neighbor pixels are from yesterday",
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "7Dfk7loHrDbM",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom data_preparation_utils import create_grid_to_window_mapper\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  # From now on, `target_day` will be Day_0. \n  # So remember to change all the `Dayx` columents to `FRP_{i+1}_days_ago` \n  # to eliminate the confusion. \n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(\"preparing data for past date\", past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_{i+1}_days_ago'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP_1_days_ago\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(train_file_path):\n    print(f\"File {train_file_path} exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  training_end_date = \"20200715\" # the last day of the 7 day history\n  prepare_training_data(training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/7Dfk7loHrDbM\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/7Dfk7loHrDbM/gw-hd31SON6toc7MsQzG5ISLVbGxX-7Dfk7loHrDbM.sh: line 15: target_day: command not found\n/home/zsun/gw-workspace/7Dfk7loHrDbM/gw-hd31SON6toc7MsQzG5ISLVbGxX-7Dfk7loHrDbM.sh: line 15: Dayx: command not found\n/home/zsun/gw-workspace/7Dfk7loHrDbM/gw-hd31SON6toc7MsQzG5ISLVbGxX-7Dfk7loHrDbM.sh: line 15: FRP_{i+1}_days_ago: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1415494\nJob 1415494 has finished with state: JobState=FAILED\nSlurm job (1415494) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1415494                             fc_model_data_preprocessing     FAILED      1:0            2024-01-12T16:17:30 2024-01-12T16:21:23 \n1415494.bat+                                              batch     FAILED      1:0    417884K 2024-01-12T16:17:30 2024-01-12T16:21:23 \n1415494.ext+                                             extern  COMPLETED      0:0          0 2024-01-12T16:17:30 2024-01-12T16:21:23 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFile does not exist\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\npreparing data for past date 20200714\npreparing data for past date 20200713\npreparing data for past date 20200712\npreparing data for past date 20200711\npreparing data for past date 20200710\npreparing data for past date 20200709\npreparing data for past date 20200708\n    LAT         LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n0  24.5 -126.000000   0.0  ...              0.0              0.0              0.0\n1  24.5 -125.899994   0.0  ...              0.0              0.0              0.0\n2  24.5 -125.800003   0.0  ...              0.0              0.0              0.0\n3  24.5 -125.699997   0.0  ...              0.0              0.0              0.0\n4  24.5 -125.599998   0.0  ...              0.0              0.0              0.0\n[5 rows x 22 columns]\nnearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ndf.shape:  (156861, 22)\ndf.iloc[100] =  0.0\nnearest_columns length:  24\nnew_df.shape =  (156861, 24)\ndf.shape =  (156861, 22)\nNew time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n[5 rows x 46 columns]\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: ' FRP_day0'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"<stdin>\", line 160, in <module>\n  File \"<stdin>\", line 144, in prepare_training_data\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3505, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: ' FRP_day0'\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1705094249015,
  "history_end_time" : 1705094490556,
  "history_notes" : "start working here. history of 7 days and neighbor grid cell using yesterday's value are working here. Next process will fix the issue in there.",
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "3KG1Eaq8SJFZ",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom data_preparation_utils import create_grid_to_window_mapper\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  # From now on, `target_day` will be Day_0. \n  # So remember to change all the `Dayx` columents to `FRP_{i+1}_days_ago` \n  # to eliminate the confusion. \n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(\"preparing data for past date\", past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_{i+1}_days_ago'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP_1_days_ago\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(train_file_path):\n    print(f\"File {train_file_path} exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  training_end_date = \"20200715\" # the last day of the 7 day history\n  prepare_training_data(training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/3KG1Eaq8SJFZ\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/3KG1Eaq8SJFZ/gw-hd31SON6toc7MsQzG5ISLVbGxX-3KG1Eaq8SJFZ.sh: line 15: target_day: command not found\n/home/zsun/gw-workspace/3KG1Eaq8SJFZ/gw-hd31SON6toc7MsQzG5ISLVbGxX-3KG1Eaq8SJFZ.sh: line 15: Dayx: command not found\n/home/zsun/gw-workspace/3KG1Eaq8SJFZ/gw-hd31SON6toc7MsQzG5ISLVbGxX-3KG1Eaq8SJFZ.sh: line 15: FRP_{i+1}_days_ago: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1415493\nJob 1415493 has finished with state: JobState=COMPLETED\nSlurm job (1415493) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1415493                             fc_model_data_preprocessing  COMPLETED      0:0            2024-01-12T16:16:03 2024-01-12T16:16:36 \n1415493.bat+                                              batch  COMPLETED      0:0       132K 2024-01-12T16:16:03 2024-01-12T16:16:36 \n1415493.ext+                                             extern  COMPLETED      0:0          0 2024-01-12T16:16:03 2024-01-12T16:16:36 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFile /groups/ESS3/zsun/firecasting/data/train//20200715_time_series_with_window.csv exists\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1705094162183,
  "history_end_time" : 1705094203404,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "L7gUS7gNIrbi",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom data_preparation_utils import create_grid_to_window_mapper\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  # From now on, `target_day` will be Day_0. \n  # So remember to change all the `Dayx` columents to `FRP_{i+1}_days_ago` \n  # to eliminate the confusion. \n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(\"preparing data for past date\", past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_{i+1}_days_ago'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP_1_days_ago\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(train_file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  training_end_date = \"20200715\" # the last day of the 7 day history\n  prepare_training_data(training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/L7gUS7gNIrbi\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/L7gUS7gNIrbi/gw-hd31SON6toc7MsQzG5ISLVbGxX-L7gUS7gNIrbi.sh: line 15: target_day: command not found\n/home/zsun/gw-workspace/L7gUS7gNIrbi/gw-hd31SON6toc7MsQzG5ISLVbGxX-L7gUS7gNIrbi.sh: line 15: Dayx: command not found\n/home/zsun/gw-workspace/L7gUS7gNIrbi/gw-hd31SON6toc7MsQzG5ISLVbGxX-L7gUS7gNIrbi.sh: line 15: FRP_{i+1}_days_ago: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1415491\nJob 1415491 has finished with state: JobState=COMPLETED\nSlurm job (1415491) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1415491                             fc_model_data_preprocessing  COMPLETED      0:0            2024-01-12T16:14:58 2024-01-12T16:15:31 \n1415491.bat+                                              batch  COMPLETED      0:0          0 2024-01-12T16:14:58 2024-01-12T16:15:31 \n1415491.ext+                                             extern  COMPLETED      0:0          0 2024-01-12T16:14:58 2024-01-12T16:15:31 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFile exists\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1705094096222,
  "history_end_time" : 1705094137449,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "d6wiP5TWiRDn",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom data_preparation_utils import create_grid_to_window_mapper\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  # From now on, `target_day` will be Day_0. \n  # So remember to change all the `Dayx` columents to `FRP_{i+1}_days_ago` \n  # to eliminate the confusion. \n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(\"preparing data for past date\", past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_{i+1}_days_ago'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP_1_days_ago\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(train_file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  training_end_date = \"20200715\" # the last day of the 7 day history\n  prepare_training_data(training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/d6wiP5TWiRDn\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/d6wiP5TWiRDn/gw-hd31SON6toc7MsQzG5ISLVbGxX-d6wiP5TWiRDn.sh: line 15: target_day: command not found\n/home/zsun/gw-workspace/d6wiP5TWiRDn/gw-hd31SON6toc7MsQzG5ISLVbGxX-d6wiP5TWiRDn.sh: line 15: Dayx: command not found\n/home/zsun/gw-workspace/d6wiP5TWiRDn/gw-hd31SON6toc7MsQzG5ISLVbGxX-d6wiP5TWiRDn.sh: line 15: FRP_{i+1}_days_ago: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1415488\nJob 1415488 has finished with state: JobState=FAILED\nSlurm job (1415488) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1415488                             fc_model_data_preprocessing     FAILED      1:0            2024-01-12T16:13:45 2024-01-12T16:14:18 \n1415488.bat+                                              batch     FAILED      1:0       264K 2024-01-12T16:13:45 2024-01-12T16:14:18 \n1415488.ext+                                             extern  COMPLETED      0:0          0 2024-01-12T16:13:45 2024-01-12T16:14:18 \nTraceback (most recent call last):\n  File \"<stdin>\", line 160, in <module>\n  File \"<stdin>\", line 120, in prepare_training_data\n  File \"/home/zsun/gw-workspace/d6wiP5TWiRDn/data_preparation_utils.py\", line 11, in create_grid_to_window_mapper\n    if os.path.exists(grid_to_window_mapper_csv):\nNameError: name 'os' is not defined\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1705094023919,
  "history_end_time" : 1705094065133,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "qLRtsECOdNtS",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom data_preparation_utils import create_grid_to_window_mapper\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  # From now on, `target_day` will be Day_0. \n  # So remember to change all the `Dayx` columents to `FRP_{i+1}_days_ago` \n  # to eliminate the confusion. \n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(\"preparing data for past date\", past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_{i+1}_days_ago'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP_1_days_ago\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(train_file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  # this is today, and we want to use all the meteo data of today and FRP data of day -7 - yesterday to predict today's FRP. \n  training_end_date = \"20200715\" # the last day of the 7 day history\n  prepare_training_data(training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/qLRtsECOdNtS\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/qLRtsECOdNtS/gw-hd31SON6toc7MsQzG5ISLVbGxX-qLRtsECOdNtS.sh: line 15: target_day: command not found\n/home/zsun/gw-workspace/qLRtsECOdNtS/gw-hd31SON6toc7MsQzG5ISLVbGxX-qLRtsECOdNtS.sh: line 15: Dayx: command not found\n/home/zsun/gw-workspace/qLRtsECOdNtS/gw-hd31SON6toc7MsQzG5ISLVbGxX-qLRtsECOdNtS.sh: line 15: FRP_{i+1}_days_ago: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1415484\nJob 1415484 has finished with state: JobState=FAILED\nSlurm job (1415484) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1415484                             fc_model_data_preprocessing     FAILED      1:0            2024-01-12T16:12:23 2024-01-12T16:12:57 \n1415484.bat+                                              batch     FAILED      1:0          0 2024-01-12T16:12:23 2024-01-12T16:12:57 \n1415484.ext+                                             extern  COMPLETED      0:0          0 2024-01-12T16:12:23 2024-01-12T16:12:57 \nTraceback (most recent call last):\n  File \"<stdin>\", line 8, in <module>\n  File \"/home/zsun/gw-workspace/qLRtsECOdNtS/data_preparation_utils.py\", line 5, in <module>\n    def create_grid_to_window_mapper(the_folder_path = folder_path):\nNameError: name 'folder_path' is not defined\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1705093940839,
  "history_end_time" : 1705093982258,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "0WwdZL18ZnLn",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(train_file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  training_end_date = \"20200715\" # the last day of the 7 day history\n  prepare_training_data(training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/0WwdZL18ZnLn\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1415449\nJob 1415449 has finished with state: JobState=COMPLETED\nSlurm job (1415449) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1415449                             fc_model_data_preprocessing  COMPLETED      0:0            2024-01-12T15:59:23 2024-01-12T15:59:56 \n1415449.bat+                                              batch  COMPLETED      0:0          0 2024-01-12T15:59:23 2024-01-12T15:59:56 \n1415449.ext+                                             extern  COMPLETED      0:0          0 2024-01-12T15:59:23 2024-01-12T15:59:56 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFile exists\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1705093161396,
  "history_end_time" : 1705093202623,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "LupGTvtvDHZn",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  training_end_date = \"20200715\" # the last day of the 7 day history\n  prepare_training_data(training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/LupGTvtvDHZn\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1415430\nJob 1415430 has finished with state: JobState=FAILED\nSlurm job (1415430) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1415430                             fc_model_data_preprocessing     FAILED      1:0            2024-01-12T15:53:52 2024-01-12T15:54:25 \n1415430.bat+                                              batch     FAILED      1:0       132K 2024-01-12T15:53:52 2024-01-12T15:54:25 \n1415430.ext+                                             extern  COMPLETED      0:0          0 2024-01-12T15:53:52 2024-01-12T15:54:26 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nTraceback (most recent call last):\n  File \"<stdin>\", line 215, in <module>\n  File \"<stdin>\", line 122, in prepare_training_data\nNameError: name 'file_path' is not defined\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1705092831151,
  "history_end_time" : 1705092872369,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "OdfES1DIi0lC",
  "history_input" : "#!/bin/bash\n\n# This file is dedicated to prepare the training data.\n\n# 1) we need a complete rewrite of this process.\n# 2) separate the training data preparation and testing data preparation.\n# 3) All the share functions should go to the util process. \n\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  prepare_training_data(training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/OdfES1DIi0lC\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1415421\nJob 1415421 has finished with state: JobState=FAILED\nSlurm job (1415421) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1415421                             fc_model_data_preprocessing     FAILED      1:0            2024-01-12T15:51:50 2024-01-12T15:52:23 \n1415421.bat+                                              batch     FAILED      1:0       212K 2024-01-12T15:51:50 2024-01-12T15:52:23 \n1415421.ext+                                             extern  COMPLETED      0:0          0 2024-01-12T15:51:50 2024-01-12T15:52:23 \nTraceback (most recent call last):\n  File \"<stdin>\", line 215, in <module>\nNameError: name 'training_end_date' is not defined\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1705092708294,
  "history_end_time" : 1705092749513,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "M3afUswAMA3D",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(\n  target_day, \n  current_start_day, \n  current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210715\", \"20210714\", output_folder_full_path)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run fc_model_predict_2weeks.sh\n/home/zsun/gw-workspace/gszcWNFt7DVV\nwrite the slurm script into fc_model_predict_2weeks_slurm_generated.sh\nsbatch fc_model_predict_2weeks_slurm_generated.sh\njob_id=1386656\nJob 1386656 has finished with state: JobState=COMPLETED\n\nStream closed",
  "history_begin_time" : 1704491129409,
  "history_end_time" : 1704502116144,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "My4Wv5gvOoMn",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(\n  target_day, \n  current_start_day, \n  current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210715\", \"20210714\", output_folder_full_path)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/My4Wv5gvOoMn\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/My4Wv5gvOoMn/gw-QjjHw6qxYWqePyv7ggC3YtjR8m-My4Wv5gvOoMn.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1386666\nJob 1386666 has finished with state: JobState=FAILED\nSlurm job (1386666) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1386666                             fc_model_data_preprocessing     FAILED      1:0            2024-01-05T16:42:55 2024-01-05T16:43:26 \n1386666.bat+                                              batch     FAILED      1:0          0 2024-01-05T16:42:55 2024-01-05T16:43:26 \n1386666.ext+                                             extern  COMPLETED      0:0          0 2024-01-05T16:42:55 2024-01-05T16:43:26 \nRead from original folder for current date: 20210715\ncurrent_start_dt is: 2021-07-14 00:00:00\nreading past files for 2021-07-14 00:00:00\nreading from predicted folder\nTraceback (most recent call last):\n  File \"<stdin>\", line 321, in <module>\n  File \"<stdin>\", line 187, in prepare_testing_data_for_2_weeks_forecasting\n  File \"<stdin>\", line 159, in get_one_day_time_series_for_2_weeks_testing_data\n  File \"<stdin>\", line 58, in read_txt_from_predicted_folder\nValueError: File /groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/firedata_20210714_predicted.txt does not exist.\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1704490973844,
  "history_end_time" : 1704491015063,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "7YmK4mdeeKKO",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(\n  target_day, \n  current_start_day, \n  current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/7YmK4mdeeKKO\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/7YmK4mdeeKKO/gw-QjjHw6qxYWqePyv7ggC3YtjR8m-7YmK4mdeeKKO.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1386664\nJob 1386664 has finished with state: JobState=COMPLETED\nSlurm job (1386664) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1386664                             fc_model_data_preprocessing  COMPLETED      0:0            2024-01-05T16:41:28 2024-01-05T16:42:01 \n1386664.bat+                                              batch  COMPLETED      0:0       144K 2024-01-05T16:41:28 2024-01-05T16:42:01 \n1386664.ext+                                             extern  COMPLETED      0:0          0 2024-01-05T16:41:28 2024-01-05T16:42:01 \nRead from original folder for current date: 20210714\ncurrent_start_dt is: 2021-07-14 00:00:00\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1704490886829,
  "history_end_time" : 1704490928040,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "zQZszF4Ira9j",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(\n  target_day, \n  current_start_day, \n  current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210715\", \"20210714\", output_folder_full_path)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/zQZszF4Ira9j\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/zQZszF4Ira9j/gw-QjjHw6qxYWqePyv7ggC3YtjR8m-zQZszF4Ira9j.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1386659\nJob 1386659 has finished with state: JobState=FAILED\nSlurm job (1386659) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1386659                             fc_model_data_preprocessing     FAILED      1:0            2024-01-05T16:38:49 2024-01-05T16:39:21 \n1386659.bat+                                              batch     FAILED      1:0          0 2024-01-05T16:38:49 2024-01-05T16:39:21 \n1386659.ext+                                             extern  COMPLETED      0:0          0 2024-01-05T16:38:49 2024-01-05T16:39:21 \nRead from original folder for current date: 20210715\ncurrent_start_dt is: 2021-07-14 00:00:00\nreading past files for 2021-07-14 00:00:00\nreading from predicted folder\nTraceback (most recent call last):\n  File \"<stdin>\", line 321, in <module>\n  File \"<stdin>\", line 187, in prepare_testing_data_for_2_weeks_forecasting\n  File \"<stdin>\", line 159, in get_one_day_time_series_for_2_weeks_testing_data\n  File \"<stdin>\", line 58, in read_txt_from_predicted_folder\nValueError: File /groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/firedata_20210714_predicted.txt does not exist.\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1704490728042,
  "history_end_time" : 1704490769266,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "LvWwTYEOqE75",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(\n  target_day, \n  current_start_day, \n  current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210718\", \"20210714\", output_folder_full_path)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/LvWwTYEOqE75\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/LvWwTYEOqE75/gw-QjjHw6qxYWqePyv7ggC3YtjR8m-LvWwTYEOqE75.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1386631\nJob 1386631 has finished with state: JobState=FAILED\nSlurm job (1386631) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1386631                             fc_model_data_preprocessing     FAILED      1:0            2024-01-05T16:16:05 2024-01-05T16:16:37 \n1386631.bat+                                              batch     FAILED      1:0        84K 2024-01-05T16:16:05 2024-01-05T16:16:37 \n1386631.ext+                                             extern  COMPLETED      0:0          0 2024-01-05T16:16:05 2024-01-05T16:16:37 \nRead from original folder for current date: 20210718\ncurrent_start_dt is: 2021-07-14 00:00:00\nreading past files for 2021-07-17 00:00:00\nreading from predicted folder\nTraceback (most recent call last):\n  File \"<stdin>\", line 321, in <module>\n  File \"<stdin>\", line 187, in prepare_testing_data_for_2_weeks_forecasting\n  File \"<stdin>\", line 159, in get_one_day_time_series_for_2_weeks_testing_data\n  File \"<stdin>\", line 58, in read_txt_from_predicted_folder\nValueError: File /groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/firedata_20210717_predicted.txt does not exist.\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1704489363949,
  "history_end_time" : 1704489405176,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "xXFqOnTFs7xB",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(\n  target_day, \n  current_start_day, \n  current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/2022-07-18/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210718\", \"20210714\", output_folder_full_path)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/xXFqOnTFs7xB\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/xXFqOnTFs7xB/gw-QjjHw6qxYWqePyv7ggC3YtjR8m-xXFqOnTFs7xB.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1386628\nJob 1386628 has finished with state: JobState=FAILED\nSlurm job (1386628) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1386628                             fc_model_data_preprocessing     FAILED      1:0            2024-01-05T16:13:21 2024-01-05T16:13:56 \n1386628.bat+                                              batch     FAILED      1:0          0 2024-01-05T16:13:21 2024-01-05T16:13:56 \n1386628.ext+                                             extern  COMPLETED      0:0          0 2024-01-05T16:13:21 2024-01-05T16:13:56 \nRead from original folder for current date: 20210718\ncurrent_start_dt is: 2021-07-14 00:00:00\nreading past files for 2021-07-17 00:00:00\nreading from predicted folder\nTraceback (most recent call last):\n  File \"<stdin>\", line 321, in <module>\n  File \"<stdin>\", line 187, in prepare_testing_data_for_2_weeks_forecasting\n  File \"<stdin>\", line 159, in get_one_day_time_series_for_2_weeks_testing_data\n  File \"<stdin>\", line 58, in read_txt_from_predicted_folder\nValueError: File /groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/2022-07-18/firedata_20210717_predicted.txt does not exist.\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1704489199899,
  "history_end_time" : 1704489241132,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "uvBTN7XqsL8m",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(\n  target_day, \n  current_start_day, \n  current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/2022-07-18/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20220718\", \"20220714\", output_folder_full_path)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/uvBTN7XqsL8m\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/uvBTN7XqsL8m/gw-QjjHw6qxYWqePyv7ggC3YtjR8m-uvBTN7XqsL8m.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1386627\nJob 1386627 has finished with state: JobState=FAILED\nSlurm job (1386627) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1386627                             fc_model_data_preprocessing     FAILED      1:0            2024-01-05T16:11:54 2024-01-05T16:12:27 \n1386627.bat+                                              batch     FAILED      1:0       160K 2024-01-05T16:11:54 2024-01-05T16:12:27 \n1386627.ext+                                             extern  COMPLETED      0:0          0 2024-01-05T16:11:54 2024-01-05T16:12:27 \nRead from original folder for current date: 20220718\nTraceback (most recent call last):\n  File \"<stdin>\", line 321, in <module>\n  File \"<stdin>\", line 187, in prepare_testing_data_for_2_weeks_forecasting\n  File \"<stdin>\", line 150, in get_one_day_time_series_for_2_weeks_testing_data\n  File \"<stdin>\", line 32, in read_original_txt_files\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 575, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n    self.handles = get_handle(  # type: ignore[call-overload]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\", line 789, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20220718.txt'\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1704489113223,
  "history_end_time" : 1704489154446,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Z0apBUR89bgk",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(\n  target_day, \n  current_start_day, \n  current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n    df.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/2022-07-18/'\n  prepare_testing_data_for_2_weeks_forecasting(\"2022-07-18\", \"2022-07-14\", output_folder_full_path)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/Z0apBUR89bgk\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/Z0apBUR89bgk/gw-QjjHw6qxYWqePyv7ggC3YtjR8m-Z0apBUR89bgk.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1386626\nJob 1386626 has finished with state: JobState=FAILED\nSlurm job (1386626) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1386626                             fc_model_data_preprocessing     FAILED      1:0            2024-01-05T16:10:30 2024-01-05T16:11:03 \n1386626.bat+                                              batch     FAILED      1:0       164K 2024-01-05T16:10:30 2024-01-05T16:11:03 \n1386626.ext+                                             extern  COMPLETED      0:0          0 2024-01-05T16:10:30 2024-01-05T16:11:03 \nTraceback (most recent call last):\n  File \"<stdin>\", line 321, in <module>\n  File \"<stdin>\", line 187, in prepare_testing_data_for_2_weeks_forecasting\n  File \"<stdin>\", line 145, in get_one_day_time_series_for_2_weeks_testing_data\n  File \"/home/zsun/anaconda3/lib/python3.8/_strptime.py\", line 568, in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n  File \"/home/zsun/anaconda3/lib/python3.8/_strptime.py\", line 349, in _strptime\n    raise ValueError(\"time data %r does not match format %r\" %\nValueError: time data '2022-07-18' does not match format '%Y%m%d'\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1704489028577,
  "history_end_time" : 1704489069804,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "7ThSDf4TQ5ex",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  print(\"nearest_columns length: \", len(nearest_columns))\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(\n  target_day, \n  current_start_day, \n  current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  \n  train_file_path = f\"{training_data_folder}/{target_date}_time_series_with_window.csv\"\n  \n  if os.path.exists(file_path):\n    print(\"File exists\")\n    existing_df = pd.read_csv(train_file_path)\n    X = existing_df.drop([target_col], axis=1)\n    y = existing_df[target_col]\n  else:\n    print(\"File does not exist\")\n    original_df = get_one_day_time_series_training_data(target_date)\n    df = original_df\n\n    #print(\"Lag/Shift the data for previous days' information\")\n    num_previous_days = 7  # Adjust the number of previous days to consider\n\n    # Drop rows with NaN values from the shifted columns\n    df_filled = df.fillna(-9999)\n\n    # drop rows where the previous day has no fire on that pixel\n\n    df = df[df[' FRP_day0'] != 0]\n    print(\"all feature names: \", df.columns)\n\tdf.to_csv(train_file_path, index=False)\n    # Define features and target\n    X = df.drop([target_col], axis=1)\n    y = df[target_col]\n  \n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/2022-07-18/'\n  prepare_testing_data_for_2_weeks_forecasting(\"2022-07-18\", \"2022-07-14\", output_folder_full_path)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/7ThSDf4TQ5ex\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/7ThSDf4TQ5ex/gw-QjjHw6qxYWqePyv7ggC3YtjR8m-7ThSDf4TQ5ex.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1386625\nJob 1386625 has finished with state: JobState=FAILED\nSlurm job (1386625) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1386625                             fc_model_data_preprocessing     FAILED      1:0            2024-01-05T16:09:07 2024-01-05T16:09:38 \n1386625.bat+                                              batch     FAILED      1:0       108K 2024-01-05T16:09:07 2024-01-05T16:09:38 \n1386625.ext+                                             extern  COMPLETED      0:0          0 2024-01-05T16:09:07 2024-01-05T16:09:38 \n  File \"<stdin>\", line 246\n    df.to_csv(train_file_path, index=False)\n                                          ^\nTabError: inconsistent use of tabs and spaces in indentation\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1704488945898,
  "history_end_time" : 1704488987164,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "4wHkenhwpy7u",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(\"new_df.shape = \", new_df.shape)\n  print(\"df.shape = \", df.shape)\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/4wHkenhwpy7u\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/4wHkenhwpy7u/gw-LuUrzHe3JjcdWO05t1rZEFjDfW-4wHkenhwpy7u.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320506\nJob 1320506 has finished with state: JobState=COMPLETED\nSlurm job (1320506) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1320506                             fc_model_data_preprocessing  COMPLETED      0:0            2023-11-29T02:37:38 2023-11-29T02:41:25 \n1320506.bat+                                              batch  COMPLETED      0:0    439076K 2023-11-29T02:37:38 2023-11-29T02:41:25 \n1320506.ext+                                             extern  COMPLETED      0:0          0 2023-11-29T02:37:38 2023-11-29T02:41:25 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n20200714\n20200713\n20200712\n20200711\n20200710\n20200709\n20200708\n    LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nnearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ndf.shape:  (156861, 22)\ndf.iloc[100] =  0.0\nnew_df.shape =  (156861, 24)\ndf.shape =  (156861, 22)\nNew time series dataframe:      LAT         LON   FRP  ...  Nearest_22  Nearest_23  Nearest_24\n0  24.5 -126.000000   0.0  ...         0.0         0.0         0.0\n1  24.5 -125.899994   0.0  ...         0.0         0.0         0.0\n2  24.5 -125.800003   0.0  ...         0.0         0.0         0.0\n3  24.5 -125.699997   0.0  ...         0.0         0.0         0.0\n4  24.5 -125.599998   0.0  ...         0.0         0.0         0.0\n[5 rows x 46 columns]\nall feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6',\n       'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701243456445,
  "history_end_time" : 1701243688130,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "gwwZpzENgQAM",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return values\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(new_df.head())\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%100,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/gwwZpzENgQAM\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/gwwZpzENgQAM/gw-44OFrMI2VhCV0lnrvq4QCm94cO-gwwZpzENgQAM.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320504\nJob 1320504 has finished with state: JobState=CANCELLED\nSlurm job (1320504) has finished.\nPrint the job's output logs\nJobID                                                                                                     JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------------------------------------------------------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1320504                                                                               fc_model_data_preprocessing CANCELLED+      0:0            2023-11-29T02:29:26 2023-11-29T02:30:44 \n1320504.bat+                                                                                                batch  CANCELLED     0:15    228348K 2023-11-29T02:29:26 2023-11-29T02:30:45 \n1320504.ext+                                                                                               extern  COMPLETED      0:0          0 2023-11-29T02:29:26 2023-11-29T02:30:44 \nslurmstepd-hop043: error: *** JOB 1320504 ON hop043 CANCELLED AT 2023-11-29T02:30:44 ***\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701242965125,
  "history_end_time" : 1701243056637,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "V754NZn9wQjd",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        #print(\"column = \", column)\n        nearest_index = result[column]\n        #print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return values\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(new_df.head())\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%50,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/V754NZn9wQjd\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/V754NZn9wQjd/gw-LuUrzHe3JjcdWO05t1rZEFjDfW-V754NZn9wQjd.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320505\nJob 1320505 has finished with state: JobState=FAILED\nSlurm job (1320505) has finished.\nPrint the job's output logs\nJobID                                                   JobName      State ExitCode     MaxRSS               Start                 End \n------------ -------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1320505                             fc_model_data_preprocessing     FAILED      1:0            2023-11-29T02:29:35 2023-11-29T02:33:00 \n1320505.bat+                                              batch     FAILED      1:0    338452K 2023-11-29T02:29:35 2023-11-29T02:33:00 \n1320505.ext+                                             extern  COMPLETED      0:0          0 2023-11-29T02:29:35 2023-11-29T02:33:00 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n20200714\n20200713\n20200712\n20200711\n20200710\n20200709\n20200708\n    LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nnearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ndf.shape:  (156861, 22)\ndf.iloc[100] =  0.0\n0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n2    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n3    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n4    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\ndtype: object\nTraceback (most recent call last):\n  File \"<stdin>\", line 287, in <module>\n  File \"<stdin>\", line 203, in prepare_training_data\n  File \"<stdin>\", line 128, in get_one_day_time_series_training_data\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3643, in __setitem__\n    self._setitem_array(key, value)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3702, in _setitem_array\n    self._iset_not_inplace(key, value)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3721, in _iset_not_inplace\n    raise ValueError(\"Columns must be same length as key\")\nValueError: Columns must be same length as key\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701242841936,
  "history_end_time" : 1701243184878,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "to9qYVVcApHp",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        print(\"column = \", column)\n        nearest_index = result[column]\n        print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\" FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return values\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(new_df.head())\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%100,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/to9qYVVcApHp\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/to9qYVVcApHp/gw-44OFrMI2VhCV0lnrvq4QCm94cO-to9qYVVcApHp.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320501\n\nStream closed",
  "history_begin_time" : 1701242181455,
  "history_end_time" : 1701242961920,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "grpA11gmqH2v",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    nearest_columns = result\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        print(\"column = \", column)\n        nearest_index = nearest_columns[column]\n        print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\"FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return values\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(new_df.head())\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%100,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/grpA11gmqH2v\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/grpA11gmqH2v/gw-44OFrMI2VhCV0lnrvq4QCm94cO-grpA11gmqH2v.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320500\nJob 1320500 has finished with state: JobState=FAILED\nSlurm job (1320500) has finished.\nPrint the job's output logs\nJobID                                                                                                     JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------------------------------------------------------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1320500                                                                               fc_model_data_preprocessing     FAILED      1:0            2023-11-29T02:15:03 2023-11-29T02:15:39 \n1320500.bat+                                                                                                batch     FAILED      1:0          0 2023-11-29T02:15:03 2023-11-29T02:15:39 \n1320500.ext+                                                                                               extern  COMPLETED      0:0          0 2023-11-29T02:15:03 2023-11-29T02:15:39 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n20200714\n20200713\n20200712\n20200711\n20200710\n20200709\n20200708\n    LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nnearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ndf.shape:  (156861, 22)\ndf.iloc[100] =  0.0\ncolumn =  Nearest_1\nnearest_index =  601\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'FRP'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"<stdin>\", line 288, in <module>\n  File \"<stdin>\", line 204, in prepare_training_data\n  File \"<stdin>\", line 127, in get_one_day_time_series_training_data\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"<stdin>\", line 119, in add_window_grid_cells\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\", line 958, in __getitem__\n    return self._get_value(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\", line 1069, in _get_value\n    loc = self.index.get_loc(label)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 'FRP'\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701242102259,
  "history_end_time" : 1701242143518,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Chzaj67xq1jq",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    nearest_columns = result\n    values = []\n    for column in nearest_columns:\n        print(\"column = \", column)\n        nearest_index = nearest_columns[column]\n        print(\"nearest_index = \", nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\"FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return values\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(new_df.head())\n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%100,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/Chzaj67xq1jq\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/Chzaj67xq1jq/gw-44OFrMI2VhCV0lnrvq4QCm94cO-Chzaj67xq1jq.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320499\nJob 1320499 has finished with state: JobState=FAILED\nSlurm job (1320499) has finished.\nPrint the job's output logs\nJobID                                                                                                     JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------------------------------------------------------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1320499                                                                               fc_model_data_preprocessing     FAILED      1:0            2023-11-29T02:12:41 2023-11-29T02:13:16 \n1320499.bat+                                                                                                batch     FAILED      1:0          0 2023-11-29T02:12:41 2023-11-29T02:13:16 \n1320499.ext+                                                                                               extern  COMPLETED      0:0          0 2023-11-29T02:12:41 2023-11-29T02:13:16 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n20200714\n20200713\n20200712\n20200711\n20200710\n20200709\n20200708\n    LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nnearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ndf.shape:  (156861, 22)\ndf.iloc[100] =  0.0\ncolumn =  601\nTraceback (most recent call last):\n  File \"<stdin>\", line 288, in <module>\n  File \"<stdin>\", line 204, in prepare_training_data\n  File \"<stdin>\", line 127, in get_one_day_time_series_training_data\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"<stdin>\", line 116, in add_window_grid_cells\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\", line 955, in __getitem__\n    return self._values[key]\nIndexError: index 601 is out of bounds for axis 0 with size 24\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701241960608,
  "history_end_time" : 1701242001863,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "DWP56hwzVSFF",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    nearest_columns = result\n    values = []\n    for column in nearest_columns:\n        nearest_index = nearest_columns[column]\n        print(nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\"FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return values\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  \n  df[nearest_columns] = new_df\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%100,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/DWP56hwzVSFF\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/DWP56hwzVSFF/gw-44OFrMI2VhCV0lnrvq4QCm94cO-DWP56hwzVSFF.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320498\nJob 1320498 has finished with state: JobState=FAILED\nSlurm job (1320498) has finished.\nPrint the job's output logs\nJobID                                                                                                     JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------------------------------------------------------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1320498                                                                               fc_model_data_preprocessing     FAILED      1:0            2023-11-29T02:08:55 2023-11-29T02:09:30 \n1320498.bat+                                                                                                batch     FAILED      1:0          0 2023-11-29T02:08:55 2023-11-29T02:09:30 \n1320498.ext+                                                                                               extern  COMPLETED      0:0          0 2023-11-29T02:08:55 2023-11-29T02:09:30 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n20200714\n20200713\n20200712\n20200711\n20200710\n20200709\n20200708\n    LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nnearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ndf.shape:  (156861, 22)\ndf.iloc[100] =  0.0\nTraceback (most recent call last):\n  File \"<stdin>\", line 287, in <module>\n  File \"<stdin>\", line 203, in prepare_training_data\n  File \"<stdin>\", line 126, in get_one_day_time_series_training_data\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"<stdin>\", line 115, in add_window_grid_cells\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\", line 955, in __getitem__\n    return self._values[key]\nIndexError: index 601 is out of bounds for axis 0 with size 24\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701241734094,
  "history_end_time" : 1701241775343,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "M2R3k4wUuOuu",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\" FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    nearest_columns = result\n    values = []\n    for column in nearest_columns:\n        nearest_index = nearest_columns[column]\n        print(nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\"FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return values\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  df[nearest_columns] = df.apply(add_window_grid_cells, axis=1)\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%100,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/M2R3k4wUuOuu\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/M2R3k4wUuOuu/gw-44OFrMI2VhCV0lnrvq4QCm94cO-M2R3k4wUuOuu.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320497\nJob 1320497 has finished with state: JobState=FAILED\nSlurm job (1320497) has finished.\nPrint the job's output logs\nJobID                                                                                                     JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------------------------------------------------------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1320497                                                                               fc_model_data_preprocessing     FAILED      1:0            2023-11-29T02:06:42 2023-11-29T02:07:17 \n1320497.bat+                                                                                                batch     FAILED      1:0          0 2023-11-29T02:06:42 2023-11-29T02:07:17 \n1320497.ext+                                                                                               extern  COMPLETED      0:0          0 2023-11-29T02:06:42 2023-11-29T02:07:17 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n20200714\n20200713\n20200712\n20200711\n20200710\n20200709\n20200708\n    LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nnearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ndf.shape:  (156861, 22)\ndf.iloc[100] =  0.0\nTraceback (most recent call last):\n  File \"<stdin>\", line 285, in <module>\n  File \"<stdin>\", line 201, in prepare_training_data\n  File \"<stdin>\", line 126, in get_one_day_time_series_training_data\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"<stdin>\", line 115, in add_window_grid_cells\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\", line 955, in __getitem__\n    return self._values[key]\nIndexError: index 601 is out of bounds for axis 0 with size 24\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701241600917,
  "history_end_time" : 1701241642157,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "BbKs1FHqvrbf",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100][\"FRP\"])\n  \n  original_df = df\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    nearest_columns = result\n    values = []\n    for column in nearest_columns:\n        nearest_index = nearest_columns[column]\n        print(nearest_index)\n        \n        values.append(original_df.iloc[nearest_index][\"FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return values\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  df[nearest_columns] = df.apply(add_window_grid_cells, axis=1)\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%100,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/BbKs1FHqvrbf\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/BbKs1FHqvrbf/gw-44OFrMI2VhCV0lnrvq4QCm94cO-BbKs1FHqvrbf.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320496\nJob 1320496 has finished with state: JobState=FAILED\nSlurm job (1320496) has finished.\nPrint the job's output logs\nJobID                                                                                                     JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------------------------------------------------------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1320496                                                                               fc_model_data_preprocessing     FAILED      1:0            2023-11-29T02:05:22 2023-11-29T02:05:56 \n1320496.bat+                                                                                                batch     FAILED      1:0          0 2023-11-29T02:05:22 2023-11-29T02:05:56 \n1320496.ext+                                                                                               extern  COMPLETED      0:0          0 2023-11-29T02:05:22 2023-11-29T02:05:56 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n20200714\n20200713\n20200712\n20200711\n20200710\n20200709\n20200708\n    LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nnearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ndf.shape:  (156861, 22)\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'FRP'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"<stdin>\", line 285, in <module>\n  File \"<stdin>\", line 201, in prepare_training_data\n  File \"<stdin>\", line 106, in get_one_day_time_series_training_data\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\", line 958, in __getitem__\n    return self._get_value(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\", line 1069, in _get_value\n    loc = self.index.get_loc(label)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 'FRP'\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701241520463,
  "history_end_time" : 1701241561721,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "LPkQW6ruUiX4",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100])\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    nearest_columns = result\n    values = []\n    for column in nearest_columns:\n        nearest_index = nearest_columns[column]\n        values.append(df.iloc[nearest_index][\"FRP\"])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return values\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  df[nearest_columns] = df.apply(add_window_grid_cells, axis=1)\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%100,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/LPkQW6ruUiX4\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/LPkQW6ruUiX4/gw-44OFrMI2VhCV0lnrvq4QCm94cO-LPkQW6ruUiX4.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320495\nJob 1320495 has finished with state: JobState=FAILED\nSlurm job (1320495) has finished.\nPrint the job's output logs\nJobID                                                                                                     JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------------------------------------------------------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1320495                                                                               fc_model_data_preprocessing     FAILED      1:0            2023-11-29T02:01:23 2023-11-29T02:01:57 \n1320495.bat+                                                                                                batch     FAILED      1:0          0 2023-11-29T02:01:23 2023-11-29T02:01:57 \n1320495.ext+                                                                                               extern  COMPLETED      0:0          0 2023-11-29T02:01:23 2023-11-29T02:01:57 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n20200714\n20200713\n20200712\n20200711\n20200710\n20200709\n20200708\n    LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nnearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ndf.shape:  (156861, 22)\ndf.iloc[100] =  LAT              24.500000\n LON           -116.000000\n FRP              0.000000\n FWI           -999.000000\n VPD           -999.000000\n HT               0.000000\n T              296.314636\n RH              83.500000\n U                1.196226\n V               -5.440639\n P           101344.476562\n RAIN             0.000000\n CAPE             0.000000\n ST            -999.000000\n SM            -999.000000\n FRP_day0         0.000000\n FRP_day1         0.000000\n FRP_day2         0.000000\n FRP_day3         0.000000\n FRP_day4         0.000000\n FRP_day5         0.000000\n FRP_day6         0.000000\nName: 100, dtype: float64\nTraceback (most recent call last):\n  File \"<stdin>\", line 281, in <module>\n  File \"<stdin>\", line 197, in prepare_training_data\n  File \"<stdin>\", line 122, in get_one_day_time_series_training_data\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"<stdin>\", line 113, in add_window_grid_cells\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\", line 955, in __getitem__\n    return self._values[key]\nIndexError: index 601 is out of bounds for axis 0 with size 24\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701241281669,
  "history_end_time" : 1701241322930,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "s31kr7Hw0Ul6",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_data_preprocessing       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  print(\"nearest columns: \", nearest_columns)\n  print(\"df.shape: \", df.shape)\n  print(\"df.iloc[100] = \", df.iloc[100])\n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    nearest_columns = result\n    values = []\n    for column in nearest_columns:\n        nearest_index = nearest_columns[column]\n        values.append(df.iloc[nearest_index])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return values\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  df[nearest_columns] = df.apply(add_window_grid_cells, axis=1)\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName%100,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/s31kr7Hw0Ul6\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/s31kr7Hw0Ul6/gw-44OFrMI2VhCV0lnrvq4QCm94cO-s31kr7Hw0Ul6.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320493\nJob 1320493 has finished with state: JobState=FAILED\nSlurm job (1320493) has finished.\nPrint the job's output logs\nJobID                                                                                                     JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------------------------------------------------------------------------------------------------- ---------- -------- ---------- ------------------- ------------------- \n1320493                                                                               fc_model_data_preprocessing     FAILED      1:0            2023-11-29T01:56:22 2023-11-29T01:56:56 \n1320493.bat+                                                                                                batch     FAILED      1:0          0 2023-11-29T01:56:22 2023-11-29T01:56:56 \n1320493.ext+                                                                                               extern  COMPLETED      0:0          0 2023-11-29T01:56:22 2023-11-29T01:56:56 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n20200714\n20200713\n20200712\n20200711\n20200710\n20200709\n20200708\n    LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nnearest columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ndf.shape:  (156861, 22)\ndf.iloc[100] =  LAT              24.500000\n LON           -116.000000\n FRP              0.000000\n FWI           -999.000000\n VPD           -999.000000\n HT               0.000000\n T              296.314636\n RH              83.500000\n U                1.196226\n V               -5.440639\n P           101344.476562\n RAIN             0.000000\n CAPE             0.000000\n ST            -999.000000\n SM            -999.000000\n FRP_day0         0.000000\n FRP_day1         0.000000\n FRP_day2         0.000000\n FRP_day3         0.000000\n FRP_day4         0.000000\n FRP_day5         0.000000\n FRP_day6         0.000000\nName: 100, dtype: float64\nTraceback (most recent call last):\n  File \"<stdin>\", line 281, in <module>\n  File \"<stdin>\", line 197, in prepare_training_data\n  File \"<stdin>\", line 122, in get_one_day_time_series_training_data\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"<stdin>\", line 113, in add_window_grid_cells\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\", line 955, in __getitem__\n    return self._values[key]\nIndexError: index 601 is out of bounds for axis 0 with size 24\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701240980679,
  "history_end_time" : 1701241021947,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "FF7VgLRh98C3",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_creation_train       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  nearest_columns = grid_to_window_mapper_df.columns\n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    nearest_columns = result\n    values = []\n    for column in nearest_columns:\n        nearest_index = nearest_columns[column]\n        values.append(df.iloc[nearest_index])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return values\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   print(new_df.describe())\n  df[nearest_columns] = df.apply(add_window_grid_cells, axis=1)\n\n  print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/FF7VgLRh98C3\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/FF7VgLRh98C3/gw-44OFrMI2VhCV0lnrvq4QCm94cO-FF7VgLRh98C3.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320492\nJob 1320492 has finished with state: JobState=FAILED\nSlurm job (1320492) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1320492      fc_model_+     FAILED      1:0            2023-11-29T01:43:57 2023-11-29T01:44:35 \n1320492.bat+      batch     FAILED      1:0          0 2023-11-29T01:43:57 2023-11-29T01:44:35 \n1320492.ext+     extern  COMPLETED      0:0          0 2023-11-29T01:43:57 2023-11-29T01:44:35 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n20200714\n20200713\n20200712\n20200711\n20200710\n20200709\n20200708\n    LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nTraceback (most recent call last):\n  File \"<stdin>\", line 277, in <module>\n  File \"<stdin>\", line 193, in prepare_training_data\n  File \"<stdin>\", line 118, in get_one_day_time_series_training_data\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"<stdin>\", line 109, in add_window_grid_cells\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\", line 955, in __getitem__\n    return self._values[key]\nIndexError: index 601 is out of bounds for axis 0 with size 24\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701240235702,
  "history_end_time" : 1701240276963,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "2qlfQZi6cqkz",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_creation_train       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n#   grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  \n#   def add_window_grid_cells(row):\n#     result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n#     nearest_columns = result\n\n#     values = []\n#     for column in grid_to_window_mapper_df.columns:\n#         nearest_index = nearest_columns[column]\n#         values.append(df.iloc[nearest_index])\n#     if len(values) != 24:\n#       raise ValueError(\"The nearest values are not 24.\")\n#     return values\n  \n#   #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n#   print(\"new columns: \", grid_to_window_mapper_df.columns)\n#   new_df = df.apply(add_window_grid_cells, axis=1)\n#   print(new_df.describe())\n#   df[grid_to_window_mapper_df.columns] = new_df\n\n  #print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/2qlfQZi6cqkz\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/2qlfQZi6cqkz/gw-44OFrMI2VhCV0lnrvq4QCm94cO-2qlfQZi6cqkz.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320491\nJob 1320491 has finished with state: JobState=COMPLETED\nSlurm job (1320491) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1320491      fc_model_+  COMPLETED      0:0            2023-11-29T01:40:19 2023-11-29T01:40:56 \n1320491.bat+      batch  COMPLETED      0:0        56K 2023-11-29T01:40:19 2023-11-29T01:40:56 \n1320491.ext+     extern  COMPLETED      0:0          0 2023-11-29T01:40:19 2023-11-29T01:40:56 \nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\npreparing training data for  20200715\nIndex(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n20200714\n20200713\n20200712\n20200711\n20200710\n20200709\n20200708\n    LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nall feature names:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701240018108,
  "history_end_time" : 1701240060126,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "I9UYpqgL7k0F",
  "history_input" : "#!/bin/bash\necho \"start to run test_data_slurm_generated.sh\"\npwd\n\n# Specify the name of the script you want to submit\nSCRIPT_NAME=\"fc_model_data_preprocess_slurm_generated.sh\"\necho \"write the slurm script into ${SCRIPT_NAME}\"\ncat > ${SCRIPT_NAME} << EOF\n#!/bin/bash\n#SBATCH -J fc_model_creation_train       # Job name\n#SBATCH --output=/scratch/%u/%x-%N-%j.out  # Output file`\n#SBATCH --error=/scratch/%u/%x-%N-%j.err   # Error file`\n#SBATCH -n 1               # Number of tasks\n#SBATCH -c 12               # Number of CPUs per task (threads)\n#SBATCH --mem=50G          # Memory per node (use units like G for gigabytes) - this job must need 200GB lol\n#SBATCH -t 0-01:00         # Runtime in D-HH:MM format\n## Slurm can send you updates via email\n#SBATCH --mail-type=FAIL  # BEGIN,END,FAIL         # ALL,NONE,BEGIN,END,FAIL,REQUEUE,..\n#SBATCH --mail-user=zsun@gmu.edu     # Put your GMU email address here\n\n# Activate your customized virtual environment\nsource /home/zsun/anaconda3/bin/activate\n\npython << INNER_EOF\n\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef get_one_day_time_series_training_data(target_day):\n  # this function is used to get 7 days time series for one day prediction\n  print(\"preparing training data for \", target_day)\n  df = read_original_txt_files(target_day)\n  # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n  \n  # get grid to window mapper csv\n  grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n  print(grid_to_window_mapper_df.columns)\n  \n  target_dt = datetime.strptime(target_day, '%Y%m%d')\n  for i in range(7):\n    past_dt = target_dt - timedelta(days=i+1)\n    print(past_dt.strftime('%Y%m%d'))\n    past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n    column_to_append = past_df[\" FRP\"]\n    df[f' FRP_day{i}'] = column_to_append\n    \n  print(df.head())\n  \n  grid_to_window_mapper_df.set_index(['LAT', ' LON'], inplace=True)\n  \n  \n  def add_window_grid_cells(row):\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    nearest_columns = result\n\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = nearest_columns[column]\n        values.append(df.iloc[nearest_index])\n    if len(values) != 24:\n      raise ValueError(\"The nearest values are not 24.\")\n    return values\n  \n  #dropped_df = grid_to_window_mapper_df.drop([\"LAT\", \"LON\"], axis=1)\n  print(\"new columns: \", grid_to_window_mapper_df.columns)\n  new_df = df.apply(add_window_grid_cells, axis=1)\n  print(new_df.describe())\n  df[grid_to_window_mapper_df.columns] = new_df\n  #print(\"New time series dataframe: \", df.head())\n  return df\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n  # read the txt from original folder if the target date is within the 7 days before the current_start_day. `current_start_day` is actually the target day where the prediction begins. \n  # read the txt from the predicted folder if the target date is equal or after the current start day. \n  if current_start_day == None or current_prediction_output_folder == None:\n    return get_one_day_time_series_training_data(target_day)\n  else:\n    target_dt = datetime.strptime(target_day, '%Y%m%d')\n    current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n    \n    # always read from original folder for current target day. there is no file for current target day in the predicted folder.\n    print(f\"Read from original folder for current date: {target_day}\")\n    df = read_original_txt_files(target_day)\n    # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n    # \n    print(f\"current_start_dt is: {current_start_dt}\")\n    for i in range(7):\n      past_dt = target_dt - timedelta(days=i+1)\n      print(f\"reading past files for {past_dt}\")\n      if past_dt >= current_start_dt and past_dt < target_dt:\n        print(f\"reading from predicted folder\")\n        past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n      else:\n        print(f\"reading from original folder\")\n        past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n      column_to_append = past_df[\" FRP\"]\n      df[f' FRP_day{i}'] = column_to_append\n\n    #print(\"New time series dataframe: \", df.head())\n    return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n  \ndef create_training_time_series_dataframe(start_date, end_date):\n  start_dt = datetime.strptime(start_date, '%Y%m%d')\n  end_dt = datetime.strptime(end_date, '%Y%m%d')\n  \n  # Traverse each day and print\n  current_dt = start_dt\n  \n  while current_dt <= end_dt:\n    print(current_dt.strftime('%Y%m%d'))\n    current_dt += timedelta(days=1)\n    \n    \n    break\n    \n  return \n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  create_grid_to_window_mapper()\n  \n  target_col = ' FRP'\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  \n  # drop rows where the previous day has no fire on that pixel\n  \n  df = df[df[' FRP_day0'] != 0]\n  print(\"all feature names: \", df.columns)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n\ndef create_grid_to_window_mapper(the_folder_path = folder_path):\n  if os.path.exists(grid_to_window_mapper_csv):\n    print(f\"The file '{grid_to_window_mapper_csv}' exists.\")\n  else:\n    # this function will find the nearest 24 pixels for one pixel\n    # we only start from 2\n    # choose any txt \n    # Replace 'path_to_folder' with the path to your folder containing text files\n    txt_folder_path = f'{the_folder_path}/*.txt'\n    import glob\n    # Get a list of text files in the folder\n    text_files = glob.glob(txt_folder_path)\n\n    # Choose the first text file (you can modify this to select any specific file)\n    file_to_read = text_files[0]\n\n    # Read the chosen text file into a DataFrame\n    df = pd.read_csv(file_to_read)  # Modify delimiter as needed\n    print(df.head())\n    # Convert all values in the DataFrame to numeric\n    df = df.applymap(pd.to_numeric, errors='coerce')\n\n    print(df.columns)\n\n    # Use groupby to get unique pairs of LAT and LON\n    # Use groupby to get unique pairs of LAT and LON\n    unique_pairs = df.groupby(['LAT', ' LON']).size().reset_index(name='Count')\n    unique_pairs_df = unique_pairs[['LAT', ' LON']]\n    print(\"unique_pairs = \", unique_pairs_df)\n    # find the nearest 24 pixels for every single pixels\n    # Create a KDTree using 'LAT' and 'LON' columns\n    from scipy.spatial import cKDTree\n    tree = cKDTree(unique_pairs_df[['LAT', ' LON']])\n\n    # Find the 24 nearest neighbors for each point\n    distances, indices = tree.query(unique_pairs_df, k=25)\n\n    print(\"distances = \", distances)\n\n    # Extract the nearest 24 neighbors (excluding the point itself)\n    nearest_24 = indices[:, 1:]\n    print(\"nearest_24 = \", nearest_24)\n    print(\"nearest_24.shape = \", nearest_24.shape)\n\n    # Create column names for the new columns\n    new_columns = [f'Nearest_{i}' for i in range(1, 25)]\n\n    nearest_24_df = pd.DataFrame(nearest_24, columns=new_columns)\n\n    print(\"unique_pairs_df.shape: \", unique_pairs_df.shape)\n\n    # Merge the DataFrames row by row\n    result = pd.concat([unique_pairs_df.reset_index(drop=True), nearest_24_df.reset_index(drop=True)], axis=1)\n\n    print(result.head())\n    print(result.shape)\n\n    result.to_csv(grid_to_window_mapper_csv, index=False)\n    print(f\"grid to window mapper csv is saved to {grid_to_window_mapper_csv}\")\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\ntraining_end_date = \"20200715\"\nprepare_training_data(training_end_date)\n#get_one_day_time_series_training_data(training_end_date)\n#create_training_time_series_dataframe(start_date, training_end_date)\n\nINNER_EOF\n\nEOF\n\n# Submit the Slurm job and wait for it to finish\necho \"sbatch ${SCRIPT_NAME}\"\n# should have another check. if there is another job running, should cancel it before submitting a new job.\n\n# Find and cancel existing running jobs with the same script name\n#existing_jobs=$(squeue -h -o \"%A %j\" -u $(whoami) | awk -v script=\"$SCRIPT_NAME\" '$2 == script {print $1}')\n\n# if [ -n \"$existing_jobs\" ]; then\n#     echo \"Canceling existing jobs with the script name '$SCRIPT_NAME'...\"\n#     for job_id in $existing_jobs; do\n#         scancel $job_id\n#     done\n# else\n#     echo \"No existing jobs with the script name '$SCRIPT_NAME' found.\"\n# fi\n\n# Submit the Slurm job\njob_id=$(sbatch ${SCRIPT_NAME} | awk '{print $4}')\necho \"job_id=\"${job_id}\n\nif [ -z \"${job_id}\" ]; then\n    echo \"job id is empty. something wrong with the slurm job submission.\"\n    exit 1\nfi\n\n# Wait for the Slurm job to finish\nwhile true; do\n    job_status=$(scontrol show job ${job_id} | awk '/JobState=/{print $1}')\n    #echo \"job_status \"$job_status\n    #if [[ $job_status == \"JobState=COMPLETED\" ]]; then\n    #    break\n    #fi\n    if [[ $job_status == *\"COMPLETED\"* || $job_status == *\"CANCELLED\"* || $job_status == *\"FAILED\"* || $job_status == *\"TIMEOUT\"* || $job_status == *\"NODE_FAIL\"* || $job_status == *\"PREEMPTED\"* || $job_status == *\"OUT_OF_MEMORY\"* ]]; then\n        echo \"Job $job_id has finished with state: $job_status\"\n        break;\n    fi\n    sleep 10  # Adjust the sleep interval as needed\ndone\n\necho \"Slurm job ($job_id) has finished.\"\n\necho \"Print the job's output logs\"\nsacct --format=JobID,JobName,State,ExitCode,MaxRSS,Start,End -j $job_id\nfind /scratch/zsun/ -type f -name \"*${job_id}.out\" -exec cat {} \\;\n\n#cat /scratch/zsun/test_data_slurm-*-$job_id.out\n\necho \"All slurm job for ${SCRIPT_NAME} finishes.\"\n",
  "history_output" : "start to run test_data_slurm_generated.sh\n/home/zsun/gw-workspace/I9UYpqgL7k0F\nwrite the slurm script into fc_model_data_preprocess_slurm_generated.sh\n/home/zsun/gw-workspace/I9UYpqgL7k0F/gw-44OFrMI2VhCV0lnrvq4QCm94cO-I9UYpqgL7k0F.sh: line 8: current_start_day: command not found\nsbatch fc_model_data_preprocess_slurm_generated.sh\njob_id=1320490\nJob 1320490 has finished with state: JobState=CANCELLED\nSlurm job (1320490) has finished.\nPrint the job's output logs\nJobID           JobName      State ExitCode     MaxRSS               Start                 End \n------------ ---------- ---------- -------- ---------- ------------------- ------------------- \n1320490      fc_model_+ CANCELLED+      0:0            2023-11-29T01:36:21 2023-11-29T01:39:30 \n1320490.bat+      batch  CANCELLED     0:15   4709684K 2023-11-29T01:36:21 2023-11-29T01:39:31 \n1320490.ext+     extern  COMPLETED      0:0          0 2023-11-29T01:36:21 2023-11-29T01:39:30 \nslurmstepd-hop043: error: *** JOB 1320490 ON hop043 CANCELLED AT 2023-11-29T01:39:30 ***\nAll slurm job for fc_model_data_preprocess_slurm_generated.sh finishes.\n",
  "history_begin_time" : 1701239615259,
  "history_end_time" : 1701239977371,
  "history_notes" : null,
  "history_process" : "k84mqm",
  "host_id" : null,
  "indicator" : "Done"
},]
