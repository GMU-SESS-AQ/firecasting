[{
  "history_id" : "M5MvFOP3niy1",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        # Initialize data containers\n        all_data = {\n            'large_west': [],\n            'small_west': [],\n            'large_east': [],\n            'small_east': []\n        }\n        \n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Processing data for {date_str}\")\n\n            # Prepare training data\n            X, y = self.prepare_training_data(folder_path, date_str)\n\n            if X.empty or y.empty:\n                print(f\"No data available for {date_str}. Skipping...\")\n                current_date += timedelta(days=1)\n                continue\n\n            X[self.target_col] = np.log10(y + 1e-2)\n\n            # Determine if the fire is large or small\n            is_large_fire = y > fire_size_threshold\n\n            # Determine if the location is west or east\n            is_west = X['LON'] < region_dividing_longitude\n\n            # Append data to the appropriate category\n            for i in range(len(y)):\n                if is_west[i]:\n                    if is_large_fire[i]:\n                        all_data['large_west'].append(X.iloc[i])\n                    else:\n                        all_data['small_west'].append(X.iloc[i])\n                else:\n                    if is_large_fire[i]:\n                        all_data['large_east'].append(X.iloc[i])\n                    else:\n                        all_data['small_east'].append(X.iloc[i])\n\n            current_date += timedelta(days=1)\n\n        # Debugging output\n        for key in all_data:\n            if not all_data[key]:\n                print(f\"No data for category: {key}\")\n\n        # Train models for each category\n        for key in all_data:\n            if all_data[key]:\n                all_data_combined = pd.DataFrame(all_data[key])\n                all_data_combined = all_data_combined.dropna(subset=[self.target_col])\n                X = all_data_combined[self.chosen_input_columns]\n                y = all_data_combined[self.target_col]\n\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n                self.model_handlers[key].fit(X_train, y_train)\n                y_pred_test = self.model_handlers[key].predict(X_test)\n\n                mse = mean_squared_error(y_test, y_pred_test)\n                rmse = np.sqrt(mse)\n                mae = mean_absolute_error(y_test, y_pred_test)\n                r2 = r2_score(y_test, y_pred_test)\n\n                print(f\"Category: {key}\")\n                print(f\"Mean Squared Error (MSE): {mse}\")\n                print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n                print(f\"Mean Absolute Error (MAE): {mae}\")\n                print(f\"R-squared (R2): {r2}\")\n\n                # Save model for each category\n                model_path = model_paths[key]\n                self.model_handlers[key].save_model(model_path)\n                print(f\"Save to {model_path}\")\n\n                now = datetime.now()\n                date_time = now.strftime(\"%Y%d%m%H%M%S\")\n                random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n                self.model_handlers[key].save_model(random_model_path)\n                print(f\"A copy of the model is saved to {random_model_path}\")\n            else:\n                print(f\"No data to train model for category: {key}\")\n\n        print(\"Training completed for all categories.\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=2, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nProcessing data for 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nProcessing data for 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nProcessing data for 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nProcessing data for 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nProcessing data for 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nProcessing data for 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nProcessing data for 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nProcessing data for 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nProcessing data for 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nProcessing data for 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nProcessing data for 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nProcessing data for 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nProcessing data for 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nProcessing data for 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nProcessing data for 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nProcessing data for 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nProcessing data for 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nProcessing data for 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nProcessing data for 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nProcessing data for 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nProcessing data for 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nProcessing data for 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nCategory: large_west\nMean Squared Error (MSE): 0.28954224666532286\nRoot Mean Squared Error (RMSE): 0.53809129956293\nMean Absolute Error (MAE): 0.4289824338271838\nR-squared (R2): -0.09353244740323063\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_west.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_west.pkl_20200109_20200130_20241907022519.pkl\nCategory: small_west\nMean Squared Error (MSE): 0.04346828088244798\nRoot Mean Squared Error (RMSE): 0.20849048151521926\nMean Absolute Error (MAE): 0.05764106012532365\nR-squared (R2): 0.029236380834156916\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_west.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_west.pkl_20200109_20200130_20241907022523.pkl\nCategory: large_east\nMean Squared Error (MSE): 0.21094405114302994\nRoot Mean Squared Error (RMSE): 0.45928645869765194\nMean Absolute Error (MAE): 0.3712263095930498\nR-squared (R2): -0.04582240853424713\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_east.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_east.pkl_20200109_20200130_20241907022527.pkl\nCategory: small_east\nMean Squared Error (MSE): 0.061387177504372885\nRoot Mean Squared Error (RMSE): 0.24776435882582645\nMean Absolute Error (MAE): 0.05515884149298732\nR-squared (R2): -0.028830453413924095\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_east.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_east.pkl_20200109_20200130_20241907022533.pkl\nTraining completed for all categories.\nTraining completed and models saved to {'large_west': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_west.pkl', 'small_west': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_west.pkl', 'large_east': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_east.pkl', 'small_east': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_east.pkl'}\n",
  "history_begin_time" : 1721370308275,
  "history_end_time" : 1721370334208,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "FWjHS0cigKkd",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        # Initialize data containers\n        all_data = {\n            'large_west': [],\n            'small_west': [],\n            'large_east': [],\n            'small_east': []\n        }\n        \n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Processing data for {date_str}\")\n\n            # Prepare training data\n            X, y = self.prepare_training_data(folder_path, date_str)\n\n            if X.empty or y.empty:\n                print(f\"No data available for {date_str}. Skipping...\")\n                current_date += timedelta(days=1)\n                continue\n\n            X[self.target_col] = np.log10(y + 1e-2)\n\n            # Determine if the fire is large or small\n            is_large_fire = y > fire_size_threshold\n\n            # Determine if the location is west or east\n            is_west = X['LON'] < region_dividing_longitude\n\n            # Append data to the appropriate category\n            for i in range(len(y)):\n                if is_west[i]:\n                    if is_large_fire[i]:\n                        all_data['large_west'].append(X.iloc[i])\n                    else:\n                        all_data['small_west'].append(X.iloc[i])\n                else:\n                    if is_large_fire[i]:\n                        all_data['large_east'].append(X.iloc[i])\n                    else:\n                        all_data['small_east'].append(X.iloc[i])\n\n            current_date += timedelta(days=1)\n\n        # Debugging output\n        for key in all_data:\n            if not all_data[key]:\n                print(f\"No data for category: {key}\")\n\n        # Train models for each category\n        for key in all_data:\n            if all_data[key]:\n                all_data_combined = pd.DataFrame(all_data[key])\n                all_data_combined = all_data_combined.dropna(subset=[self.target_col])\n                X = all_data_combined[self.chosen_input_columns]\n                y = all_data_combined[self.target_col]\n\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n                self.model_handlers[key].fit(X_train, y_train)\n                y_pred_test = self.model_handlers[key].predict(X_test)\n\n                mse = mean_squared_error(y_test, y_pred_test)\n                rmse = np.sqrt(mse)\n                mae = mean_absolute_error(y_test, y_pred_test)\n                r2 = r2_score(y_test, y_pred_test)\n\n                print(f\"Category: {key}\")\n                print(f\"Mean Squared Error (MSE): {mse}\")\n                print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n                print(f\"Mean Absolute Error (MAE): {mae}\")\n                print(f\"R-squared (R2): {r2}\")\n\n                # Save model for each category\n                model_path = model_paths[key]\n                self.model_handlers[key].save_model(model_path)\n                print(f\"Save to {model_path}\")\n\n                now = datetime.now()\n                date_time = now.strftime(\"%Y%d%m%H%M%S\")\n                random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n                self.model_handlers[key].save_model(random_model_path)\n                print(f\"A copy of the model is saved to {random_model_path}\")\n            else:\n                print(f\"No data to train model for category: {key}\")\n\n        print(\"Training completed for all categories.\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=3, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nProcessing data for 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nProcessing data for 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nProcessing data for 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nProcessing data for 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nProcessing data for 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nProcessing data for 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nProcessing data for 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nProcessing data for 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nProcessing data for 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nProcessing data for 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nProcessing data for 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nProcessing data for 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nProcessing data for 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nProcessing data for 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nProcessing data for 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nProcessing data for 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nProcessing data for 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nProcessing data for 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nProcessing data for 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nProcessing data for 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nProcessing data for 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nProcessing data for 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nCategory: large_west\nMean Squared Error (MSE): 0.31799788998686856\nRoot Mean Squared Error (RMSE): 0.5639130163304165\nMean Absolute Error (MAE): 0.46535225111827594\nR-squared (R2): -0.30810380216427347\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_west.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_west.pkl_20200109_20200130_20241907022400.pkl\nCategory: small_west\nMean Squared Error (MSE): 0.08970997350917373\nRoot Mean Squared Error (RMSE): 0.29951623246357406\nMean Absolute Error (MAE): 0.09268848645937473\nR-squared (R2): 0.03174095614310235\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_west.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_west.pkl_20200109_20200130_20241907022409.pkl\nCategory: large_east\nMean Squared Error (MSE): 0.20300200067772856\nRoot Mean Squared Error (RMSE): 0.45055743327319386\nMean Absolute Error (MAE): 0.37084441713331506\nR-squared (R2): -0.13006031271165708\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_east.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_east.pkl_20200109_20200130_20241907022412.pkl\nCategory: small_east\nMean Squared Error (MSE): 0.11291836733135628\nRoot Mean Squared Error (RMSE): 0.33603328307082364\nMean Absolute Error (MAE): 0.08939933133805915\nR-squared (R2): -0.021951487612066334\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_east.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_east.pkl_20200109_20200130_20241907022426.pkl\nTraining completed for all categories.\nTraining completed and models saved to {'large_west': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_west.pkl', 'small_west': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_west.pkl', 'large_east': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_east.pkl', 'small_east': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_east.pkl'}\n",
  "history_begin_time" : 1721370231764,
  "history_end_time" : 1721370266839,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "dJbmJIllg5ZL",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        # Initialize data containers\n        all_data = {\n            'large_west': [],\n            'small_west': [],\n            'large_east': [],\n            'small_east': []\n        }\n        \n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Processing data for {date_str}\")\n\n            # Prepare training data\n            X, y = self.prepare_training_data(folder_path, date_str)\n\n            if X.empty or y.empty:\n                print(f\"No data available for {date_str}. Skipping...\")\n                current_date += timedelta(days=1)\n                continue\n\n            X[self.target_col] = np.log10(y + 1e-2)\n\n            # Determine if the fire is large or small\n            is_large_fire = y > fire_size_threshold\n\n            # Determine if the location is west or east\n            is_west = X['LON'] < region_dividing_longitude\n\n            # Append data to the appropriate category\n            for i in range(len(y)):\n                if is_west[i]:\n                    if is_large_fire[i]:\n                        all_data['large_west'].append(X.iloc[i])\n                    else:\n                        all_data['small_west'].append(X.iloc[i])\n                else:\n                    if is_large_fire[i]:\n                        all_data['large_east'].append(X.iloc[i])\n                    else:\n                        all_data['small_east'].append(X.iloc[i])\n\n            current_date += timedelta(days=1)\n\n        # Debugging output\n        for key in all_data:\n            if not all_data[key]:\n                print(f\"No data for category: {key}\")\n\n        # Train models for each category\n        for key in all_data:\n            if all_data[key]:\n                all_data_combined = pd.DataFrame(all_data[key])\n                all_data_combined = all_data_combined.dropna(subset=[self.target_col])\n                X = all_data_combined[self.chosen_input_columns]\n                y = all_data_combined[self.target_col]\n\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n                self.model_handlers[key].fit(X_train, y_train)\n                y_pred_test = self.model_handlers[key].predict(X_test)\n\n                mse = mean_squared_error(y_test, y_pred_test)\n                rmse = np.sqrt(mse)\n                mae = mean_absolute_error(y_test, y_pred_test)\n                r2 = r2_score(y_test, y_pred_test)\n\n                print(f\"Category: {key}\")\n                print(f\"Mean Squared Error (MSE): {mse}\")\n                print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n                print(f\"Mean Absolute Error (MAE): {mae}\")\n                print(f\"R-squared (R2): {r2}\")\n\n                # Save model for each category\n                model_path = model_paths[key]\n                self.model_handlers[key].save_model(model_path)\n                print(f\"Save to {model_path}\")\n\n                now = datetime.now()\n                date_time = now.strftime(\"%Y%d%m%H%M%S\")\n                random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n                self.model_handlers[key].save_model(random_model_path)\n                print(f\"A copy of the model is saved to {random_model_path}\")\n            else:\n                print(f\"No data to train model for category: {key}\")\n\n        print(\"Training completed for all categories.\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=1000, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nProcessing data for 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nProcessing data for 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nProcessing data for 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nProcessing data for 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nProcessing data for 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nProcessing data for 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nProcessing data for 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nProcessing data for 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nProcessing data for 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nProcessing data for 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nProcessing data for 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nProcessing data for 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nProcessing data for 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nProcessing data for 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nProcessing data for 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nProcessing data for 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nProcessing data for 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nProcessing data for 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nProcessing data for 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nProcessing data for 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nProcessing data for 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nProcessing data for 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nNo data for category: large_west\nNo data for category: large_east\nNo data to train model for category: large_west\nCategory: small_west\nMean Squared Error (MSE): 0.47225904903223187\nRoot Mean Squared Error (RMSE): 0.6872110658540299\nMean Absolute Error (MAE): 0.30674705703629435\nR-squared (R2): 0.13687615027130706\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_west.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_west.pkl_20200109_20200130_20241907022234.pkl\nNo data to train model for category: large_east\nCategory: small_east\nMean Squared Error (MSE): 0.42355754164865744\nRoot Mean Squared Error (RMSE): 0.6508129851567633\nMean Absolute Error (MAE): 0.2650380020468938\nR-squared (R2): -0.0013819500612177738\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_east.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_east.pkl_20200109_20200130_20241907022241.pkl\nTraining completed for all categories.\nTraining completed and models saved to {'large_west': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_west.pkl', 'small_west': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_west.pkl', 'large_east': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_east.pkl', 'small_east': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_east.pkl'}\n",
  "history_begin_time" : 1721370134361,
  "history_end_time" : 1721370162333,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "YFEDvx0xXYaa",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        # Initialize data containers\n        all_data = {\n            'large_west': [],\n            'small_west': [],\n            'large_east': [],\n            'small_east': []\n        }\n        \n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Processing data for {date_str}\")\n\n            # Prepare training data\n            X, y = self.prepare_training_data(folder_path, date_str)\n\n            if X.empty or y.empty:\n                print(f\"No data available for {date_str}. Skipping...\")\n                current_date += timedelta(days=1)\n                continue\n\n            X[self.target_col] = np.log10(y + 1e-2)\n\n            # Determine if the fire is large or small\n            is_large_fire = y > fire_size_threshold\n\n            # Determine if the location is west or east\n            is_west = X['LON'] < region_dividing_longitude\n\n            # Append data to the appropriate category\n            for i in range(len(y)):\n                if is_west[i]:\n                    if is_large_fire[i]:\n                        all_data['large_west'].append(X.iloc[i])\n                    else:\n                        all_data['small_west'].append(X.iloc[i])\n                else:\n                    if is_large_fire[i]:\n                        all_data['large_east'].append(X.iloc[i])\n                    else:\n                        all_data['small_east'].append(X.iloc[i])\n\n            current_date += timedelta(days=1)\n\n        # Debugging output\n        for key in all_data:\n            if not all_data[key]:\n                print(f\"No data for category: {key}\")\n\n        # Train models for each category\n        for key in all_data:\n            if all_data[key]:\n                all_data_combined = pd.DataFrame(all_data[key])\n                all_data_combined = all_data_combined.dropna(subset=[self.target_col])\n                X = all_data_combined[self.chosen_input_columns]\n                y = all_data_combined[self.target_col]\n\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n                self.model_handlers[key].fit(X_train, y_train)\n                y_pred_test = self.model_handlers[key].predict(X_test)\n\n                mse = mean_squared_error(y_test, y_pred_test)\n                rmse = np.sqrt(mse)\n                mae = mean_absolute_error(y_test, y_pred_test)\n                r2 = r2_score(y_test, y_pred_test)\n\n                print(f\"Category: {key}\")\n                print(f\"Mean Squared Error (MSE): {mse}\")\n                print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n                print(f\"Mean Absolute Error (MAE): {mae}\")\n                print(f\"R-squared (R2): {r2}\")\n\n                # Save model for each category\n                model_path = model_paths[key]\n                self.model_handlers[key].save_model(model_path)\n                print(f\"Save to {model_path}\")\n\n                now = datetime.now()\n                date_time = now.strftime(\"%Y%d%m%H%M%S\")\n                random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n                self.model_handlers[key].save_model(random_model_path)\n                print(f\"A copy of the model is saved to {random_model_path}\")\n            else:\n                print(f\"No data to train model for category: {key}\")\n\n        print(\"Training completed for all categories.\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nProcessing data for 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nProcessing data for 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nProcessing data for 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nProcessing data for 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nProcessing data for 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nProcessing data for 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nProcessing data for 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nProcessing data for 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nProcessing data for 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nProcessing data for 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nProcessing data for 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nProcessing data for 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nProcessing data for 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nProcessing data for 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nProcessing data for 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nProcessing data for 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nProcessing data for 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nProcessing data for 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nProcessing data for 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nProcessing data for 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nProcessing data for 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nProcessing data for 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nNo data for category: large_east\n/home/zsun/.local/lib/python3.8/site-packages/sklearn/metrics/_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n  warnings.warn(msg, UndefinedMetricWarning)\nCategory: large_west\nMean Squared Error (MSE): 0.010781872183678563\nRoot Mean Squared Error (RMSE): 0.10383579432776813\nMean Absolute Error (MAE): 0.10383579432776813\nR-squared (R2): nan\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_west.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_west.pkl_20200109_20200130_20241907021808.pkl\nCategory: small_west\nMean Squared Error (MSE): 0.4670454541760381\nRoot Mean Squared Error (RMSE): 0.6834072388964271\nMean Absolute Error (MAE): 0.2998291200267072\nR-squared (R2): 0.12592529704230948\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_west.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_west.pkl_20200109_20200130_20241907021820.pkl\nNo data to train model for category: large_east\nCategory: small_east\nMean Squared Error (MSE): 0.42355754164865744\nRoot Mean Squared Error (RMSE): 0.6508129851567633\nMean Absolute Error (MAE): 0.2650380020468938\nR-squared (R2): -0.0013819500612177738\nSave to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_east.pkl\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_east.pkl_20200109_20200130_20241907021828.pkl\nTraining completed for all categories.\nTraining completed and models saved to {'large_west': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_west.pkl', 'small_west': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_west.pkl', 'large_east': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_large_east.pkl', 'small_east': '/groups/ESS3/zsun/firecasting/model/fc_lightgbm_small_east.pkl'}\n",
  "history_begin_time" : 1721369883391,
  "history_end_time" : 1721369909132,
  "history_notes" : "no data to train for large fire in east",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "hOp1epiCLyPM",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        # Initialize data containers\n        all_data = {\n            'large_west': [],\n            'small_west': [],\n            'large_east': [],\n            'small_east': []\n        }\n        \n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Processing data for {date_str}\")\n\n            # Prepare training data\n            X, y = self.prepare_training_data(folder_path, date_str)\n\n            if X.empty or y.empty:\n                print(f\"No data available for {date_str}. Skipping...\")\n                current_date += timedelta(days=1)\n                continue\n\n            X[self.target_col] = np.log10(y + 1e-2)\n\n            # Determine if the fire is large or small\n            is_large_fire = y > fire_size_threshold\n\n            # Determine if the location is west or east\n            is_west = X['LON'] < region_dividing_longitude\n\n            # Append data to the appropriate category\n            for i in range(len(y)):\n                if is_west[i]:\n                    if is_large_fire[i]:\n                        all_data['large_west'].append(X.iloc[i])\n                    else:\n                        all_data['small_west'].append(X.iloc[i])\n                else:\n                    if is_large_fire[i]:\n                        all_data['large_east'].append(X.iloc[i])\n                    else:\n                        all_data['small_east'].append(X.iloc[i])\n\n            current_date += timedelta(days=1)\n\n        # Debugging output\n        for key in all_data:\n            if not all_data[key]:\n                print(f\"No data for category: {key}\")\n\n        # Train models for each category\n        for key in all_data:\n            if all_data[key]:\n                all_data_combined = pd.DataFrame(all_data[key])\n                all_data_combined = all_data_combined.dropna(subset=[self.target_col])\n                X = all_data_combined[self.chosen_input_columns]\n                y = all_data_combined[self.target_col]\n\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n                self.model_handlers[key].fit(X_train, y_train)\n                y_pred_test = self.model_handlers[key].predict(X_test)\n\n                mse = mean_squared_error(y_test, y_pred_test)\n                rmse = np.sqrt(mse)\n                mae = mean_absolute_error(y_test, y_pred_test)\n                r2 = r2_score(y_test, y_pred_test)\n\n                print(f\"Category: {key}\")\n                print(f\"Mean Squared Error (MSE): {mse}\")\n                print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n                print(f\"Mean Absolute Error (MAE): {mae}\")\n                print(f\"R-squared (R2): {r2}\")\n\n                # Save model for each category\n                model_path = model_paths[key]\n                self.model_handlers[key].save_model(model_path)\n\n                now = datetime.now()\n                date_time = now.strftime(\"%Y%d%m%H%M%S\")\n                random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n                self.model_handler.save_model(random_model_path)\n                print(f\"A copy of the model is saved to {random_model_path}\")\n            else:\n                print(f\"No data to train model for category: {key}\")\n\n        print(\"Training completed for all categories.\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nProcessing data for 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nProcessing data for 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nProcessing data for 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nProcessing data for 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nProcessing data for 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nProcessing data for 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nProcessing data for 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nProcessing data for 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nProcessing data for 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nProcessing data for 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nProcessing data for 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nProcessing data for 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nProcessing data for 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nProcessing data for 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nProcessing data for 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nProcessing data for 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nProcessing data for 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nProcessing data for 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nProcessing data for 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nProcessing data for 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nProcessing data for 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nProcessing data for 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nNo data for category: large_east\n/home/zsun/.local/lib/python3.8/site-packages/sklearn/metrics/_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n  warnings.warn(msg, UndefinedMetricWarning)\nCategory: large_west\nMean Squared Error (MSE): 0.010781872183678563\nRoot Mean Squared Error (RMSE): 0.10383579432776813\nMean Absolute Error (MAE): 0.10383579432776813\nR-squared (R2): nan\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 251, in <module>\n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n  File \"fc_model_creation.py\", line 220, in train_model\n    self.model_handler.save_model(random_model_path)\nAttributeError: 'WildfireModelTrainer' object has no attribute 'model_handler'\n",
  "history_begin_time" : 1721369843189,
  "history_end_time" : 1721369848667,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "rgYc5ce3tkAO",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        # Initialize data containers\n        all_data = {\n            'large_west': [],\n            'small_west': [],\n            'large_east': [],\n            'small_east': []\n        }\n        \n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Processing data for {date_str}\")\n\n            # Prepare training data\n            X, y = self.prepare_training_data(folder_path, date_str)\n\n            if X.empty or y.empty:\n                print(f\"No data available for {date_str}. Skipping...\")\n                current_date += timedelta(days=1)\n                continue\n\n            X[self.target_col] = np.log10(y + 1e-2)\n\n            # Determine if the fire is large or small\n            is_large_fire = y > fire_size_threshold\n\n            # Determine if the location is west or east\n            is_west = X['LON'] < region_dividing_longitude\n\n            # Append data to the appropriate category\n            for i in range(len(y)):\n                if is_west[i]:\n                    if is_large_fire[i]:\n                        all_data['large_west'].append(X.iloc[i])\n                    else:\n                        all_data['small_west'].append(X.iloc[i])\n                else:\n                    if is_large_fire[i]:\n                        all_data['large_east'].append(X.iloc[i])\n                    else:\n                        all_data['small_east'].append(X.iloc[i])\n\n            current_date += timedelta(days=1)\n\n        # Debugging output\n        for key in all_data:\n            if not all_data[key]:\n                print(f\"No data for category: {key}\")\n\n        # Train models for each category\n        for key in all_data:\n            if all_data[key]:\n                all_data_combined = pd.DataFrame(all_data[key])\n                all_data_combined = all_data_combined.dropna(subset=[self.target_col])\n                X = all_data_combined[self.chosen_input_columns]\n                y = all_data_combined[self.target_col]\n\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n                self.model_handlers[key].fit(X_train, y_train)\n                y_pred_test = self.model_handlers[key].predict(X_test)\n\n                mse = mean_squared_error(y_test, y_pred_test)\n                rmse = np.sqrt(mse)\n                mae = mean_absolute_error(y_test, y_pred_test)\n                r2 = r2_score(y_test, y_pred_test)\n\n                print(f\"Category: {key}\")\n                print(f\"Mean Squared Error (MSE): {mse}\")\n                print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n                print(f\"Mean Absolute Error (MAE): {mae}\")\n                print(f\"R-squared (R2): {r2}\")\n\n                # Save model for each category\n                model_path = model_paths[key]\n                self.model_handler.save_model(model_path)\n\n                now = datetime.now()\n                date_time = now.strftime(\"%Y%d%m%H%M%S\")\n                random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n                self.model_handler.save_model(random_model_path)\n                print(f\"A copy of the model is saved to {random_model_path}\")\n            else:\n                print(f\"No data to train model for category: {key}\")\n\n        print(\"Training completed for all categories.\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nProcessing data for 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nProcessing data for 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nProcessing data for 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nProcessing data for 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nProcessing data for 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nProcessing data for 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nProcessing data for 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nProcessing data for 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nProcessing data for 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nProcessing data for 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nProcessing data for 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nProcessing data for 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nProcessing data for 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nProcessing data for 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nProcessing data for 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nProcessing data for 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nProcessing data for 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nProcessing data for 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nProcessing data for 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nProcessing data for 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nProcessing data for 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nProcessing data for 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nNo data for category: large_east\n/home/zsun/.local/lib/python3.8/site-packages/sklearn/metrics/_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n  warnings.warn(msg, UndefinedMetricWarning)\nCategory: large_west\nMean Squared Error (MSE): 0.010781872183678563\nRoot Mean Squared Error (RMSE): 0.10383579432776813\nMean Absolute Error (MAE): 0.10383579432776813\nR-squared (R2): nan\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 251, in <module>\n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n  File \"fc_model_creation.py\", line 215, in train_model\n    self.model_handler.save_model(model_path)\nAttributeError: 'WildfireModelTrainer' object has no attribute 'model_handler'\n",
  "history_begin_time" : 1721369813263,
  "history_end_time" : 1721369818650,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "OxPagCJgsmgD",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        # Initialize data containers\n        all_data = {\n            'large_west': [],\n            'small_west': [],\n            'large_east': [],\n            'small_east': []\n        }\n        \n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Processing data for {date_str}\")\n\n            # Prepare training data\n            X, y = self.prepare_training_data(folder_path, date_str)\n\n            if X.empty or y.empty:\n                print(f\"No data available for {date_str}. Skipping...\")\n                current_date += timedelta(days=1)\n                continue\n\n            X[self.target_col] = np.log10(y + 1e-2)\n\n            # Determine if the fire is large or small\n            is_large_fire = y > fire_size_threshold\n\n            # Determine if the location is west or east\n            is_west = X['LON'] < region_dividing_longitude\n\n            # Append data to the appropriate category\n            for i in range(len(y)):\n                if is_west[i]:\n                    if is_large_fire[i]:\n                        all_data['large_west'].append(X.iloc[i])\n                    else:\n                        all_data['small_west'].append(X.iloc[i])\n                else:\n                    if is_large_fire[i]:\n                        all_data['large_east'].append(X.iloc[i])\n                    else:\n                        all_data['small_east'].append(X.iloc[i])\n\n            current_date += timedelta(days=1)\n\n        # Debugging output\n        for key in all_data:\n            if not all_data[key]:\n                print(f\"No data for category: {key}\")\n\n        # Train models for each category\n        for key in all_data:\n            if all_data[key]:\n                all_data_combined = pd.DataFrame(all_data[key])\n                all_data_combined = all_data_combined.dropna(subset=[self.target_col])\n                X = all_data_combined[self.chosen_input_columns]\n                y = all_data_combined[self.target_col]\n\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n                self.model_handlers[key].fit(X_train, y_train)\n                y_pred_test = self.model_handler.predict(X_test)\n\n                mse = mean_squared_error(y_test, y_pred_test)\n                rmse = np.sqrt(mse)\n                mae = mean_absolute_error(y_test, y_pred_test)\n                r2 = r2_score(y_test, y_pred_test)\n\n                print(f\"Category: {key}\")\n                print(f\"Mean Squared Error (MSE): {mse}\")\n                print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n                print(f\"Mean Absolute Error (MAE): {mae}\")\n                print(f\"R-squared (R2): {r2}\")\n\n                # Save model for each category\n                model_path = model_paths[key]\n                self.model_handler.save_model(model_path)\n\n                now = datetime.now()\n                date_time = now.strftime(\"%Y%d%m%H%M%S\")\n                random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n                self.model_handler.save_model(random_model_path)\n                print(f\"A copy of the model is saved to {random_model_path}\")\n            else:\n                print(f\"No data to train model for category: {key}\")\n\n        print(\"Training completed for all categories.\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nProcessing data for 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nProcessing data for 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nProcessing data for 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nProcessing data for 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nProcessing data for 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nProcessing data for 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nProcessing data for 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nProcessing data for 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nProcessing data for 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nProcessing data for 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nProcessing data for 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nProcessing data for 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nProcessing data for 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nProcessing data for 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nProcessing data for 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nProcessing data for 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nProcessing data for 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nProcessing data for 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nProcessing data for 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nProcessing data for 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nProcessing data for 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nProcessing data for 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nNo data for category: large_east\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 251, in <module>\n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n  File \"fc_model_creation.py\", line 200, in train_model\n    y_pred_test = self.model_handler.predict(X_test)\nAttributeError: 'WildfireModelTrainer' object has no attribute 'model_handler'\n",
  "history_begin_time" : 1721369788262,
  "history_end_time" : 1721369794191,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "A42KYmxb6EVX",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        # Initialize data containers\n        all_data = {\n            'west_large': [],\n            'west_small': [],\n            'east_large': [],\n            'east_small': []\n        }\n        \n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Processing data for {date_str}\")\n\n            # Prepare training data\n            X, y = self.prepare_training_data(folder_path, date_str)\n\n            if X.empty or y.empty:\n                print(f\"No data available for {date_str}. Skipping...\")\n                current_date += timedelta(days=1)\n                continue\n\n            X[self.target_col] = np.log10(y + 1e-2)\n\n            # Determine if the fire is large or small\n            is_large_fire = y > fire_size_threshold\n\n            # Determine if the location is west or east\n            is_west = X['LON'] < region_dividing_longitude\n\n            # Append data to the appropriate category\n            for i in range(len(y)):\n                if is_west[i]:\n                    if is_large_fire[i]:\n                        all_data['large_west'].append(X.iloc[i])\n                    else:\n                        all_data['small_west'].append(X.iloc[i])\n                else:\n                    if is_large_fire[i]:\n                        all_data['large_east'].append(X.iloc[i])\n                    else:\n                        all_data['small_east'].append(X.iloc[i])\n\n            current_date += timedelta(days=1)\n\n        # Debugging output\n        for key in all_data:\n            if not all_data[key]:\n                print(f\"No data for category: {key}\")\n\n        # Train models for each category\n        for key in all_data:\n            if all_data[key]:\n                all_data_combined = pd.DataFrame(all_data[key])\n                all_data_combined = all_data_combined.dropna(subset=[self.target_col])\n                X = all_data_combined[self.chosen_input_columns]\n                y = all_data_combined[self.target_col]\n\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n                self.model_handlers[key].fit(X_train, y_train)\n                y_pred_test = self.model_handler.predict(X_test)\n\n                mse = mean_squared_error(y_test, y_pred_test)\n                rmse = np.sqrt(mse)\n                mae = mean_absolute_error(y_test, y_pred_test)\n                r2 = r2_score(y_test, y_pred_test)\n\n                print(f\"Category: {key}\")\n                print(f\"Mean Squared Error (MSE): {mse}\")\n                print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n                print(f\"Mean Absolute Error (MAE): {mae}\")\n                print(f\"R-squared (R2): {r2}\")\n\n                # Save model for each category\n                model_path = model_paths[key]\n                self.model_handler.save_model(model_path)\n\n                now = datetime.now()\n                date_time = now.strftime(\"%Y%d%m%H%M%S\")\n                random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n                self.model_handler.save_model(random_model_path)\n                print(f\"A copy of the model is saved to {random_model_path}\")\n            else:\n                print(f\"No data to train model for category: {key}\")\n\n        print(\"Training completed for all categories.\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nProcessing data for 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 251, in <module>\n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n  File \"fc_model_creation.py\", line 180, in train_model\n    all_data['small_east'].append(X.iloc[i])\nKeyError: 'small_east'\n",
  "history_begin_time" : 1721369726853,
  "history_end_time" : 1721369730529,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "UsxZasRGf8lt",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        # Initialize data containers\n        all_data = {\n            'west_large': [],\n            'west_small': [],\n            'east_large': [],\n            'east_small': []\n        }\n        \n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Processing data for {date_str}\")\n\n            # Prepare training data\n            X, y = self.prepare_training_data(folder_path, date_str)\n\n            if X.empty or y.empty:\n                print(f\"No data available for {date_str}. Skipping...\")\n                current_date += timedelta(days=1)\n                continue\n\n            X[self.target_col] = np.log10(y + 1e-2)\n\n            # Determine if the fire is large or small\n            is_large_fire = y > fire_size_threshold\n\n            # Determine if the location is west or east\n            is_west = X['LON'] < region_dividing_longitude\n\n            # Append data to the appropriate category\n            for i in range(len(y)):\n                if is_west[i]:\n                    if is_large_fire[i]:\n                        all_data['west_large'].append(X.iloc[i])\n                    else:\n                        all_data['west_small'].append(X.iloc[i])\n                else:\n                    if is_large_fire[i]:\n                        all_data['east_large'].append(X.iloc[i])\n                    else:\n                        all_data['east_small'].append(X.iloc[i])\n\n            current_date += timedelta(days=1)\n\n        # Debugging output\n        for key in all_data:\n            if not all_data[key]:\n                print(f\"No data for category: {key}\")\n\n        # Train models for each category\n        for key in all_data:\n            if all_data[key]:\n                all_data_combined = pd.DataFrame(all_data[key])\n                all_data_combined = all_data_combined.dropna(subset=[self.target_col])\n                X = all_data_combined[self.chosen_input_columns]\n                y = all_data_combined[self.target_col]\n\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n                self.model_handlers[key].fit(X_train, y_train)\n                y_pred_test = self.model_handler.predict(X_test)\n\n                mse = mean_squared_error(y_test, y_pred_test)\n                rmse = np.sqrt(mse)\n                mae = mean_absolute_error(y_test, y_pred_test)\n                r2 = r2_score(y_test, y_pred_test)\n\n                print(f\"Category: {key}\")\n                print(f\"Mean Squared Error (MSE): {mse}\")\n                print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n                print(f\"Mean Absolute Error (MAE): {mae}\")\n                print(f\"R-squared (R2): {r2}\")\n\n                # Save model for each category\n                model_path = model_paths[key]\n                self.model_handler.save_model(model_path)\n\n                now = datetime.now()\n                date_time = now.strftime(\"%Y%d%m%H%M%S\")\n                random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n                self.model_handler.save_model(random_model_path)\n                print(f\"A copy of the model is saved to {random_model_path}\")\n            else:\n                print(f\"No data to train model for category: {key}\")\n\n        print(\"Training completed for all categories.\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nProcessing data for 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nProcessing data for 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nProcessing data for 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nProcessing data for 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nProcessing data for 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nProcessing data for 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nProcessing data for 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nProcessing data for 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nProcessing data for 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nProcessing data for 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nProcessing data for 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nProcessing data for 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nProcessing data for 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nProcessing data for 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nProcessing data for 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nProcessing data for 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nProcessing data for 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nProcessing data for 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nProcessing data for 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nProcessing data for 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nProcessing data for 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nProcessing data for 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nNo data for category: east_large\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 251, in <module>\n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n  File \"fc_model_creation.py\", line 199, in train_model\n    self.model_handlers[key].fit(X_train, y_train)\nKeyError: 'west_large'\n",
  "history_begin_time" : 1721369665533,
  "history_end_time" : 1721369670682,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "1EzEjnWYXLXh",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        # Initialize data containers\n        all_data = {\n            'west_large': [],\n            'west_small': [],\n            'east_large': [],\n            'east_small': []\n        }\n        \n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Processing data for {date_str}\")\n\n            # Prepare training data\n            X, y = self.prepare_training_data(folder_path, date_str)\n\n            if X.empty or y.empty:\n                print(f\"No data available for {date_str}. Skipping...\")\n                current_date += timedelta(days=1)\n                continue\n\n            X[self.target_col] = np.log10(y + 1e-2)\n\n            # Determine if the fire is large or small\n            is_large_fire = y > fire_size_threshold\n\n            # Determine if the location is west or east\n            is_west = X['LON'] < region_dividing_longitude\n\n            # Append data to the appropriate category\n            for i in range(len(y)):\n                if is_west[i]:\n                    if is_large_fire[i]:\n                        all_data['west_large'].append(X.iloc[i])\n                    else:\n                        all_data['west_small'].append(X.iloc[i])\n                else:\n                    if is_large_fire[i]:\n                        all_data['east_large'].append(X.iloc[i])\n                    else:\n                        all_data['east_small'].append(X.iloc[i])\n\n            current_date += timedelta(days=1)\n\n        # Debugging output\n        for key in all_data:\n            if not all_data[key]:\n                print(f\"No data for category: {key}\")\n\n        # Train models for each category\n        for key in all_data:\n            if all_data[key]:\n                all_data_combined = pd.DataFrame(all_data[key])\n                all_data_combined = all_data_combined.dropna(subset=[self.target_col])\n                X = all_data_combined[self.chosen_input_columns]\n                y = all_data_combined[self.target_col]\n\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n                self.model_handler.fit(X_train, y_train)\n                y_pred_test = self.model_handler.predict(X_test)\n\n                mse = mean_squared_error(y_test, y_pred_test)\n                rmse = np.sqrt(mse)\n                mae = mean_absolute_error(y_test, y_pred_test)\n                r2 = r2_score(y_test, y_pred_test)\n\n                print(f\"Category: {key}\")\n                print(f\"Mean Squared Error (MSE): {mse}\")\n                print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n                print(f\"Mean Absolute Error (MAE): {mae}\")\n                print(f\"R-squared (R2): {r2}\")\n\n                # Save model for each category\n                model_path = model_paths[key]\n                self.model_handler.save_model(model_path)\n\n                now = datetime.now()\n                date_time = now.strftime(\"%Y%d%m%H%M%S\")\n                random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n                self.model_handler.save_model(random_model_path)\n                print(f\"A copy of the model is saved to {random_model_path}\")\n            else:\n                print(f\"No data to train model for category: {key}\")\n\n        print(\"Training completed for all categories.\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nProcessing data for 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nProcessing data for 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nProcessing data for 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nProcessing data for 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nProcessing data for 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nProcessing data for 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nProcessing data for 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nProcessing data for 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nProcessing data for 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nProcessing data for 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nProcessing data for 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nProcessing data for 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nProcessing data for 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nProcessing data for 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nProcessing data for 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nProcessing data for 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nProcessing data for 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nProcessing data for 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nProcessing data for 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nProcessing data for 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nProcessing data for 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nProcessing data for 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nNo data for category: east_large\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 251, in <module>\n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n  File \"fc_model_creation.py\", line 199, in train_model\n    self.model_handler.fit(X_train, y_train)\nAttributeError: 'WildfireModelTrainer' object has no attribute 'model_handler'\n",
  "history_begin_time" : 1721369632695,
  "history_end_time" : 1721369638521,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "sIrSYV830zPD",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-80):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        all_data = {'large_fire': [], 'small_fire': [], 'west_us': [], 'east_us': []}\n        \n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Training on {date_str}\")\n            X, y = self.prepare_training_data(folder_path, date_str)\n            \n            if X.empty or y.empty:\n                print(f\"No data available for {date_str}. Skipping...\")\n                current_date += timedelta(days=1)\n                continue\n\n            X[self.target_col] = np.log10(y + 1e-2)\n\n            if (y > fire_size_threshold).any():\n                all_data['large_fire'].append(X)\n            else:\n                all_data['small_fire'].append(X)\n\n            if (X['LON'] < region_dividing_longitude).any():\n                all_data['west_us'].append(X)\n            else:\n                all_data['east_us'].append(X)\n\n            current_date += timedelta(days=1)\n\n        # Debugging output\n        for key in all_data:\n            if not all_data[key]:\n                print(f\"No data for category: {key}\")\n\n        # Concatenate and check for empty dataframes\n        for key in all_data:\n            if all_data[key]:\n                all_data_combined = pd.concat(all_data[key], axis=0).dropna(subset=[self.target_col])\n                X = all_data_combined[self.chosen_input_columns]\n                y = all_data_combined[self.target_col]\n\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n                self.model_handler.fit(X_train, y_train)\n                y_pred_test = self.model_handler.predict(X_test)\n\n                mse = mean_squared_error(y_test, y_pred_test)\n                rmse = np.sqrt(mse)\n                mae = mean_absolute_error(y_test, y_pred_test)\n                r2 = r2_score(y_test, y_pred_test)\n\n                print(f\"Category: {key}\")\n                print(f\"Mean Squared Error (MSE): {mse}\")\n                print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n                print(f\"Mean Absolute Error (MAE): {mae}\")\n                print(f\"R-squared (R2): {r2}\")\n\n                # Save model for each category\n                model_path = model_paths[key]\n                self.model_handler.save_model(model_path)\n\n                now = datetime.now()\n                date_time = now.strftime(\"%Y%d%m%H%M%S\")\n                random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n                self.model_handler.save_model(random_model_path)\n                print(f\"A copy of the model is saved to {random_model_path}\")\n            else:\n                print(f\"No data to train model for category: {key}\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nTraining on 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nTraining on 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nTraining on 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nTraining on 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nTraining on 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nTraining on 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nTraining on 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nTraining on 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nTraining on 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nTraining on 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nTraining on 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nTraining on 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nTraining on 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nTraining on 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nTraining on 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nTraining on 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nTraining on 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nTraining on 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nTraining on 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nTraining on 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nTraining on 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nTraining on 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nNo data for category: east_us\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 231, in <module>\n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n  File \"fc_model_creation.py\", line 181, in train_model\n    self.model_handler.fit(X_train, y_train)\nAttributeError: 'WildfireModelTrainer' object has no attribute 'model_handler'\n",
  "history_begin_time" : 1721369243916,
  "history_end_time" : 1721369248110,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "0UE4z7RqeHLl",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-80):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        all_data = {'large_west': [], 'small_west': [], 'large_east': [], 'small_east': []}\n\n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Processing data for {date_str}\")\n            X, y = self.prepare_training_data(folder_path, date_str)\n            X[self.target_col] = np.log10(y + 1e-2)\n            \n            X['FRP'] = y\n            X['Region'] = X['LAT'].apply(lambda x: 'West' if x < region_dividing_longitude else 'East')\n            X['FireSize'] = y.apply(lambda x: 'Large' if x > fire_size_threshold else 'Small')\n            \n            for key in all_data:\n                fire_size, region = key.split('_')\n                subset = X[(X['FireSize'] == fire_size) & (X['Region'] == region)]\n                if not subset.empty:\n                    all_data[key].append(subset)\n            \n            current_date += timedelta(days=1)\n\n        # Debugging output\n        for key in all_data:\n            if not all_data[key]:\n                print(f\"No data for category: {key}\")\n\n        # Train models for each subset\n        for key, handler in self.model_handlers.items():\n            subset_data = pd.concat(all_data[key], axis=0).dropna(subset=[self.target_col])\n            X = subset_data[self.chosen_input_columns]\n            y = subset_data[self.target_col]\n\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n            handler.fit(X_train, y_train)\n            y_pred_test = handler.predict(X_test)\n\n            mse = mean_squared_error(y_test, y_pred_test)\n            rmse = np.sqrt(mse)\n            mae = mean_absolute_error(y_test, y_pred_test)\n            r2 = r2_score(y_test, y_pred_test)\n\n            print(f\"{key} - Mean Squared Error (MSE): {mse}\")\n            print(f\"{key} - Root Mean Squared Error (RMSE): {rmse}\")\n            print(f\"{key} - Mean Absolute Error (MAE): {mae}\")\n            print(f\"{key} - R-squared (R2): {r2}\")\n\n            handler.save_model(model_paths[key])\n\n            now = datetime.now()\n            date_time = now.strftime(\"%Y%d%m%H%M%S\")\n            random_model_path = f\"{model_paths[key]}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n            handler.save_model(random_model_path)\n            print(f\"A copy of the {key} model is saved to {random_model_path}\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nProcessing data for 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nProcessing data for 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nProcessing data for 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nProcessing data for 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nProcessing data for 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nProcessing data for 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nProcessing data for 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nProcessing data for 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nProcessing data for 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nProcessing data for 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nProcessing data for 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nProcessing data for 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nProcessing data for 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nProcessing data for 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nProcessing data for 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nProcessing data for 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nProcessing data for 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nProcessing data for 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nProcessing data for 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nProcessing data for 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nProcessing data for 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nProcessing data for 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nNo data for category: large_west\nNo data for category: small_west\nNo data for category: large_east\nNo data for category: small_east\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 219, in <module>\n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n  File \"fc_model_creation.py\", line 168, in train_model\n    subset_data = pd.concat(all_data[key], axis=0).dropna(subset=[self.target_col])\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1721369160843,
  "history_end_time" : 1721369165061,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "UYDNvo0OgtO5",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", chosen_input_columns=[], training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = chosen_input_columns\n        self.model_handlers = {\n            'large_west': self.init_model_handler(model_type),\n            'small_west': self.init_model_handler(model_type),\n            'large_east': self.init_model_handler(model_type),\n            'small_east': self.init_model_handler(model_type),\n        }\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-80):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        all_data = {'large_west': [], 'small_west': [], 'large_east': [], 'small_east': []}\n\n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Processing data for {date_str}\")\n            X, y = self.prepare_training_data(folder_path, date_str)\n            X[self.target_col] = np.log10(y + 1e-2)\n            \n            X['FRP'] = y\n            X['Region'] = X['LAT'].apply(lambda x: 'West' if x < region_dividing_longitude else 'East')\n            X['FireSize'] = y.apply(lambda x: 'Large' if x > fire_size_threshold else 'Small')\n            \n            for key in all_data:\n                fire_size, region = key.split('_')\n                subset = X[(X['FireSize'] == fire_size) & (X['Region'] == region)]\n                if not subset.empty:\n                    all_data[key].append(subset)\n            \n            current_date += timedelta(days=1)\n\n        # Train models for each subset\n        for key, handler in self.model_handlers.items():\n            subset_data = pd.concat(all_data[key], axis=0).dropna(subset=[self.target_col])\n            X = subset_data[self.chosen_input_columns]\n            y = subset_data[self.target_col]\n\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n            handler.fit(X_train, y_train)\n            y_pred_test = handler.predict(X_test)\n\n            mse = mean_squared_error(y_test, y_pred_test)\n            rmse = np.sqrt(mse)\n            mae = mean_absolute_error(y_test, y_pred_test)\n            r2 = r2_score(y_test, y_pred_test)\n\n            print(f\"{key} - Mean Squared Error (MSE): {mse}\")\n            print(f\"{key} - Root Mean Squared Error (RMSE): {rmse}\")\n            print(f\"{key} - Mean Absolute Error (MAE): {mae}\")\n            print(f\"{key} - R-squared (R2): {r2}\")\n\n            handler.save_model(model_paths[key])\n\n            now = datetime.now()\n            date_time = now.strftime(\"%Y%d%m%H%M%S\")\n            random_model_path = f\"{model_paths[key]}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n            handler.save_model(random_model_path)\n            print(f\"A copy of the {key} model is saved to {random_model_path}\")\n\n\n# Define global variables that can be imported by others\nmodel_type = \"lightgbm\"  # Can be 'lightgbm' or 'tabnet'\nmodel_paths = {\n    'large_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_west.pkl\",\n    'small_west': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_west.pkl\",\n    'large_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_large_east.pkl\",\n    'small_east': f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_small_east.pkl\"\n}\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n]\n\nif __name__ == \"__main__\":\n    trainer = WildfireModelTrainer(\n        model_type=model_type,\n        training_data_folder=training_data_folder, \n        chosen_input_columns=chosen_input_columns\n    )\n    start_date_str = \"20200109\"\n    end_date_str = \"20200130\"\n    \n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n    print(f\"Training completed and models saved to {model_paths}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nProcessing data for 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nProcessing data for 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nProcessing data for 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nProcessing data for 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nProcessing data for 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nProcessing data for 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nProcessing data for 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nProcessing data for 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nProcessing data for 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nProcessing data for 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nProcessing data for 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nProcessing data for 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nProcessing data for 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nProcessing data for 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nProcessing data for 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nProcessing data for 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nProcessing data for 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nProcessing data for 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nProcessing data for 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nProcessing data for 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nProcessing data for 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nProcessing data for 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 214, in <module>\n    trainer.train_model(start_date_str, end_date_str, folder_path, model_paths, fire_size_threshold=300, region_dividing_longitude=-100)\n  File \"fc_model_creation.py\", line 163, in train_model\n    subset_data = pd.concat(all_data[key], axis=0).dropna(subset=[self.target_col])\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1721368940069,
  "history_end_time" : 1721368949616,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "BpgNwtrDhFZa",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = [\n            'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n        ]\n        self.model_handler = self.init_model_handler(model_type)\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_path):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        all_data = []\n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Training on {date_str}\")\n            X, y = self.prepare_training_data(folder_path, date_str)\n            X[self.target_col] = np.log10(y + 1e-2)\n            all_data.append(X)\n            current_date += timedelta(days=1)\n\n        all_data_combined = pd.concat(all_data, axis=0).dropna(subset=[self.target_col])\n        X = all_data_combined[self.chosen_input_columns]\n        y = all_data_combined[self.target_col]\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n        self.model_handler.fit(X_train, y_train)\n        y_pred_test = self.model_handler.predict(X_test)\n\n        mse = mean_squared_error(y_test, y_pred_test)\n        rmse = np.sqrt(mse)\n        mae = mean_absolute_error(y_test, y_pred_test)\n        r2 = r2_score(y_test, y_pred_test)\n\n        print(f\"Mean Squared Error (MSE): {mse}\")\n        print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n        print(f\"Mean Absolute Error (MAE): {mae}\")\n        print(f\"R-squared (R2): {r2}\")\n\n        self.model_handler.save_model(model_path)\n\n        now = datetime.now()\n        date_time = now.strftime(\"%Y%d%m%H%M%S\")\n        random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n        self.model_handler.save_model(random_model_path)\n        print(f\"A copy of the model is saved to {random_model_path}\")\n\n\n# Define global variable that can be imported by others\nmodel_type = \"lightgbm\"\nmodel_path = f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_model_v5_latest.pkl\"\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\ntraining_data_folder=\"/groups/ESS3/zsun/firecasting/data/train/\"\n\nif __name__ == \"__main__\":\n\n    \n    trainer = WildfireModelTrainer(model_type=model_type, training_data_folder=training_data_folder)\n    start_date_str = \"20200109\"\n    end_date_str = \"20201230\"\n    \n    # final model path\n    #model_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n    #model_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v2_latest.pkl\"\n    # model_type = \"tabnet\"\n     # added the land use to distinguish the different geographical areas\n    #model_path = \"/groups/ESS3/zsun/firecasting/model/fc_tabnet_model_v1_latest.pkl\"\n    trainer.train_model(start_date_str, end_date_str, folder_path, model_path)\n    print(f\"Training completed and model saved to {model_path}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nTraining on 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nTraining on 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nTraining on 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nTraining on 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nTraining on 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nTraining on 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nTraining on 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nTraining on 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nTraining on 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nTraining on 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nTraining on 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nTraining on 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nTraining on 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200121_time_series_with_new_window.csv exists\nTraining on 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200122_time_series_with_new_window.csv exists\nTraining on 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200123_time_series_with_new_window.csv exists\nTraining on 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200124_time_series_with_new_window.csv exists\nTraining on 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200125_time_series_with_new_window.csv exists\nTraining on 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200126_time_series_with_new_window.csv exists\nTraining on 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200127_time_series_with_new_window.csv exists\nTraining on 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200128_time_series_with_new_window.csv exists\nTraining on 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200129_time_series_with_new_window.csv exists\nTraining on 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200130_time_series_with_new_window.csv exists\nTraining on 20200131\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200131_time_series_with_new_window.csv exists\nTraining on 20200201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200201_time_series_with_new_window.csv exists\nTraining on 20200202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200202_time_series_with_new_window.csv exists\nTraining on 20200203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200203_time_series_with_new_window.csv exists\nTraining on 20200204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200204_time_series_with_new_window.csv exists\nTraining on 20200205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200205_time_series_with_new_window.csv exists\nTraining on 20200206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200206_time_series_with_new_window.csv exists\nTraining on 20200207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200207_time_series_with_new_window.csv exists\nTraining on 20200208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200208.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200207.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200206.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200205.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200204.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200203.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200202.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200201.txt\nTraining on 20200209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200209.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200208.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200207.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200206.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200205.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200204.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200203.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200202.txt\nTraining on 20200210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200210.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200209.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200208.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200207.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200206.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200205.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200204.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200203.txt\nTraining on 20200211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200211.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200210.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200209.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200208.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200207.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200206.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200205.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200204.txt\nTraining on 20200212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200212.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200211.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200210.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200209.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200208.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200207.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200206.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200205.txt\nTraining on 20200213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200213.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200212.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200211.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200210.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200209.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200208.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200207.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200206.txt\nTraining on 20200214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200214.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200213.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200212.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200211.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200210.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200209.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200208.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200207.txt\nTraining on 20200215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200215.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200214.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200213.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200212.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200211.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200210.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200209.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200208.txt\nTraining on 20200216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200216.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200215.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200214.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200213.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200212.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200211.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200210.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200209.txt\nTraining on 20200217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200217.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200216.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200215.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200214.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200213.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200212.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200211.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200210.txt\nTraining on 20200218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200218.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200217.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200216.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200215.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200214.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200213.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200212.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200211.txt\nTraining on 20200219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200219.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200218.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200217.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200216.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200215.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200214.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200213.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200212.txt\nTraining on 20200220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200220.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200219.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200218.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200217.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200216.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200215.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200214.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200213.txt\nTraining on 20200221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200221.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200220.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200219.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200218.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200217.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200216.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200215.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200214.txt\nTraining on 20200222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200222.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200221.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200220.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200219.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200218.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200217.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200216.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200215.txt\nTraining on 20200223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200223.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200222.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200221.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200220.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200219.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200218.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200217.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200216.txt\nTraining on 20200224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200224.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200223.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200222.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200221.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200220.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200219.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200218.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200217.txt\nTraining on 20200225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200225.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200224.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200223.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200222.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200221.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200220.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200219.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200218.txt\nTraining on 20200226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200226.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200225.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200224.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200223.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200222.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200221.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200220.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200219.txt\nTraining on 20200227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200227.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200226.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200225.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200224.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200223.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200222.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200221.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200220.txt\nTraining on 20200228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200228.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200227.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200226.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200225.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200224.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200223.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200222.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200221.txt\nTraining on 20200229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200229.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200228.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200227.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200226.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200225.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200224.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200223.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200222.txt\nTraining on 20200301\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200301.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200229.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200228.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200227.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200226.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200225.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200224.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200223.txt\nTraining on 20200302\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200302.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200301.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200229.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200228.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200227.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200226.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200225.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200224.txt\nTraining on 20200303\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200303.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200302.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200301.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200229.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200228.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200227.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200226.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200225.txt\nTraining on 20200304\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200304.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200303.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200302.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200301.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200229.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200228.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200227.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200226.txt\nTraining on 20200305\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200305.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200304.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200303.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200302.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200301.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200229.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200228.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200227.txt\nTraining on 20200306\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200306.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200305.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200304.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200303.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200302.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200301.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200229.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200228.txt\nTraining on 20200307\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200307.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200306.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200305.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200304.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200303.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200302.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200301.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200229.txt\nTraining on 20200308\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200308.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200307.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200306.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200305.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200304.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200303.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200302.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200301.txt\nTraining on 20200309\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200309.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200308.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200307.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200306.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200305.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200304.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200303.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200302.txt\nTraining on 20200310\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200310.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200309.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200308.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200307.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200306.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200305.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200304.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200303.txt\nTraining on 20200311\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200311.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200310.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200309.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200308.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200307.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200306.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200305.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200304.txt\nTraining on 20200312\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200312.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200311.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200310.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200309.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200308.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200307.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200306.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200305.txt\nTraining on 20200313\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200313.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200312.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200311.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200310.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200309.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200308.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200307.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200306.txt\nTraining on 20200314\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200314.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200313.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200312.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200311.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200310.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200309.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200308.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200307.txt\nTraining on 20200315\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200315.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200314.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200313.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200312.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200311.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200310.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200309.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200308.txt\nTraining on 20200316\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200316.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200315.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200314.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200313.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200312.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200311.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200310.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200309.txt\nTraining on 20200317\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200317.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200316.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200315.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200314.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200313.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200312.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200311.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200310.txt\nTraining on 20200318\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200318.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200317.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200316.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200315.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200314.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200313.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200312.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200311.txt\nTraining on 20200319\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200319.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200318.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200317.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200316.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200315.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200314.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200313.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200312.txt\nTraining on 20200320\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200320.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200319.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200318.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200317.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200316.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200315.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200314.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200313.txt\nTraining on 20200321\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200321.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200320.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200319.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200318.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200317.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200316.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200315.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200314.txt\nTraining on 20200322\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200322.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200321.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200320.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200319.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200318.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200317.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200316.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200315.txt\nTraining on 20200323\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200323.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200322.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200321.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200320.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200319.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200318.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200317.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200316.txt\nTraining on 20200324\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200324.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200323.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200322.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200321.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200320.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200319.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200318.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200317.txt\nTraining on 20200325\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200325.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200324.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200323.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200322.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200321.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200320.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200319.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200318.txt\nTraining on 20200326\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200326.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200325.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200324.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200323.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200322.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200321.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200320.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200319.txt\nTraining on 20200327\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200327.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200326.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200325.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200324.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200323.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200322.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200321.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200320.txt\nTraining on 20200328\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200328.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200327.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200326.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200325.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200324.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200323.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200322.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200321.txt\nTraining on 20200329\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200329.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200328.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200327.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200326.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200325.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200324.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200323.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200322.txt\nTraining on 20200330\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200330.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200329.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200328.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200327.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200326.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200325.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200324.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200323.txt\nTraining on 20200331\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200331.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200330.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200329.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200328.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200327.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200326.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200325.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200324.txt\nTraining on 20200401\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200401.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200331.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200330.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200329.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200328.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200327.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200326.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200325.txt\nTraining on 20200402\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200402.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200401.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200331.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200330.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200329.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200328.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200327.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200326.txt\nTraining on 20200403\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200403.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200402.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200401.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200331.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200330.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200329.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200328.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200327.txt\nTraining on 20200404\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200404.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200403.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200402.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200401.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200331.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200330.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200329.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200328.txt\nTraining on 20200405\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200405.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200404.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200403.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200402.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200401.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200331.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200330.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200329.txt\nTraining on 20200406\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200406.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200405.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200404.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200403.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200402.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200401.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200331.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200330.txt\nTraining on 20200407\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200407.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200406.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200405.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200404.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200403.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200402.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200401.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200331.txt\nTraining on 20200408\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200408.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200407.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200406.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200405.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200404.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200403.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200402.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200401.txt\nTraining on 20200409\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200409.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200408.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200407.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200406.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200405.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200404.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200403.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200402.txt\nTraining on 20200410\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200410.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200409.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200408.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200407.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200406.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200405.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200404.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200403.txt\nTraining on 20200411\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200411.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200410.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200409.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200408.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200407.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200406.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200405.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200404.txt\nTraining on 20200412\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200412.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200411.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200410.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200409.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200408.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200407.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200406.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200405.txt\nTraining on 20200413\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200413.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200412.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200411.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200410.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200409.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200408.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200407.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200406.txt\nTraining on 20200414\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200414.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200413.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200412.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200411.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200410.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200409.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200408.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200407.txt\nTraining on 20200415\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200415.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200414.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200413.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200412.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200411.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200410.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200409.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200408.txt\nTraining on 20200416\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200416.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200415.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200414.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200413.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200412.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200411.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200410.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200409.txt\nTraining on 20200417\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200417.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200416.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200415.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200414.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200413.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200412.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200411.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200410.txt\nTraining on 20200418\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200418.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200417.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200416.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200415.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200414.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200413.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200412.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200411.txt\nTraining on 20200419\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200419.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200418.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200417.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200416.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200415.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200414.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200413.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200412.txt\nTraining on 20200420\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200420.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200419.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200418.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200417.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200416.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200415.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200414.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200413.txt\nTraining on 20200421\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200421.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200420.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200419.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200418.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200417.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200416.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200415.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200414.txt\nTraining on 20200422\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200422.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200421.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200420.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200419.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200418.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200417.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200416.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200415.txt\nTraining on 20200423\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200423.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200422.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200421.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200420.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200419.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200418.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200417.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200416.txt\nTraining on 20200424\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200424.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200423.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200422.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200421.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200420.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200419.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200418.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200417.txt\nTraining on 20200425\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200425.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200424.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200423.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200422.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200421.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200420.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200419.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200418.txt\nTraining on 20200426\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200426.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200425.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200424.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200423.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200422.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200421.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200420.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200419.txt\nTraining on 20200427\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200427.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200426.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200425.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200424.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200423.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200422.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200421.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200420.txt\nTraining on 20200428\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200428.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200427.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200426.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200425.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200424.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200423.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200422.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200421.txt\nTraining on 20200429\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200429.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200428.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200427.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200426.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200425.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200424.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200423.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200422.txt\nTraining on 20200430\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200430.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200429.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200428.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200427.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200426.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200425.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200424.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200423.txt\nTraining on 20200501\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200501.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200430.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200429.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200428.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200427.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200426.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200425.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200424.txt\nTraining on 20200502\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200502.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200501.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200430.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200429.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200428.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200427.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200426.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200425.txt\nTraining on 20200503\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200503.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200502.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200501.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200430.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200429.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200428.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200427.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200426.txt\nTraining on 20200504\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200504.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200503.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200502.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200501.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200430.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200429.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200428.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200427.txt\nTraining on 20200505\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200505.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200504.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200503.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200502.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200501.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200430.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200429.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200428.txt\nTraining on 20200506\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200506.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200505.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200504.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200503.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200502.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200501.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200430.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200429.txt\nTraining on 20200507\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200507.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200506.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200505.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200504.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200503.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200502.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200501.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200430.txt\nTraining on 20200508\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200508.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200507.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200506.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200505.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200504.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200503.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200502.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200501.txt\nTraining on 20200509\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200509.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200508.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200507.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200506.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200505.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200504.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200503.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200502.txt\nTraining on 20200510\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200510.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200509.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200508.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200507.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200506.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200505.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200504.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200503.txt\nTraining on 20200511\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200511.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200510.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200509.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200508.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200507.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200506.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200505.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200504.txt\nTraining on 20200512\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200512.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200511.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200510.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200509.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200508.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200507.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200506.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200505.txt\nTraining on 20200513\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200513.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200512.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200511.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200510.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200509.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200508.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200507.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200506.txt\nTraining on 20200514\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200514.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200513.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200512.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200511.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200510.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200509.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200508.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200507.txt\nTraining on 20200515\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200515.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200514.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200513.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200512.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200511.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200510.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200509.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200508.txt\nTraining on 20200516\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200516.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200515.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200514.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200513.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200512.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200511.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200510.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200509.txt\nTraining on 20200517\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200517.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200516.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200515.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200514.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200513.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200512.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200511.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200510.txt\nTraining on 20200518\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200518.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200517.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200516.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200515.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200514.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200513.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200512.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200511.txt\nTraining on 20200519\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200519.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200518.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200517.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200516.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200515.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200514.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200513.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200512.txt\nTraining on 20200520\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200520.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200519.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200518.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200517.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200516.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200515.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200514.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200513.txt\nTraining on 20200521\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200521.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200520.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200519.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200518.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200517.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200516.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200515.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200514.txt\nTraining on 20200522\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200522.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200521.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200520.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200519.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200518.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200517.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200516.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200515.txt\nTraining on 20200523\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200523.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200522.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200521.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200520.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200519.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200518.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200517.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200516.txt\nTraining on 20200524\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200524.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200523.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200522.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200521.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200520.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200519.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200518.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200517.txt\nTraining on 20200525\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200525.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200524.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200523.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200522.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200521.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200520.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200519.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200518.txt\nTraining on 20200526\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200526.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200525.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200524.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200523.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200522.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200521.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200520.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200519.txt\nTraining on 20200527\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200527.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200526.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200525.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200524.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200523.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200522.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200521.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200520.txt\nTraining on 20200528\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200528.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200527.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200526.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200525.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200524.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200523.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200522.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200521.txt\nTraining on 20200529\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200529.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200528.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200527.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200526.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200525.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200524.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200523.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200522.txt\nTraining on 20200530\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200530.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200529.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200528.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200527.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200526.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200525.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200524.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200523.txt\nTraining on 20200531\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200531.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200530.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200529.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200528.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200527.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200526.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200525.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200524.txt\nTraining on 20200601\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200601.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200531.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200530.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200529.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200528.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200527.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200526.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200525.txt\nTraining on 20200602\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200602.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200601.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200531.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200530.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200529.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200528.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200527.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200526.txt\nTraining on 20200603\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200603.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200602.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200601.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200531.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200530.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200529.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200528.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200527.txt\nTraining on 20200604\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200604.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200603.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200602.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200601.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200531.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200530.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200529.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200528.txt\nTraining on 20200605\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200605.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200604.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200603.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200602.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200601.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200531.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200530.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200529.txt\nTraining on 20200606\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200606.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200605.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200604.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200603.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200602.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200601.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200531.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200530.txt\nTraining on 20200607\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200607.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200606.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200605.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200604.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200603.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200602.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200601.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200531.txt\nTraining on 20200608\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200608.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200607.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200606.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200605.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200604.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200603.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200602.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200601.txt\nTraining on 20200609\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200609.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200608.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200607.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200606.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200605.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200604.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200603.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200602.txt\nTraining on 20200610\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200610.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200609.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200608.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200607.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200606.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200605.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200604.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200603.txt\nTraining on 20200611\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200611.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200610.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200609.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200608.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200607.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200606.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200605.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200604.txt\nTraining on 20200612\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200612.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200611.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200610.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200609.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200608.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200607.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200606.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200605.txt\nTraining on 20200613\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200613.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200612.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200611.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200610.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200609.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200608.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200607.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200606.txt\nTraining on 20200614\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200614.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200613.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200612.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200611.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200610.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200609.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200608.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200607.txt\nTraining on 20200615\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200615.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200614.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200613.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200612.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200611.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200610.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200609.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200608.txt\nTraining on 20200616\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200616.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200615.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200614.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200613.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200612.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200611.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200610.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200609.txt\nTraining on 20200617\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200617.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200616.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200615.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200614.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200613.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200612.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200611.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200610.txt\nTraining on 20200618\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200618.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200617.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200616.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200615.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200614.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200613.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200612.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200611.txt\nTraining on 20200619\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200619.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200618.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200617.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200616.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200615.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200614.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200613.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200612.txt\nTraining on 20200620\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200620.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200619.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200618.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200617.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200616.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200615.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200614.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200613.txt\nTraining on 20200621\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200621.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200620.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200619.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200618.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200617.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200616.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200615.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200614.txt\nTraining on 20200622\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200622.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200621.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200620.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200619.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200618.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200617.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200616.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200615.txt\nTraining on 20200623\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200623.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200622.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200621.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200620.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200619.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200618.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200617.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200616.txt\nTraining on 20200624\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200624.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200623.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200622.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200621.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200620.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200619.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200618.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200617.txt\nTraining on 20200625\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200625.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200624.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200623.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200622.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200621.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200620.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200619.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200618.txt\nTraining on 20200626\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200626.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200625.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200624.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200623.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200622.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200621.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200620.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200619.txt\nTraining on 20200627\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200627.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200626.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200625.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200624.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200623.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200622.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200621.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200620.txt\nTraining on 20200628\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200628.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200627.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200626.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200625.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200624.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200623.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200622.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200621.txt\nTraining on 20200629\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200629.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200628.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200627.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200626.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200625.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200624.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200623.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200622.txt\nTraining on 20200630\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200630.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200629.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200628.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200627.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200626.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200625.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200624.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200623.txt\nTraining on 20200701\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200701.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200630.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200629.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200628.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200627.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200626.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200625.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200624.txt\nTraining on 20200702\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200702.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200701.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200630.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200629.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200628.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200627.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200626.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200625.txt\nTraining on 20200703\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200703.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200702.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200701.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200630.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200629.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200628.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200627.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200626.txt\nTraining on 20200704\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200704.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200703.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200702.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200701.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200630.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200629.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200628.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200627.txt\nTraining on 20200705\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200705.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200704.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200703.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200702.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200701.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200630.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200629.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200628.txt\nTraining on 20200706\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200706.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200705.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200704.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200703.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200702.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200701.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200630.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200629.txt\nTraining on 20200707\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200707.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200706.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200705.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200704.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200703.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200702.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200701.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200630.txt\nTraining on 20200708\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200708.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200707.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200706.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200705.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200704.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200703.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200702.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200701.txt\nTraining on 20200709\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200709.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200708.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200707.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200706.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200705.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200704.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200703.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200702.txt\nTraining on 20200710\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200710.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200709.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200708.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200707.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200706.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200705.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200704.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200703.txt\nTraining on 20200711\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200711.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200710.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200709.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200708.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200707.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200706.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200705.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200704.txt\nTraining on 20200712\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200712.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200711.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200710.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200709.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200708.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200707.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200706.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200705.txt\nTraining on 20200713\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200713.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200712.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200711.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200710.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200709.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200708.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200707.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200706.txt\nTraining on 20200714\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200714.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200713.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200712.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200711.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200710.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200709.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200708.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200707.txt\nTraining on 20200715\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200715.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200714.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200713.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200712.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200711.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200710.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200709.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200708.txt\nTraining on 20200716\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200716.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200715.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200714.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200713.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200712.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200711.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200710.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200709.txt\nTraining on 20200717\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200717.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200716.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200715.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200714.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200713.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200712.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200711.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200710.txt\nTraining on 20200718\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200718.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200717.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200716.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200715.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200714.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200713.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200712.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200711.txt\nTraining on 20200719\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200719.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200718.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200717.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200716.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200715.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200714.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200713.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200712.txt\nTraining on 20200720\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200720.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200719.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200718.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200717.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200716.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200715.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200714.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200713.txt\nTraining on 20200721\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200721.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200720.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200719.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200718.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200717.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200716.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200715.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200714.txt\nTraining on 20200722\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200722.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200721.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200720.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200719.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200718.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200717.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200716.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200715.txt\nTraining on 20200723\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200723.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200722.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200721.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200720.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200719.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200718.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200717.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200716.txt\nTraining on 20200724\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200724.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200723.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200722.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200721.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200720.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200719.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200718.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200717.txt\nTraining on 20200725\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200725.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200724.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200723.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200722.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200721.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200720.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200719.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200718.txt\nTraining on 20200726\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200726.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200725.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200724.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200723.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200722.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200721.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200720.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200719.txt\nTraining on 20200727\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200727.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200726.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200725.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200724.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200723.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200722.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200721.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200720.txt\nTraining on 20200728\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200728.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200727.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200726.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200725.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200724.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200723.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200722.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200721.txt\nTraining on 20200729\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200729.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200728.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200727.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200726.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200725.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200724.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200723.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200722.txt\nTraining on 20200730\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200730.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200729.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200728.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200727.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200726.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200725.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200724.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200723.txt\nTraining on 20200731\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200731.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200730.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200729.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200728.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200727.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200726.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200725.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200724.txt\nTraining on 20200801\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200801.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200731.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200730.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200729.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200728.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200727.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200726.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200725.txt\nTraining on 20200802\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200802.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200801.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200731.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200730.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200729.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200728.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200727.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200726.txt\nTraining on 20200803\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200803.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200802.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200801.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200731.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200730.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200729.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200728.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200727.txt\nTraining on 20200804\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200804.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200803.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200802.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200801.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200731.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200730.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200729.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200728.txt\nTraining on 20200805\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200805.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200804.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200803.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200802.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200801.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200731.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200730.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200729.txt\nTraining on 20200806\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200806.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200805.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200804.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200803.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200802.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200801.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200731.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200730.txt\nTraining on 20200807\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200807.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200806.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200805.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200804.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200803.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200802.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200801.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200731.txt\nTraining on 20200808\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200808.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200807.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200806.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200805.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200804.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200803.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200802.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200801.txt\nTraining on 20200809\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200809.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200808.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200807.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200806.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200805.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200804.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200803.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200802.txt\nTraining on 20200810\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200810.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200809.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200808.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200807.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200806.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200805.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200804.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200803.txt\nTraining on 20200811\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200811.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200810.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200809.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200808.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200807.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200806.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200805.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200804.txt\nTraining on 20200812\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200812.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200811.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200810.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200809.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200808.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200807.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200806.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200805.txt\nTraining on 20200813\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200813.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200812.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200811.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200810.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200809.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200808.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200807.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200806.txt\nTraining on 20200814\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200814.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200813.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200812.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200811.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200810.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200809.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200808.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200807.txt\nTraining on 20200815\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200815.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200814.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200813.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200812.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200811.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200810.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200809.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200808.txt\nTraining on 20200816\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200816.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200815.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200814.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200813.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200812.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200811.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200810.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200809.txt\nTraining on 20200817\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200817.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200816.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200815.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200814.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200813.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200812.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200811.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200810.txt\nTraining on 20200818\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200818.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200817.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200816.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200815.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200814.txt\n",
  "history_begin_time" : 1721367713219,
  "history_end_time" : 1721368927474,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "6K2e7CnPXCiW",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = [\n            'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n        ]\n        self.model_handler = self.init_model_handler(model_type)\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_path):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        all_data = []\n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Training on {date_str}\")\n            X, y = self.prepare_training_data(folder_path, date_str)\n            X[self.target_col] = np.log10(y + 1e-2)\n            all_data.append(X)\n            current_date += timedelta(days=1)\n\n        all_data_combined = pd.concat(all_data, axis=0).dropna(subset=[self.target_col])\n        X = all_data_combined[self.chosen_input_columns]\n        y = all_data_combined[self.target_col]\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n        self.model_handler.fit(X_train, y_train)\n        y_pred_test = self.model_handler.predict(X_test)\n\n        mse = mean_squared_error(y_test, y_pred_test)\n        rmse = np.sqrt(mse)\n        mae = mean_absolute_error(y_test, y_pred_test)\n        r2 = r2_score(y_test, y_pred_test)\n\n        print(f\"Mean Squared Error (MSE): {mse}\")\n        print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n        print(f\"Mean Absolute Error (MAE): {mae}\")\n        print(f\"R-squared (R2): {r2}\")\n\n        self.model_handler.save_model(model_path)\n\n        now = datetime.now()\n        date_time = now.strftime(\"%Y%d%m%H%M%S\")\n        random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n        self.model_handler.save_model(random_model_path)\n        print(f\"A copy of the model is saved to {random_model_path}\")\n\n\nif __name__ == \"__main__\":\n\n    model_type = \"lightgbm\"\n    trainer = WildfireModelTrainer(model_type=model_type, training_data_folder=\"/groups/ESS3/zsun/firecasting/data/train/\")\n    start_date_str = \"20200109\"\n    end_date_str = \"20200120\"\n    folder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\n    # final model path\n    #model_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n    #model_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v2_latest.pkl\"\n    # model_type = \"tabnet\"\n    model_path = f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_model_v3_latest.pkl\" # added the land use to distinguish the different geographical areas\n    #model_path = \"/groups/ESS3/zsun/firecasting/model/fc_tabnet_model_v1_latest.pkl\"\n    trainer.train_model(start_date_str, end_date_str, folder_path, model_path)\n    print(f\"Training completed and model saved to {model_path}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nTraining on 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200109_time_series_with_new_window.csv exists\nTraining on 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200110_time_series_with_new_window.csv exists\nTraining on 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200111_time_series_with_new_window.csv exists\nTraining on 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200112_time_series_with_new_window.csv exists\nTraining on 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200113_time_series_with_new_window.csv exists\nTraining on 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200114_time_series_with_new_window.csv exists\nTraining on 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200115_time_series_with_new_window.csv exists\nTraining on 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200116_time_series_with_new_window.csv exists\nTraining on 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200117_time_series_with_new_window.csv exists\nTraining on 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200118_time_series_with_new_window.csv exists\nTraining on 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200119_time_series_with_new_window.csv exists\nTraining on 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nFile /groups/ESS3/zsun/firecasting/data/train/20200120_time_series_with_new_window.csv exists\nMean Squared Error (MSE): 0.43534028040119227\nRoot Mean Squared Error (RMSE): 0.659803213391078\nMean Absolute Error (MAE): 0.2829583009179572\nR-squared (R2): 0.038069836125811385\nA copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v3_latest.pkl_20200109_20200120_20241907013754.pkl\nTraining completed and model saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v3_latest.pkl\n",
  "history_begin_time" : 1721367453032,
  "history_end_time" : 1721367475633,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "E3ZMT27IOWt7",
  "history_input" : "import os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport pickle\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\nclass ModelHandler:\n    def fit(self, X_train, y_train):\n        raise NotImplementedError\n\n    def predict(self, X_test):\n        raise NotImplementedError\n\n    def save_model(self, model, model_path):\n        raise NotImplementedError\n\n    def load_model(self, model_path):\n        raise NotImplementedError\n\n\nclass LightGBMHandler(ModelHandler):\n    def __init__(self):\n        self.model = LGBMRegressor(n_jobs=-1, random_state=42)\n\n    def fit(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n    def save_model(self, model_path):\n        with open(model_path, 'wb') as model_file:\n            pickle.dump(self.model, model_file)\n\n    def load_model(self, model_path):\n        with open(model_path, 'rb') as model_file:\n            self.model = pickle.load(model_file)\n\n\nclass TabNetHandler(ModelHandler):\n    def __init__(self):\n        self.model = TabNetRegressor(\n            n_d=17,\n            n_a=41,\n            n_steps=4,\n            gamma=1.1546672563068268,\n            lambda_sparse=0.00042602006758391\n        )\n\n    def fit(self, X_train, y_train):\n        y_train = y_train.to_numpy().reshape(-1, 1)\n        self.model.fit(\n            X_train.values, y_train,\n            eval_set=[(X_train.values, y_train)],\n            eval_metric=['mae'],\n            max_epochs=100,\n            patience=10,\n            batch_size=256,\n            virtual_batch_size=128,\n        )\n\n    def predict(self, X_test):\n        return self.model.predict(X_test.values)\n\n    def save_model(self, model_path):\n        self.model.save_model(model_path)\n\n    def load_model(self, model_path):\n        self.model.load_model(model_path)\n    \n\n\nclass WildfireModelTrainer:\n    def __init__(self, model_type=\"lightgbm\", training_data_folder=\"/path/to/training/data\"):\n        self.training_data_folder = training_data_folder\n        self.target_col = 'FRP'\n        self.chosen_input_columns = [\n            'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD', 'V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use', 'RH'\n        ]\n        self.model_handler = self.init_model_handler(model_type)\n\n    def init_model_handler(self, model_type):\n        if model_type == \"tabnet\":\n            return TabNetHandler()\n        else:\n            return LightGBMHandler()\n\n    def read_original_txt_files(self, folder_path, datestr):\n        file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n        print(f\"Reading original file: {file_path}\")\n        return pd.read_csv(file_path)\n\n    def get_one_day_time_series_training_data(self, folder_path, target_day):\n        df = self.read_original_txt_files(folder_path, target_day)\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i + 1)\n            past_df = self.read_original_txt_files(folder_path, past_dt.strftime('%Y%m%d'))\n            for c in ['FWI', 'VPD', 'P', 'FRP']:\n                df[f'{c}_{i + 1}_days_ago'] = past_df[c]\n        return df\n\n    def prepare_training_data(self, folder_path, target_date):\n        if not os.path.exists(self.training_data_folder):\n            os.makedirs(self.training_data_folder)\n            print(f\"Folder created: {self.training_data_folder}\")\n        else:\n            print(f\"Folder already exists: {self.training_data_folder}\")\n\n        train_file_path = os.path.join(self.training_data_folder, f\"{target_date}_time_series_with_new_window.csv\")\n\n        if os.path.exists(train_file_path):\n            print(f\"File {train_file_path} exists\")\n            df = pd.read_csv(train_file_path)\n        else:\n            df = self.get_one_day_time_series_training_data(folder_path, target_date)\n            df.fillna(-999, inplace=True)\n            df = df[(df[['FRP_1_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8']] > 0).any(axis=1)]\n            df.to_csv(train_file_path, index=False)\n\n        X = df[self.chosen_input_columns]\n        y = df[self.target_col]\n        return X, y\n\n    def train_model(self, start_date_str, end_date_str, folder_path, model_path):\n        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n        current_date = start_date\n\n        all_data = []\n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y%m%d\")\n            print(f\"Training on {date_str}\")\n            X, y = self.prepare_training_data(folder_path, date_str)\n            X[self.target_col] = np.log10(y + 1e-2)\n            all_data.append(X)\n            current_date += timedelta(days=1)\n\n        all_data_combined = pd.concat(all_data, axis=0).dropna(subset=[self.target_col])\n        X = all_data_combined[self.chosen_input_columns]\n        y = all_data_combined[self.target_col]\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n        self.model_handler.fit(X_train, y_train)\n        y_pred_test = self.model_handler.predict(X_test)\n\n        mse = mean_squared_error(y_test, y_pred_test)\n        rmse = np.sqrt(mse)\n        mae = mean_absolute_error(y_test, y_pred_test)\n        r2 = r2_score(y_test, y_pred_test)\n\n        print(f\"Mean Squared Error (MSE): {mse}\")\n        print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n        print(f\"Mean Absolute Error (MAE): {mae}\")\n        print(f\"R-squared (R2): {r2}\")\n\n        self.model_handler.save_model(model_path)\n\n        now = datetime.now()\n        date_time = now.strftime(\"%Y%d%m%H%M%S\")\n        random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n        self.model_handler.save_model(random_model_path)\n        print(f\"A copy of the model is saved to {random_model_path}\")\n\n\nif __name__ == \"__main__\":\n\n    model_type = \"lightgbm\"\n    trainer = WildfireModelTrainer(model_type=model_type, training_data_folder=\"/groups/ESS3/zsun/firecasting/data/train/\")\n    start_date_str = \"20200109\"\n    end_date_str = \"20201231\"\n    folder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata_VHI'\n    # final model path\n    #model_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n    #model_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v2_latest.pkl\"\n    # model_type = \"tabnet\"\n    model_path = f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_model_v3_latest.pkl\" # added the land use to distinguish the different geographical areas\n    #model_path = \"/groups/ESS3/zsun/firecasting/model/fc_tabnet_model_v1_latest.pkl\"\n    trainer.train_model(start_date_str, end_date_str, folder_path, model_path)\n    print(f\"Training completed and model saved to {model_path}\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nTraining on 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200109.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200108.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200107.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200106.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200105.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200104.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200103.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200102.txt\nTraining on 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200110.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200109.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200108.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200107.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200106.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200105.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200104.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200103.txt\nTraining on 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200111.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200110.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200109.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200108.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200107.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200106.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200105.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200104.txt\nTraining on 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200112.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200111.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200110.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200109.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200108.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200107.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200106.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200105.txt\nTraining on 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200113.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200112.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200111.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200110.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200109.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200108.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200107.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200106.txt\nTraining on 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200114.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200113.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200112.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200111.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200110.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200109.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200108.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200107.txt\nTraining on 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200115.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200114.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200113.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200112.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200111.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200110.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200109.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200108.txt\nTraining on 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200116.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200115.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200114.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200113.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200112.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200111.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200110.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200109.txt\nTraining on 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200117.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200116.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200115.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200114.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200113.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200112.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200111.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200110.txt\nTraining on 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200118.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200117.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200116.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200115.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200114.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200113.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200112.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200111.txt\nTraining on 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200119.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200118.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200117.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200116.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200115.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200114.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200113.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200112.txt\nTraining on 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200120.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200119.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200118.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200117.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200116.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200115.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200114.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200113.txt\nTraining on 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200121.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200120.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200119.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200118.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200117.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200116.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200115.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200114.txt\nTraining on 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200122.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200121.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200120.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200119.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200118.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200117.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200116.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200115.txt\nTraining on 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200123.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200122.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200121.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200120.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200119.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200118.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200117.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200116.txt\nTraining on 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200124.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200123.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200122.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200121.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200120.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200119.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200118.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200117.txt\nTraining on 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200125.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200124.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200123.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200122.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200121.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200120.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200119.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200118.txt\nTraining on 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200126.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200125.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200124.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200123.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200122.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200121.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200120.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200119.txt\nTraining on 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200127.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200126.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200125.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200124.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200123.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200122.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200121.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200120.txt\nTraining on 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200128.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200127.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200126.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200125.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200124.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200123.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200122.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200121.txt\nTraining on 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200129.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200128.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200127.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200126.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200125.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200124.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200123.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200122.txt\nTraining on 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200130.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200129.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200128.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200127.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200126.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200125.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200124.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200123.txt\nTraining on 20200131\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200131.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200130.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200129.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200128.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200127.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200126.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200125.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200124.txt\nTraining on 20200201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200201.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200131.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200130.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200129.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200128.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200127.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200126.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200125.txt\nTraining on 20200202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200202.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200201.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200131.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200130.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200129.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200128.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200127.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200126.txt\nTraining on 20200203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200203.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200202.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200201.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200131.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200130.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200129.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200128.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200127.txt\nTraining on 20200204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200204.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200203.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200202.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200201.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200131.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200130.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200129.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200128.txt\nTraining on 20200205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200205.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200204.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200203.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200202.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200201.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200131.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200130.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200129.txt\nTraining on 20200206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200206.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200205.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200204.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200203.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200202.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200201.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200131.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200130.txt\nTraining on 20200207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200207.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200206.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200205.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200204.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200203.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200202.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200201.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200131.txt\nTraining on 20200208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200208.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200207.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200206.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200205.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200204.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200203.txt\nReading original file: /groups/ESS3/yli74/data/AI_Emis/firedata_VHI/firedata_20200202.txt\n",
  "history_begin_time" : 1721367220431,
  "history_end_time" : 1721367434830,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "c64ai52k276",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1721364488162,
  "history_end_time" : 1721364488162,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5R5bjzDjCiAY",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nfrom lightgbm import LGBMRegressor\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\nfrom pytorch_tabnet.tab_model import TabNetRegressor\n\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v2_latest.pkl\"\nmodel_type = \"lightgbm\"\n# model_type = \"tabnet\"\nmodel_path = f\"/groups/ESS3/zsun/firecasting/model/fc_{model_type}_model_v3_latest.pkl\" # added the land use to distinguish the different geographical areas\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_tabnet_model_v1_latest.pkl\"\n\nchosen_input_columns = [\n    'FRP_1_days_ago', 'Nearest_1', 'Nearest_5', 'Nearest_7', 'Nearest_3', 'FRP_2_days_ago', 'VPD','V', 'LAT', 'LON', 'FWI', 'Nearest_17', 'Land_Use','RH', \n\n  #      'HT', 'T', 'U', 'P', 'RAIN', 'CAPE', 'ST',\n\n  # > 'SM', 'Nearest_2',  'Nearest_4', \n\n  # > 'Nearest_6', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n\n  # > 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n\n  # > 'Nearest_16', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n\n  # > 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24', \n\n  # > 'VCI_AVE', 'TCI_AVE', 'VHI_AVE', 'VCI_TOT', 'TCI_TOT', 'VHI_TOT',\n\n  # > 'FWI_1_days_ago', 'VPD_1_days_ago', 'P_1_days_ago', \n\n  # > 'FWI_2_days_ago', 'VPD_2_days_ago', 'P_2_days_ago', \n\n  # > 'FWI_3_days_ago', 'VPD_3_days_ago', 'P_3_days_ago', 'FRP_3_days_ago',\n\n  # > 'FWI_4_days_ago', 'VPD_4_days_ago', 'P_4_days_ago', 'FRP_4_days_ago',\n\n  # > 'FWI_5_days_ago', 'VPD_5_days_ago', 'P_5_days_ago', 'FRP_5_days_ago',\n\n  # > 'FWI_6_days_ago', 'VPD_6_days_ago', 'P_6_days_ago', 'FRP_6_days_ago',\n\n  # > 'FWI_7_days_ago', 'VPD_7_days_ago', 'P_7_days_ago', 'FRP_7_days_ago',\n\n]\n\n\ndef check_model_is_tabnet(loaded_model):\n    # Type check\n    if isinstance(loaded_model, TabNetRegressor):\n        print(\"Loaded model is a TabNet model.\")\n        return True\n    else:\n        print(\"Loaded model is not a TabNet model.\")\n        return False\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder, \n  model_type: str=\"tabnet\"):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  if model_type == \"tabnet\":\n    model = TabNetRegressor(\n        n_d=17,\n        n_a=41,\n        n_steps=4,\n        gamma=1.1546672563068268,\n        lambda_sparse=0.00042602006758391\n    )\n  else:\n#   model = XGBRegressor(n_estimators=100,\n#                        max_depth=8,\n#                        learning_rate=0.1,)\n    model = LGBMRegressor(n_jobs=-1, random_state=42)\n    {'model_type': 'tabnet', 'n_d': 17, 'n_a': 41, 'n_steps': 4, 'gamma': 1.1546672563068268, 'lambda_sparse': 0.00042602006758391}\n  \n  # tabnet_model.fit(\n  #     X_train.values, y_train,\n  #     eval_set=[(X_val.values, y_val)],\n  #     eval_metric=['mae'],\n  #     max_epochs=100,\n  #     patience=10,\n  #     batch_size=256,\n  #     virtual_batch_size=128,\n  # )\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = 'FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    # use log10 to reduce the value range\n    X[target_col] = np.log10(X[target_col]+1e-2)\n    \n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  print(\"X.columns: \", X.columns)\n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n  \n  all_data_combined = all_data_combined.dropna(subset=['FRP'])\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  print(f\"all training data is saved to {all_train_file_path}\")\n  \n  # X = all_data_combined.drop(columns=[target_col])\n  X = all_data_combined[chosen_input_columns]\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe(include='all'))\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  #sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  print(\"y_train.shape = \", y_train.shape)\n  print(\"y_test.shape = \", y_test.shape)\n\n  if model_type == \"tabnet\":\n    # train tabnet\n    y_train_tabnet = y_train.to_numpy().reshape(-1, 1)\n    y_test_tabnet = y_test.to_numpy().reshape(-1, 1)\n    model.fit(\n        X_train.values, y_train_tabnet,\n        eval_set=[(X_test.values, y_test_tabnet)],\n        eval_metric=['mae'],\n        max_epochs=100,\n        patience=10,\n        batch_size=256,\n        virtual_batch_size=128,\n    )\n  else:\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n    model.fit(X_train, y_train)\n\n  # Evaluate the model on test set\n  if model_type == \"tabnet\":\n    y_pred_test = model.predict(X_test.values)\n  else:\n    y_pred_test = model.predict(X_test)\n  \n  print(\"y_pred_test.shape = \", y_pred_test.shape)\n  y_predicted_df = pd.DataFrame(y_pred_test, columns=[\"predicted_FRP\"])\n  print(\"get some statistics of the predicted FRP: \", y_predicted_df[\"predicted_FRP\"].describe())\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  if model_type == \"tabnet\":\n    # Save tabnet to file\n    model.save_model(model_path)\n    \n    now = datetime.now()\n    date_time = now.strftime(\"%Y%d%m%H%M%S\")\n    random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n    model.save_model(random_model_path)\n  else:\n    with open(model_path, 'wb') as model_file:\n        pickle.dump(model, model_file)\n        print(f\"The new model is saved to {model_path}\")\n\n    now = datetime.now()\n    date_time = now.strftime(\"%Y%d%m%H%M%S\")\n    random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n    # Save the model to a file\n    with open(random_model_path, 'wb') as model_file:\n        pickle.dump(model, model_file)\n        print(f\"The new model is saved to {random_model_path}\")\n  \n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {random_model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200109\"\n  end_date_str = \"20201231\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder, model_type)\n  print(\"all training on {training_data_folder} is done\")\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\ntraining on 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200131\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200131_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200301\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200301_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200302\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200302_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200303\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200303_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200304\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200304_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200305\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200305_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200306\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200306_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200307\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200307_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200308\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200308_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200309\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200309_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200310\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200310_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200311\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200311_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200312\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200312_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200313\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200313_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200314\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200314_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200315\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200315_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200316\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200316_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200317\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200317_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200318\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200318_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200319\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200319_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200320\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200320_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200321\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200321_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200322\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200322_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200323\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200323_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200324\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200324_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200325\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200325_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200326\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200326_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200327\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200327_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200328\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200328_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200329\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200329_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200330\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200330_time_series_with_new_window.csv exists\n",
  "history_begin_time" : 1721180711530,
  "history_end_time" : 1721180728255,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "55i751qbwkb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1721133289758,
  "history_end_time" : 1721156176102,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ybal6b1l1wr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1720812753716,
  "history_end_time" : 1720812753716,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rI8xtoBMxq6z",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nfrom lightgbm import LGBMRegressor\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\nfrom pytorch_tabnet.tab_model import TabNetRegressor\n\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v2_latest.pkl\"\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v2_latest.pkl\" # added the land use to distinguish the different geographical areas\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n#   model = XGBRegressor(n_estimators=100,\n#                        max_depth=8,\n#                        learning_rate=0.1,)\n  #model = LGBMRegressor(n_jobs=-1, random_state=42)\n  # {'model_type': 'tabnet', 'n_d': 17, 'n_a': 41, 'n_steps': 4, 'gamma': 1.1546672563068268, 'lambda_sparse': 0.00042602006758391}\n  model = TabNetRegressor(\n      n_d=17,\n      n_a=41,\n      n_steps=4,\n      gamma=1.1546672563068268,\n      lambda_sparse=0.00042602006758391\n  )\n  # tabnet_model.fit(\n  #     X_train.values, y_train,\n  #     eval_set=[(X_val.values, y_val)],\n  #     eval_metric=['mae'],\n  #     max_epochs=100,\n  #     patience=10,\n  #     batch_size=256,\n  #     virtual_batch_size=128,\n  # )\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = 'FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    # use log10 to reduce the value range\n    X[target_col] = np.log10(X[target_col]+1e-2)\n    \n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n  \n  all_data_combined = all_data_combined.dropna(subset=['FRP'])\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  print(f\"all training data is saved to {all_train_file_path}\")\n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe(include='all'))\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  #sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  #model.fit(X_train, y_train)\n\n  \n\n  # train tabnet\n  y_train_tabnet = y_train.to_numpy().reshape(-1, 1)\n  y_test_tabnet = y_test.to_numpy().reshape(-1, 1)\n  model.fit(\n      X_train.values, y_train_tabnet,\n      eval_set=[(X_test.values, y_test_tabnet)],\n      eval_metric=['mae'],\n      max_epochs=100,\n      patience=10,\n      batch_size=256,\n      virtual_batch_size=128,\n  )\n  \n  print(\"y_train.shape = \", y_train.shape)\n  print(\"y_test.shape = \", y_test.shape)\n  \n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test.values)\n  \n  print(\"y_pred_test.shape = \", y_pred_test.shape)\n  y_predicted_df = pd.DataFrame(y_pred_test, columns=[\"predicted_FRP\"])\n  print(\"get some statistics of the predicted FRP: \", y_predicted_df[\"predicted_FRP\"].describe())\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  # with open(model_path, 'wb') as model_file:\n  #     pickle.dump(model, model_file)\n  #     print(f\"The new model is saved to {model_path}\")\n\n  # Save tabnet to file\n  best_model.save_model(model_path)\n  \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  # with open(random_model_path, 'wb') as model_file:\n  #     pickle.dump(model, model_file)\n  #     print(f\"The new model is saved to {random_model_path}\")\n  # Save tabnet to file\n  best_model.save_model(random_model_path)\n  \n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {random_model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200109\"\n  end_date_str = \"20201231\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n  warnings.warn(f\"Device used : {self.device}\")\ntraining on 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200131\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200131_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200301\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200301_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200302\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200302_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200303\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200303_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200304\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200304_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200305\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200305_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200306\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200306_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200307\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200307_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200308\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200308_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200309\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200309_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200310\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200310_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200311\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200311_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200312\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200312_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200313\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200313_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200314\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200314_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200315\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200315_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200316\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200316_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200317\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200317_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200318\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200318_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200319\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200319_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200320\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200320_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200321\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200321_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200322\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200322_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200323\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200323_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200324\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200324_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200325\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200325_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200326\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200326_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200327\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200327_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200328\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200328_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200329\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200329_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200330\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200330_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200331\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200331_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200401\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200401_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200402\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200402_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200403\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200403_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200404\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200404_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200405\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200405_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200406\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200406_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200407\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200407_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200408\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200408_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200409\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200409_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200410\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200410_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200411\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200411_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200412\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200412_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200413\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200413_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200414\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200414_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200415\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200415_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200416\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200416_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200417\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200417_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200418\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200418_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200419\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200419_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200420\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200420_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200421\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200421_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200422\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200422_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200423\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200423_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200424\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200424_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200425\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200425_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200426\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200426_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200427\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200427_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200428\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200428_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200429\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200429_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200430\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200430_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200501\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200501_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200502\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200502_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200503\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200503_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200504\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200504_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200505\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200505_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200506\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200506_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200507\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200507_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200508\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200508_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200509\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200509_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200510\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200510_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200511\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200511_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200512\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200512_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200513\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200513_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200514\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200514_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200515\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200515_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200516\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200516_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200517\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200517_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200518\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200518_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200519\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200519_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200520\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200520_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200521\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200521_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200522\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200522_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200523\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200523_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200524\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200524_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200525\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200525_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200526\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200526_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200527\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200527_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200528\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200528_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200529\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200529_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200530\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200530_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200531\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200531_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200601\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200601_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200602\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200602_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200603\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200603_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200604\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200604_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200605\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200605_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200606\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200606_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200607\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200607_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200608\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200608_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200609\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200609_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200610\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200610_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200611\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200611_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200612\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200612_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200613\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200613_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200614\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200614_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200615\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200615_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200616\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200616_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200617\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200617_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200618\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200618_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200619\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200619_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200620\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200620_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200621\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200621_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200622\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200622_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200623\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200623_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200624\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200624_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200625\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200625_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200626\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200626_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200627\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200627_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200628\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200628_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200629\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200629_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200630\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200630_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200701\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200701_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200702\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200702_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200703\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200703_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200704\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200704_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200705\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200705_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200706\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200706_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200707\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200707_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200708\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200708_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200709\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200709_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200710\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200710_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200711\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200711_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200712\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200712_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200713\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200713_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200714\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200714_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200715\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200715_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200716\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200716_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200717\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200717_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200718\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200718_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200719\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200719_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200720\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200720_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200721\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200721_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200722\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200722_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200723\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200723_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200724\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200724_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200725\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200725_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200726\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200726_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200727\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200727_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200728\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200728_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200729\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200729_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200730\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200730_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200731\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200731_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200801\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200801_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200802\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200802_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200803\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200803_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200804\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200804_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200805\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200805_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200806\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200806_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200807\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200807_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200808\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200808_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200809\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200809_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200810\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200810_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200811\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200811_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200812\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200812_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200813\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200813_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200814\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200814_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200815\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200815_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200816\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200816_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200817\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200817_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200818\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200818_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200819\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200819_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200820\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200820_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200821\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200821_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200822\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200822_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200823\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200823_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200824\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200824_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200825\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200825_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200826\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200826_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200827\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200827_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200828\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200828_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200829\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200829_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200830\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200830_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200831\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200831_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200901\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200901_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200902\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200902_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200903\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200903_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200904\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200904_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200905\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200905_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200906\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200906_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200907\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200907_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200908\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200908_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200909\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200909_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200910\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200910_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200911\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200911_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200912\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200912_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200913\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200913_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200914\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200914_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200915\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200915_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200916\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200916_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200917\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200917_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200918\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200918_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200919\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200919_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200920\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200920_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200921\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200921_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200922\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200922_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200923\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200923_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200924\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200924_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200925\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200925_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200926\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200926_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200927\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200927_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200928\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200928_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200929\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200929_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200930\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200930_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201001\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201001_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201002\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201002_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201003\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201003_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201004\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201004_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201005\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201005_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201006\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201006_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201007\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201007_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201008\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201008_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201009\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201009_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201010\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201010_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201011\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201011_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201012\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201012_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201013\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201013_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201014\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201014_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201015\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201015_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201016\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201016_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201017\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201017_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201018\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201018_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201019\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201019_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201020\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201020_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201021\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201021_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201022\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201022_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201023\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201023_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201024\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201024_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201025\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201025_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201026\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201026_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201027\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201027_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201028\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201028_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201029\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201029_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201030\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201030_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201031\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201031_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201101\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201101_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201102\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201102_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201103\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201103_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201104\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201104_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201105\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201105_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201106\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201106_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201107\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201107_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201108\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201108_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201230\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201230_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201231\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201231_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\nall training data is saved to /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200109_20201231_all.csv\ninput columns:  Index(['FWI', 'VPD', 'HT', 'T', 'RH', 'U', 'V', 'P', 'RAIN', 'CAPE', 'ST',\n       'SM', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24',\n       'FRP_1_days_ago', 'FRP_2_days_ago', 'FRP_3_days_ago', 'FRP_4_days_ago',\n       'FRP_5_days_ago', 'FRP_6_days_ago', 'FRP_7_days_ago'],\n      dtype='object')\nget some statistics:  count    619372.000000\nmean         -1.793374\nstd           0.765395\nmin          -2.000000\n25%          -2.000000\n50%          -2.000000\n75%          -2.000000\nmax           4.046597\nName: FRP, dtype: float64\n",
  "history_begin_time" : 1719604356218,
  "history_end_time" : 1719604410204,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "Jmgih2mD2sg1",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nfrom lightgbm import LGBMRegressor\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\nfrom pytorch_tabnet.tab_model import TabNetRegressor\n\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v2_latest.pkl\"\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v2_latest.pkl\" # added the land use to distinguish the different geographical areas\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n#   model = XGBRegressor(n_estimators=100,\n#                        max_depth=8,\n#                        learning_rate=0.1,)\n  #model = LGBMRegressor(n_jobs=-1, random_state=42)\n  # {'model_type': 'tabnet', 'n_d': 17, 'n_a': 41, 'n_steps': 4, 'gamma': 1.1546672563068268, 'lambda_sparse': 0.00042602006758391}\n  model = TabNetRegressor(\n      n_d=17,\n      n_a=41,\n      n_steps=4,\n      gamma=1.1546672563068268,\n      lambda_sparse=0.00042602006758391\n  )\n  # tabnet_model.fit(\n  #     X_train.values, y_train,\n  #     eval_set=[(X_val.values, y_val)],\n  #     eval_metric=['mae'],\n  #     max_epochs=100,\n  #     patience=10,\n  #     batch_size=256,\n  #     virtual_batch_size=128,\n  # )\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = 'FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    # use log10 to reduce the value range\n    X[target_col] = np.log10(X[target_col]+1e-2)\n    \n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n  \n  all_data_combined = all_data_combined.dropna(subset=['FRP'])\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  print(f\"all training data is saved to {all_train_file_path}\")\n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe(include='all'))\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  #sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  #model.fit(X_train, y_train)\n\n  # train tabnet\n  model.fit(\n      X_train.values, y_train,\n      eval_set=[(X_test.values, y_test)],\n      eval_metric=['mae'],\n      max_epochs=100,\n      patience=10,\n      batch_size=256,\n      virtual_batch_size=128,\n  )\n  \n  print(\"y_train.shape = \", y_train.shape)\n  print(\"y_test.shape = \", y_test.shape)\n  \n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test.values)\n  \n  print(\"y_pred_test.shape = \", y_pred_test.shape)\n  y_predicted_df = pd.DataFrame(y_pred_test, columns=[\"predicted_FRP\"])\n  print(\"get some statistics of the predicted FRP: \", y_predicted_df[\"predicted_FRP\"].describe())\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  # with open(model_path, 'wb') as model_file:\n  #     pickle.dump(model, model_file)\n  #     print(f\"The new model is saved to {model_path}\")\n\n  # Save tabnet to file\n  best_model.save_model(model_path)\n  \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  # with open(random_model_path, 'wb') as model_file:\n  #     pickle.dump(model, model_file)\n  #     print(f\"The new model is saved to {random_model_path}\")\n  # Save tabnet to file\n  best_model.save_model(random_model_path)\n  \n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {random_model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200109\"\n  end_date_str = \"20201231\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n  warnings.warn(f\"Device used : {self.device}\")\ntraining on 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200131\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200131_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200301\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200301_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200302\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200302_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200303\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200303_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200304\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200304_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200305\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200305_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200306\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200306_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200307\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200307_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200308\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200308_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200309\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200309_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200310\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200310_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200311\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200311_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200312\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200312_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200313\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200313_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200314\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200314_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200315\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200315_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200316\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200316_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200317\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200317_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200318\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200318_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200319\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200319_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200320\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200320_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200321\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200321_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200322\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200322_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200323\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200323_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200324\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200324_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200325\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200325_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200326\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200326_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200327\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200327_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200328\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200328_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200329\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200329_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200330\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200330_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200331\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200331_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200401\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200401_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200402\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200402_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200403\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200403_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200404\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200404_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200405\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200405_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200406\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200406_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200407\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200407_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200408\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200408_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200409\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200409_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200410\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200410_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200411\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200411_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200412\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200412_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200413\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200413_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200414\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200414_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200415\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200415_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200416\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200416_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200417\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200417_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200418\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200418_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200419\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200419_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200420\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200420_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200421\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200421_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200422\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200422_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200423\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200423_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200424\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200424_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200425\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200425_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200426\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200426_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200427\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200427_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200428\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200428_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200429\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200429_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200430\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200430_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200501\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200501_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200502\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200502_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200503\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200503_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200504\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200504_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200505\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200505_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200506\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200506_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200507\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200507_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200508\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200508_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200509\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200509_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200510\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200510_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200511\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200511_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200512\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200512_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200513\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200513_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200514\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200514_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200515\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200515_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200516\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200516_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200517\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200517_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200518\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200518_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200519\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200519_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200520\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200520_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200521\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200521_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200522\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200522_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200523\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200523_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200524\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200524_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200525\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200525_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200526\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200526_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200527\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200527_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200528\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200528_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200529\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200529_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200530\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200530_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200531\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200531_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200601\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200601_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200602\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200602_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200603\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200603_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200604\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200604_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200605\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200605_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200606\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200606_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200607\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200607_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200608\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200608_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200609\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200609_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200610\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200610_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200611\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200611_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200612\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200612_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200613\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200613_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200614\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200614_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200615\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200615_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200616\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200616_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200617\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200617_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200618\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200618_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200619\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200619_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200620\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200620_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200621\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200621_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200622\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200622_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200623\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200623_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200624\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200624_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200625\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200625_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200626\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200626_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200627\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200627_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200628\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200628_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200629\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200629_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200630\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200630_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200701\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200701_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200702\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200702_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200703\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200703_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200704\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200704_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200705\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200705_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200706\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200706_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200707\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200707_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200708\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200708_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200709\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200709_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200710\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200710_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200711\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200711_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200712\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200712_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200713\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200713_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200714\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200714_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200715\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200715_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200716\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200716_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200717\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200717_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200718\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200718_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200719\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200719_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200720\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200720_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200721\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200721_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200722\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200722_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200723\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200723_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200724\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200724_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200725\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200725_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200726\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200726_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200727\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200727_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200728\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200728_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200729\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200729_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200730\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200730_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200731\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200731_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200801\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200801_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200802\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200802_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200803\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200803_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200804\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200804_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200805\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200805_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200806\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200806_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200807\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200807_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200808\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200808_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200809\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200809_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200810\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200810_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200811\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200811_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200812\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200812_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200813\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200813_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200814\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200814_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200815\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200815_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200816\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200816_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200817\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200817_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200818\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200818_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200819\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200819_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200820\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200820_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200821\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200821_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200822\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200822_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200823\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200823_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200824\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200824_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200825\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200825_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200826\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200826_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200827\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200827_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200828\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200828_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200829\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200829_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200830\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200830_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200831\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200831_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200901\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200901_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200902\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200902_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200903\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200903_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200904\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200904_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200905\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200905_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200906\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200906_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200907\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200907_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200908\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200908_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200909\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200909_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200910\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200910_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200911\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200911_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200912\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200912_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200913\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200913_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200914\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200914_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200915\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200915_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200916\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200916_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200917\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200917_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200918\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200918_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200919\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200919_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200920\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200920_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200921\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200921_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200922\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200922_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200923\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200923_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200924\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200924_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200925\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200925_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200926\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200926_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200927\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200927_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200928\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200928_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200929\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200929_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200930\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200930_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201001\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201001_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201002\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201002_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201003\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201003_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201004\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201004_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201005\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201005_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201006\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201006_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201007\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201007_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201008\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201008_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201009\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201009_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201010\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201010_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201011\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201011_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201012\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201012_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201013\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201013_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201014\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201014_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201015\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201015_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201016\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201016_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201017\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201017_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201018\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201018_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201019\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201019_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201020\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201020_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201021\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201021_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201022\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201022_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201023\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201023_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201024\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201024_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201025\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201025_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201026\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201026_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201027\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201027_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201028\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201028_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201029\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201029_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201030\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201030_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201031\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201031_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201101\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201101_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201102\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201102_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201103\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201103_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201104\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201104_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201105\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201105_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201106\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201106_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201107\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201107_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201108\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201108_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201230\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201230_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201231\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201231_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\nall training data is saved to /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200109_20201231_all.csv\ninput columns:  Index(['FWI', 'VPD', 'HT', 'T', 'RH', 'U', 'V', 'P', 'RAIN', 'CAPE', 'ST',\n       'SM', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24',\n       'FRP_1_days_ago', 'FRP_2_days_ago', 'FRP_3_days_ago', 'FRP_4_days_ago',\n       'FRP_5_days_ago', 'FRP_6_days_ago', 'FRP_7_days_ago'],\n      dtype='object')\nget some statistics:  count    619372.000000\nmean         -1.793374\nstd           0.765395\nmin          -2.000000\n25%          -2.000000\n50%          -2.000000\n75%          -2.000000\nmax           4.046597\nName: FRP, dtype: float64\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 192, in <module>\n    train_model(start_date_str, end_date_str, training_data_folder)\n  File \"fc_model_creation.py\", line 120, in train_model\n    model.fit(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py\", line 220, in fit\n    self.update_fit_params(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pytorch_tabnet/tab_model.py\", line 141, in update_fit_params\n    raise ValueError(msg)\nValueError: Targets should be 2D : (n_samples, n_regression) but y_train.shape=(495497,) given.\nUse reshape(-1, 1) for single regression.\n",
  "history_begin_time" : 1719604224935,
  "history_end_time" : 1719604289797,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "pbrr24ikboy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1718636826223,
  "history_end_time" : 1718636826223,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "eb8m1syoehs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1718636745269,
  "history_end_time" : 1718636745269,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ace7ggc52fh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1718636565073,
  "history_end_time" : 1718636565073,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "na7y8ak4d9i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1718211173501,
  "history_end_time" : 1718211173501,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "39ohlx5769i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717260625821,
  "history_end_time" : 1717260625821,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "650haw932v1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717258417370,
  "history_end_time" : 1717260624655,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "5jx1htta999",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717233644371,
  "history_end_time" : 1717258424624,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "853op2bqmhd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717233051746,
  "history_end_time" : 1717233634226,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "vyxlmb7hvd4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717183214952,
  "history_end_time" : 1717233633758,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "62mw71n9blj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717182654848,
  "history_end_time" : 1717182654848,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tyxkt6qtflo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716612552438,
  "history_end_time" : 1717233631792,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "mql0kv1c8vl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716611582515,
  "history_end_time" : 1716612551153,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "fwm4dv7s70v",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716610207086,
  "history_end_time" : 1716611579207,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "nsbk7eb61ms",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716606646627,
  "history_end_time" : 1716610196708,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "clx4j00ka5j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716120710341,
  "history_end_time" : 1716610159513,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "egh7a2bshz2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716068762986,
  "history_end_time" : 1716076012586,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "kzmk3r3exf1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716068608537,
  "history_end_time" : 1716068760861,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "iyrc0ggjrt2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714808468658,
  "history_end_time" : 1714838057256,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "MAhnDtgVLtuH",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nfrom lightgbm import LGBMRegressor\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v1_latest.pkl\"\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n#   model = XGBRegressor(n_estimators=100,\n#                        max_depth=8,\n#                        learning_rate=0.1,)\n  model = LGBMRegressor(n_jobs=-1, random_state=42)\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = 'FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    # use log10 to reduce the value range\n    X[target_col] = np.log10(X[target_col]+1e-2)\n    \n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  #sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  \n  print(\"y_train.shape = \", y_train.shape)\n  print(\"y_test.shape = \", y_test.shape)\n  \n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  \n  print(\"y_pred_test.shape = \", y_pred_test.shape)\n  y_predicted_df = pd.DataFrame(y_pred_test, columns=[\"predicted_FRP\"])\n  print(\"get some statistics of the predicted FRP: \", y_predicted_df[\"predicted_FRP\"].describe())\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200109\"\n  end_date_str = \"20201231\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\ntraining on 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200131\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200131_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200301\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200301_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200302\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200302_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200303\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200303_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200304\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200304_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200305\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200305_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200306\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200306_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200307\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200307_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200308\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200308_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200309\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200309_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200310\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200310_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200311\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200311_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200312\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200312_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200313\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200313_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200314\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200314_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200315\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200315_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200316\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200316_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200317\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200317_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200318\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200318_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200319\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200319_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200320\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200320_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200321\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200321_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200322\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200322_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200323\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200323_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200324\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200324_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200325\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200325_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200326\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200326_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200327\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200327_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200328\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200328_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200329\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200329_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200330\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200330_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200331\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200331_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200401\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200401_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200402\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200402_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200403\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200403_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200404\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200404_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200405\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200405_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200406\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200406_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200407\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200407_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200408\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200408_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200409\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200409_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200410\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200410_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200411\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200411_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200412\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200412_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200413\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200413_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200414\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200414_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200415\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200415_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200416\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200416_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200417\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200417_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200418\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200418_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200419\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200419_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200420\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200420_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200421\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200421_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200422\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200422_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200423\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200423_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200424\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200424_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200425\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200425_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200426\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200426_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200427\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200427_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200428\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200428_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200429\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200429_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200430\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200430_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200501\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200501_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200502\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200502_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200503\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200503_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200504\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200504_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200505\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200505_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200506\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200506_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200507\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200507_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200508\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200508_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200509\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200509_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200510\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200510_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200511\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200511_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200512\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200512_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200513\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200513_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200514\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200514_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200515\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200515_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200516\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200516_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200517\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200517_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200518\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200518_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200519\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200519_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200520\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200520_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200521\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200521_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200522\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200522_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200523\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200523_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200524\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200524_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200525\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200525_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200526\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200526_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200527\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200527_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200528\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200528_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200529\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200529_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200530\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200530_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200531\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200531_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200601\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200601_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200602\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200602_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200603\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200603_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200604\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200604_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200605\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200605_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200606\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200606_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200607\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200607_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200608\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200608_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200609\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200609_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200610\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200610_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200611\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200611_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200612\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200612_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200613\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200613_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200614\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200614_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200615\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200615_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200616\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200616_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200617\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200617_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200618\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200618_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200619\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200619_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200620\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200620_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200621\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200621_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200622\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200622_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200623\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200623_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200624\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200624_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200625\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200625_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200626\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200626_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200627\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200627_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200628\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200628_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200629\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200629_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200630\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200630_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200701\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200701_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200702\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200702_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200703\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200703_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200704\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200704_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200705\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200705_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200706\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200706_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200707\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200707_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200708\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200708_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200709\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200709_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200710\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200710_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200711\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200711_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200712\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200712_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200713\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200713_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200714\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200714_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200715\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200715_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200716\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200716_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200717\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200717_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200718\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200718_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200719\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200719_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200720\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200720_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200721\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200721_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200722\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200722_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200723\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200723_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200724\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200724_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200725\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200725_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200726\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200726_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200727\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200727_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200728\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200728_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200729\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200729_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200730\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200730_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200731\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200731_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200801\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200801_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200802\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200802_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200803\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200803_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200804\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200804_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200805\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200805_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200806\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200806_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200807\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200807_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200808\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200808_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200809\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200809_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200810\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200810_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200811\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200811_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200812\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200812_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200813\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200813_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200814\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200814_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200815\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200815_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200816\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200816_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200817\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200817_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200818\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200818_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200819\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200819_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200820\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200820_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200821\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200821_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200822\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200822_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200823\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200823_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200824\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200824_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200825\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200825_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200826\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200826_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200827\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200827_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200828\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200828_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200829\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200829_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200830\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200830_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200831\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200831_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200901\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200901_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200902\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200902_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200903\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200903_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200904\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200904_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200905\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200905_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200906\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200906_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200907\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200907_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200908\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200908_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200909\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200909_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200910\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200910_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200911\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200911_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200912\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200912_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200913\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200913_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200914\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200914_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200915\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200915_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200916\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200916_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200917\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200917_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200918\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200918_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200919\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200919_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200920\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200920_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200921\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200921_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200922\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200922_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200923\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200923_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200924\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200924_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200925\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200925_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200926\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200926_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200927\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200927_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200928\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200928_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200929\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200929_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200930\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200930_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201001\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201001_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201002\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201002_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201003\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201003_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201004\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201004_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201005\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201005_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201006\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201006_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201007\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201007_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201008\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201008_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201009\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201009_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201010\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201010_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201011\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201011_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201012\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201012_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201013\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201013_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201014\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201014_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201015\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201015_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201016\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201016_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201017\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201017_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201018\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201018_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201019\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201019_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201020\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201020_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201021\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201021_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201022\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201022_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201023\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201023_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201024\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201024_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201025\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201025_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201026\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201026_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201027\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201027_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201028\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201028_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201029\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201029_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201030\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201030_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201031\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201031_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201101\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201101_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201102\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201102_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201103\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201103_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201104\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201104_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201105\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201105_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201106\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201106_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201107\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201107_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201108\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201108_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201230\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201230_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201231\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201231_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ninput columns:  Index(['FWI', 'VPD', 'HT', 'T', 'RH', 'U', 'V', 'P', 'RAIN', 'CAPE', 'ST',\n       'SM', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24',\n       'FRP_1_days_ago', 'FRP_2_days_ago', 'FRP_3_days_ago', 'FRP_4_days_ago',\n       'FRP_5_days_ago', 'FRP_6_days_ago', 'FRP_7_days_ago'],\n      dtype='object')\n      FRP\n0     NaN\n1     NaN\n2     NaN\n3     NaN\n4     NaN\n...   ...\n3825  NaN\n3826  NaN\n3827  NaN\n3828  NaN\n3829  NaN\n[1848028 rows x 1 columns]\nget some statistics:  count    619372.000000\nmean         -1.793374\nstd           0.765395\nmin          -2.000000\n25%          -2.000000\n50%          -2.000000\n75%          -2.000000\nmax           4.046597\nName: FRP, dtype: float64\ny_train.shape =  (1478422,)\ny_test.shape =  (369606,)\ny_pred_test.shape =  (369606,)\nget some statistics of the predicted FRP:  count    369606.000000\nmean         -0.623328\nstd           0.872578\nmin          -2.254195\n25%          -1.804348\n50%          -0.001068\n75%          -0.001068\nmax           3.656639\nName: predicted_FRP, dtype: float64\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 156, in <module>\n    train_model(start_date_str, end_date_str, training_data_folder)\n  File \"fc_model_creation.py\", line 111, in train_model\n    mse = mean_squared_error(y_test, y_pred_test)\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 438, in mean_squared_error\n    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 95, in _check_reg_targets\n    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 800, in check_array\n    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 114, in _assert_all_finite\n    raise ValueError(\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
  "history_begin_time" : 1714803816154,
  "history_end_time" : 1714803964168,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "eQrozPZIel3e",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nfrom lightgbm import LGBMRegressor\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v1_latest.pkl\"\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n#   model = XGBRegressor(n_estimators=100,\n#                        max_depth=8,\n#                        learning_rate=0.1,)\n  model = LGBMRegressor(n_jobs=-1, random_state=42)\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = 'FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    # use log10 to reduce the value range\n    X[target_col] = np.log10(X[target_col]+1e-2)\n    \n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  #sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  \n  print(\"y_train.shape = \", y_train.shape)\n  print(\"y_test.sahpe = \", y_test.shape)\n  \n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  \n  print(\"y_pred_test.shape = \", y_pred_test.shape)\n  y_df[\"predicted_FRP\"] = y_pred_test\n  print(\"get some statistics of the predicted FRP: \", y_df[\"predicted_FRP\"].describe())\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200109\"\n  end_date_str = \"20201231\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\ntraining on 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200131\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200131_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200301\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200301_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200302\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200302_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200303\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200303_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200304\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200304_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200305\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200305_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200306\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200306_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200307\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200307_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200308\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200308_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200309\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200309_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200310\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200310_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200311\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200311_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200312\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200312_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200313\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200313_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200314\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200314_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200315\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200315_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200316\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200316_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200317\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200317_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200318\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200318_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200319\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200319_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200320\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200320_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200321\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200321_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200322\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200322_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200323\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200323_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200324\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200324_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200325\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200325_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200326\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200326_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200327\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200327_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200328\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200328_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200329\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200329_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200330\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200330_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200331\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200331_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200401\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200401_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200402\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200402_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200403\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200403_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200404\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200404_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200405\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200405_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200406\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200406_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200407\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200407_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200408\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200408_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200409\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200409_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200410\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200410_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200411\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200411_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200412\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200412_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200413\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200413_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200414\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200414_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200415\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200415_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200416\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200416_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200417\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200417_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200418\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200418_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200419\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200419_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200420\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200420_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200421\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200421_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200422\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200422_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200423\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200423_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200424\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200424_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200425\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200425_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200426\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200426_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200427\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200427_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200428\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200428_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200429\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200429_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200430\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200430_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200501\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200501_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200502\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200502_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200503\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200503_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200504\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200504_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200505\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200505_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200506\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200506_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200507\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200507_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200508\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200508_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200509\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200509_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200510\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200510_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200511\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200511_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200512\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200512_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200513\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200513_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200514\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200514_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200515\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200515_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200516\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200516_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200517\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200517_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200518\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200518_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200519\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200519_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200520\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200520_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200521\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200521_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200522\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200522_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200523\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200523_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200524\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200524_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200525\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200525_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200526\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200526_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200527\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200527_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200528\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200528_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200529\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200529_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200530\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200530_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200531\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200531_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200601\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200601_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200602\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200602_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200603\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200603_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200604\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200604_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200605\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200605_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200606\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200606_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200607\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200607_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200608\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200608_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200609\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200609_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200610\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200610_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200611\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200611_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200612\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200612_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200613\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200613_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200614\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200614_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200615\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200615_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200616\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200616_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200617\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200617_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200618\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200618_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200619\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200619_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200620\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200620_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200621\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200621_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200622\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200622_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200623\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200623_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200624\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200624_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200625\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200625_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200626\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200626_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200627\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200627_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200628\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200628_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200629\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200629_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200630\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200630_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200701\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200701_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200702\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200702_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200703\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200703_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200704\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200704_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200705\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200705_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200706\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200706_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200707\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200707_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200708\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200708_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200709\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200709_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200710\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200710_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200711\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200711_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200712\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200712_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200713\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200713_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200714\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200714_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200715\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200715_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200716\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200716_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200717\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200717_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200718\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200718_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200719\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200719_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200720\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200720_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200721\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200721_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200722\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200722_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200723\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200723_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200724\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200724_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200725\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200725_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200726\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200726_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200727\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200727_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200728\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200728_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200729\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200729_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200730\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200730_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200731\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200731_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200801\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200801_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200802\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200802_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200803\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200803_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200804\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200804_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200805\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200805_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200806\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200806_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200807\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200807_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200808\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200808_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200809\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200809_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200810\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200810_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200811\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200811_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200812\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200812_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200813\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200813_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200814\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200814_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200815\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200815_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200816\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200816_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200817\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200817_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200818\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200818_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200819\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200819_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200820\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200820_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200821\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200821_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200822\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200822_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200823\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200823_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200824\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200824_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200825\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200825_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200826\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200826_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200827\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200827_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200828\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200828_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200829\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200829_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200830\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200830_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200831\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200831_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200901\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200901_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200902\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200902_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200903\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200903_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200904\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200904_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200905\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200905_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200906\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200906_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200907\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200907_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200908\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200908_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200909\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200909_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200910\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200910_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200911\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200911_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200912\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200912_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200913\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200913_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200914\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200914_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200915\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200915_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200916\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200916_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200917\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200917_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200918\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200918_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200919\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200919_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200920\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200920_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200921\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200921_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200922\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200922_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200923\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200923_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200924\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200924_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200925\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200925_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200926\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200926_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200927\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200927_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200928\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200928_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200929\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200929_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200930\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200930_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201001\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201001_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201002\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201002_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201003\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201003_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201004\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201004_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201005\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201005_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201006\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201006_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201007\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201007_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201008\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201008_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201009\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201009_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201010\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201010_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201011\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201011_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201012\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201012_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201013\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201013_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201014\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201014_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201015\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201015_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201016\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201016_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201017\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201017_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201018\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201018_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201019\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201019_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201020\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201020_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201021\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201021_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201022\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201022_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201023\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201023_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201024\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201024_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201025\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201025_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201026\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201026_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201027\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201027_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201028\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201028_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201029\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201029_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201030\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201030_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201031\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201031_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201101\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201101_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201102\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201102_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201103\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201103_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201104\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201104_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201105\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201105_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201106\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201106_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201107\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201107_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201108\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201108_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201230\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201230_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201231\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201231_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ninput columns:  Index(['FWI', 'VPD', 'HT', 'T', 'RH', 'U', 'V', 'P', 'RAIN', 'CAPE', 'ST',\n       'SM', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24',\n       'FRP_1_days_ago', 'FRP_2_days_ago', 'FRP_3_days_ago', 'FRP_4_days_ago',\n       'FRP_5_days_ago', 'FRP_6_days_ago', 'FRP_7_days_ago'],\n      dtype='object')\n      FRP\n0     NaN\n1     NaN\n2     NaN\n3     NaN\n4     NaN\n...   ...\n3825  NaN\n3826  NaN\n3827  NaN\n3828  NaN\n3829  NaN\n[1848028 rows x 1 columns]\nget some statistics:  count    619372.000000\nmean         -1.793374\nstd           0.765395\nmin          -2.000000\n25%          -2.000000\n50%          -2.000000\n75%          -2.000000\nmax           4.046597\n",
  "history_begin_time" : 1714801589138,
  "history_end_time" : 1714803490941,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "2gud0cywgzp1",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nfrom lightgbm import LGBMRegressor\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v1_latest.pkl\"\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n#   model = XGBRegressor(n_estimators=100,\n#                        max_depth=8,\n#                        learning_rate=0.1,)\n  model = LGBMRegressor(n_jobs=-1, random_state=42)\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = 'FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    # use log10 to reduce the value range\n    X[target_col] = np.log10(X[target_col]+1e-2)\n    \n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  #sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  \n  y_df[\"predicted_FRP\"] = y_pred_test\n  print(\"get some statistics of the predicted FRP: \", y_df[\"predicted_FRP\"].describe())\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200109\"\n  end_date_str = \"20201231\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\ntraining on 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200131\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200131_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200301\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200301_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200302\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200302_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200303\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200303_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200304\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200304_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200305\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200305_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200306\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200306_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200307\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200307_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200308\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200308_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200309\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200309_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200310\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200310_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200311\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200311_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200312\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200312_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200313\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200313_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200314\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200314_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200315\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200315_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200316\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200316_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200317\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200317_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200318\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200318_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200319\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200319_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200320\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200320_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200321\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200321_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200322\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200322_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200323\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200323_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200324\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200324_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200325\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200325_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200326\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200326_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200327\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200327_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200328\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200328_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200329\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200329_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200330\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200330_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200331\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200331_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200401\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200401_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200402\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200402_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200403\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200403_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200404\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200404_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200405\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200405_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200406\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200406_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200407\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200407_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200408\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200408_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200409\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200409_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200410\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200410_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200411\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200411_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200412\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200412_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200413\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200413_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200414\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200414_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200415\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200415_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200416\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200416_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200417\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200417_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200418\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200418_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200419\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200419_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200420\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200420_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200421\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200421_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200422\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200422_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200423\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200423_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200424\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200424_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200425\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200425_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200426\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200426_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200427\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200427_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200428\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200428_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200429\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200429_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200430\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200430_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200501\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200501_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200502\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200502_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200503\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200503_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200504\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200504_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200505\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200505_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200506\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200506_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200507\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200507_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200508\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200508_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200509\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200509_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200510\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200510_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200511\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200511_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200512\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200512_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200513\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200513_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200514\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200514_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200515\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200515_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200516\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200516_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200517\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200517_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200518\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200518_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200519\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200519_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200520\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200520_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200521\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200521_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200522\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200522_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200523\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200523_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200524\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200524_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200525\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200525_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200526\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200526_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200527\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200527_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200528\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200528_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200529\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200529_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200530\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200530_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200531\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200531_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200601\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200601_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200602\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200602_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200603\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200603_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200604\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200604_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200605\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200605_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200606\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200606_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200607\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200607_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200608\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200608_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200609\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200609_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200610\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200610_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200611\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200611_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200612\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200612_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200613\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200613_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200614\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200614_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200615\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200615_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200616\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200616_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200617\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200617_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200618\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200618_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200619\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200619_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200620\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200620_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200621\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200621_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200622\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200622_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200623\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200623_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200624\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200624_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200625\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200625_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200626\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200626_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200627\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200627_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200628\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200628_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200629\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200629_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200630\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200630_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200701\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200701_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200702\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200702_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200703\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200703_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200704\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200704_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200705\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200705_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200706\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200706_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200707\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200707_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200708\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200708_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200709\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200709_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200710\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200710_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200711\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200711_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200712\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200712_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200713\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200713_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200714\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200714_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200715\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200715_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200716\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200716_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200717\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200717_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200718\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200718_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200719\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200719_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200720\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200720_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200721\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200721_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200722\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200722_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200723\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200723_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200724\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200724_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200725\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200725_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200726\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200726_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200727\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200727_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200728\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200728_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200729\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200729_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200730\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200730_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200731\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200731_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200801\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200801_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200802\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200802_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200803\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200803_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200804\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200804_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200805\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200805_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200806\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200806_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200807\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200807_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200808\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200808_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200809\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200809_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200810\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200810_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200811\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200811_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200812\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200812_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200813\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200813_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200814\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200814_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200815\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200815_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200816\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200816_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200817\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200817_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200818\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200818_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200819\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200819_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200820\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200820_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200821\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200821_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200822\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200822_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200823\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200823_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200824\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200824_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200825\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200825_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200826\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200826_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200827\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200827_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200828\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200828_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200829\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200829_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200830\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200830_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200831\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200831_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200901\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200901_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200902\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200902_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200903\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200903_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200904\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200904_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200905\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200905_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200906\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200906_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200907\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200907_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200908\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200908_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200909\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200909_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200910\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200910_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200911\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200911_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200912\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200912_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200913\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200913_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200914\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200914_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200915\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200915_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200916\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200916_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200917\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200917_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200918\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200918_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200919\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200919_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200920\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200920_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200921\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200921_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200922\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200922_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200923\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200923_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200924\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200924_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200925\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200925_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200926\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200926_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200927\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200927_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200928\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200928_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200929\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200929_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200930\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200930_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201001\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201001_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201002\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201002_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201003\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201003_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201004\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201004_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201005\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201005_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201006\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201006_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201007\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201007_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201008\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201008_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201009\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201009_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201010\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201010_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201011\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201011_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201012\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201012_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201013\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201013_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201014\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201014_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201015\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201015_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201016\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201016_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201017\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201017_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201018\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201018_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201019\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201019_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201020\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201020_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201021\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201021_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201022\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201022_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201023\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201023_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201024\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201024_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201025\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201025_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201026\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201026_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201027\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201027_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201028\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201028_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201029\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201029_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201030\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201030_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201031\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201031_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201101\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201101_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201102\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201102_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201103\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201103_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201104\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201104_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201105\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201105_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201106\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201106_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201107\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201107_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201108\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201108_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201230\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201230_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201231\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201231_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ninput columns:  Index(['FWI', 'VPD', 'HT', 'T', 'RH', 'U', 'V', 'P', 'RAIN', 'CAPE', 'ST',\n       'SM', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24',\n       'FRP_1_days_ago', 'FRP_2_days_ago', 'FRP_3_days_ago', 'FRP_4_days_ago',\n       'FRP_5_days_ago', 'FRP_6_days_ago', 'FRP_7_days_ago'],\n      dtype='object')\n      FRP\n0     NaN\n1     NaN\n2     NaN\n3     NaN\n4     NaN\n...   ...\n3825  NaN\n3826  NaN\n3827  NaN\n3828  NaN\n3829  NaN\n[1848028 rows x 1 columns]\nget some statistics:  count    619372.000000\nmean         -1.793374\nstd           0.765395\nmin          -2.000000\n25%          -2.000000\n50%          -2.000000\n75%          -2.000000\nmax           4.046597\nName: FRP, dtype: float64\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 151, in <module>\n    train_model(start_date_str, end_date_str, training_data_folder)\n  File \"fc_model_creation.py\", line 102, in train_model\n    y_df[\"predicted_FRP\"] = y_pred_test\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3655, in __setitem__\n    self._set_item(key, value)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3832, in _set_item\n    value = self._sanitize_column(value)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 4529, in _sanitize_column\n    com.require_length_match(value, self.index)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/common.py\", line 557, in require_length_match\n    raise ValueError(\nValueError: Length of values (369606) does not match length of index (619372)\n",
  "history_begin_time" : 1714800182624,
  "history_end_time" : 1714800329102,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "vaptreK1chvH",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nfrom lightgbm import LGBMRegressor\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v1_latest.pkl\"\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n#   model = XGBRegressor(n_estimators=100,\n#                        max_depth=8,\n#                        learning_rate=0.1,)\n  model = LGBMRegressor(n_jobs=-1, random_state=42)\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = 'FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    # use log10 to reduce the value range\n    X[target_col] = np.log10(X[target_col]+1e-2)\n    \n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"{model_path}_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200109\"\n  end_date_str = \"20201231\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\ntraining on 20200109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200131\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200131_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200301\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200301_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200302\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200302_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200303\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200303_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200304\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200304_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200305\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200305_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200306\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200306_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200307\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200307_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200308\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200308_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200309\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200309_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200310\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200310_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200311\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200311_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200312\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200312_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200313\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200313_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200314\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200314_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200315\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200315_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200316\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200316_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200317\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200317_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200318\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200318_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200319\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200319_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200320\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200320_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200321\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200321_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200322\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200322_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200323\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200323_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200324\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200324_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200325\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200325_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200326\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200326_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200327\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200327_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200328\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200328_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200329\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200329_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200330\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200330_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200331\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200331_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200401\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200401_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200402\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200402_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200403\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200403_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200404\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200404_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200405\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200405_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200406\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200406_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200407\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200407_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200408\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200408_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200409\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200409_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200410\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200410_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200411\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200411_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200412\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200412_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200413\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200413_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200414\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200414_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200415\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200415_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200416\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200416_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200417\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200417_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200418\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200418_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200419\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200419_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200420\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200420_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200421\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200421_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200422\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200422_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200423\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200423_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200424\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200424_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200425\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200425_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200426\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200426_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200427\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200427_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200428\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200428_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200429\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200429_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200430\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200430_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200501\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200501_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200502\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200502_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200503\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200503_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200504\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200504_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200505\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200505_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200506\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200506_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200507\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200507_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200508\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200508_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200509\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200509_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200510\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200510_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200511\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200511_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200512\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200512_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200513\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200513_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200514\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200514_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200515\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200515_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200516\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200516_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200517\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200517_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200518\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200518_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200519\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200519_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200520\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200520_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200521\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200521_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200522\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200522_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200523\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200523_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200524\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200524_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200525\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200525_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200526\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200526_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200527\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200527_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200528\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200528_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200529\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200529_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200530\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200530_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200531\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200531_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200601\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200601_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200602\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200602_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200603\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200603_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200604\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200604_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200605\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200605_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200606\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200606_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200607\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200607_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200608\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200608_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200609\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200609_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200610\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200610_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200611\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200611_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200612\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200612_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200613\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200613_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200614\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200614_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200615\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200615_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200616\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200616_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200617\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200617_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200618\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200618_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200619\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200619_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200620\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200620_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200621\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200621_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200622\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200622_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200623\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200623_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200624\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200624_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200625\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200625_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200626\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200626_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200627\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200627_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200628\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200628_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200629\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200629_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200630\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200630_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200701\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200701_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200702\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200702_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200703\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200703_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200704\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200704_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200705\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200705_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200706\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200706_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200707\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200707_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200708\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200708_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200709\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200709_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200710\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200710_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200711\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200711_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200712\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200712_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200713\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200713_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200714\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200714_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200715\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200715_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200716\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200716_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200717\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200717_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200718\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200718_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200719\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200719_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200720\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200720_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200721\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200721_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200722\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200722_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200723\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200723_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200724\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200724_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200725\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200725_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200726\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200726_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200727\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200727_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200728\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200728_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200729\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200729_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200730\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200730_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200731\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200731_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200801\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200801_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200802\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200802_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200803\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200803_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200804\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200804_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200805\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200805_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200806\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200806_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200807\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200807_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200808\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200808_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200809\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200809_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200810\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200810_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200811\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200811_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200812\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200812_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200813\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200813_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200814\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200814_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200815\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200815_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200816\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200816_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200817\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200817_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200818\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200818_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200819\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200819_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200820\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200820_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200821\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200821_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200822\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200822_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200823\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200823_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200824\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200824_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200825\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200825_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200826\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200826_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200827\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200827_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200828\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200828_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200829\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200829_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200830\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200830_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200831\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200831_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200901\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200901_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200902\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200902_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200903\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200903_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200904\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200904_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200905\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200905_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200906\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200906_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200907\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200907_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200908\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200908_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200909\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200909_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200910\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200910_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200911\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200911_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200912\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200912_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200913\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200913_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200914\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200914_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200915\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200915_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200916\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200916_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200917\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200917_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200918\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200918_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200919\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200919_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200920\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200920_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200921\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200921_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200922\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200922_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200923\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200923_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200924\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200924_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200925\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200925_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200926\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200926_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200927\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200927_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200928\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200928_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200929\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200929_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20200930\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20200930_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201001\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201001_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201002\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201002_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201003\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201003_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201004\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201004_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201005\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201005_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201006\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201006_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201007\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201007_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201008\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201008_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201009\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201009_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201010\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201010_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201011\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201011_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201012\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201012_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201013\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201013_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201014\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201014_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201015\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201015_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201016\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201016_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201017\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201017_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201018\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201018_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201019\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201019_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201020\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201020_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201021\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201021_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201022\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201022_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201023\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201023_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201024\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201024_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201025\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201025_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201026\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201026_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201027\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201027_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201028\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201028_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201029\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201029_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201030\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201030_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201031\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201031_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201101\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201101_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201102\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201102_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201103\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201103_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201104\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201104_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201105\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201105_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201106\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201106_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201107\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201107_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201108\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201108_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201109\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201109_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201110\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201110_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201111\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201111_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201112\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201112_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201113\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201113_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201114\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201114_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201115\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201115_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201116\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201116_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201117\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201117_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201118\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201118_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201119\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201119_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201120\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201120_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201121\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201121_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201122\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201122_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201123\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201123_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201124\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201124_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201125\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201125_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201126\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201126_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201127\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201127_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201128\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201128_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201129\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201129_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201130\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201130_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201201\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201201_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201202\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201202_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201203\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201203_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201204\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201204_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201205\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201205_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201206\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201206_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201207\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201207_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201208\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201208_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201209\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201209_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201210\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201210_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201211\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201211_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201212\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201212_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201213\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201213_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201214\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201214_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201215\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201215_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201216\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201216_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201217\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201217_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201218\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201218_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201219\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201219_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201220\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201220_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201221\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201221_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201222\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201222_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201223\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201223_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201224\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201224_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201225\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201225_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201226\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201226_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201227\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201227_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201228\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201228_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201229\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201229_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201230\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201230_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ntraining on 20201231\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_with_yunyao_window_data//20201231_time_series_with_new_window.csv exists\n/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: invalid value encountered in log10\n  result = getattr(ufunc, method)(*inputs, **kwargs)\ninput columns:  Index(['FWI', 'VPD', 'HT', 'T', 'RH', 'U', 'V', 'P', 'RAIN', 'CAPE', 'ST',\n       'SM', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24',\n       'FRP_1_days_ago', 'FRP_2_days_ago', 'FRP_3_days_ago', 'FRP_4_days_ago',\n       'FRP_5_days_ago', 'FRP_6_days_ago', 'FRP_7_days_ago'],\n      dtype='object')\n      FRP\n0     NaN\n1     NaN\n2     NaN\n3     NaN\n4     NaN\n...   ...\n3825  NaN\n3826  NaN\n3827  NaN\n3828  NaN\n3829  NaN\n[1848028 rows x 1 columns]\nget some statistics:  count    619372.000000\nmean         -1.793374\nstd           0.765395\nmin          -2.000000\n25%          -2.000000\n50%          -2.000000\n75%          -2.000000\nmax           4.046597\nName: FRP, dtype: float64\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 148, in <module>\n    train_model(start_date_str, end_date_str, training_data_folder)\n  File \"fc_model_creation.py\", line 103, in train_model\n    mse = mean_squared_error(y_test, y_pred_test)\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 438, in mean_squared_error\n    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 95, in _check_reg_targets\n    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 800, in check_array\n    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 114, in _assert_all_finite\n    raise ValueError(\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
  "history_begin_time" : 1714799362486,
  "history_end_time" : 1714799549295,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "htlptja0d1l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714161440454,
  "history_end_time" : 1714161440454,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zocagxxade1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713966604329,
  "history_end_time" : 1713966604329,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "71me409a3m9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713935811075,
  "history_end_time" : 1713935811075,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "DzKYaBS9IXV8",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nfrom lightgbm import LGBMRegressor\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v1_latest.pkl\"\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n#   model = XGBRegressor(n_estimators=100,\n#                        max_depth=8,\n#                        learning_rate=0.1,)\n  model = LGBMRegressor(n_jobs=-1, random_state=42)\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = ' FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    # use log10 to reduce the value range\n    X[target_col] = np.log10(X[target_col]+1e-2)\n    \n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"/groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200701\"\n  end_date_str = \"20201030\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\ntraining on 20200701\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200701_time_series_with_window.csv exists\ntraining on 20200702\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200702_time_series_with_window.csv exists\ntraining on 20200703\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200703_time_series_with_window.csv exists\ntraining on 20200704\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200704_time_series_with_window.csv exists\ntraining on 20200705\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200705_time_series_with_window.csv exists\ntraining on 20200706\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200706_time_series_with_window.csv exists\ntraining on 20200707\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200707_time_series_with_window.csv exists\ntraining on 20200708\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200708_time_series_with_window.csv exists\ntraining on 20200709\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200709_time_series_with_window.csv exists\ntraining on 20200710\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200710_time_series_with_window.csv exists\ntraining on 20200711\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200711_time_series_with_window.csv exists\ntraining on 20200712\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200712_time_series_with_window.csv exists\ntraining on 20200713\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200713_time_series_with_window.csv exists\ntraining on 20200714\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200714_time_series_with_window.csv exists\ntraining on 20200715\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200715_time_series_with_window.csv exists\ntraining on 20200716\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200716_time_series_with_window.csv exists\ntraining on 20200717\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200717_time_series_with_window.csv exists\ntraining on 20200718\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200718_time_series_with_window.csv exists\ntraining on 20200719\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200719_time_series_with_window.csv exists\ntraining on 20200720\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200720_time_series_with_window.csv exists\ntraining on 20200721\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200721_time_series_with_window.csv exists\ntraining on 20200722\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200722_time_series_with_window.csv exists\ntraining on 20200723\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200723_time_series_with_window.csv exists\ntraining on 20200724\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200724_time_series_with_window.csv exists\ntraining on 20200725\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200725_time_series_with_window.csv exists\ntraining on 20200726\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200726_time_series_with_window.csv exists\ntraining on 20200727\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200727_time_series_with_window.csv exists\ntraining on 20200728\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200728_time_series_with_window.csv exists\ntraining on 20200729\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200729_time_series_with_window.csv exists\ntraining on 20200730\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200730_time_series_with_window.csv exists\ntraining on 20200731\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200731_time_series_with_window.csv exists\ntraining on 20200801\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200801_time_series_with_window.csv exists\ntraining on 20200802\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200802_time_series_with_window.csv exists\ntraining on 20200803\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200803_time_series_with_window.csv exists\ntraining on 20200804\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200804_time_series_with_window.csv exists\ntraining on 20200805\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200805_time_series_with_window.csv exists\ntraining on 20200806\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200806_time_series_with_window.csv exists\ntraining on 20200807\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200807_time_series_with_window.csv exists\ntraining on 20200808\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200808_time_series_with_window.csv exists\ntraining on 20200809\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200809_time_series_with_window.csv exists\ntraining on 20200810\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200810_time_series_with_window.csv exists\ntraining on 20200811\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200811_time_series_with_window.csv exists\ntraining on 20200812\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200812_time_series_with_window.csv exists\ntraining on 20200813\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200813_time_series_with_window.csv exists\ntraining on 20200814\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200814_time_series_with_window.csv exists\ntraining on 20200815\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200815_time_series_with_window.csv exists\ntraining on 20200816\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200816_time_series_with_window.csv exists\ntraining on 20200817\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200817_time_series_with_window.csv exists\ntraining on 20200818\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200818_time_series_with_window.csv exists\ntraining on 20200819\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200819_time_series_with_window.csv exists\ntraining on 20200820\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200820_time_series_with_window.csv exists\ntraining on 20200821\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200821_time_series_with_window.csv exists\ntraining on 20200822\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200822_time_series_with_window.csv exists\ntraining on 20200823\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200823_time_series_with_window.csv exists\ntraining on 20200824\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200824_time_series_with_window.csv exists\ntraining on 20200825\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200825_time_series_with_window.csv exists\ntraining on 20200826\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200826_time_series_with_window.csv exists\ntraining on 20200827\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200827_time_series_with_window.csv exists\ntraining on 20200828\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200828_time_series_with_window.csv exists\ntraining on 20200829\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200829_time_series_with_window.csv exists\ntraining on 20200830\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200830_time_series_with_window.csv exists\ntraining on 20200831\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200831_time_series_with_window.csv exists\ntraining on 20200901\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200901_time_series_with_window.csv exists\ntraining on 20200902\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200902_time_series_with_window.csv exists\ntraining on 20200903\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200903_time_series_with_window.csv exists\ntraining on 20200904\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200904_time_series_with_window.csv exists\ntraining on 20200905\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200905_time_series_with_window.csv exists\ntraining on 20200906\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200906_time_series_with_window.csv exists\ntraining on 20200907\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200907_time_series_with_window.csv exists\ntraining on 20200908\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200908_time_series_with_window.csv exists\ntraining on 20200909\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200909_time_series_with_window.csv exists\ntraining on 20200910\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200910_time_series_with_window.csv exists\ntraining on 20200911\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200911_time_series_with_window.csv exists\ntraining on 20200912\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200912_time_series_with_window.csv exists\ntraining on 20200913\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200913_time_series_with_window.csv exists\ntraining on 20200914\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200914_time_series_with_window.csv exists\ntraining on 20200915\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200915_time_series_with_window.csv exists\ntraining on 20200916\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200916_time_series_with_window.csv exists\ntraining on 20200917\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200917_time_series_with_window.csv exists\ntraining on 20200918\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200918_time_series_with_window.csv exists\ntraining on 20200919\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200919_time_series_with_window.csv exists\ntraining on 20200920\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200920_time_series_with_window.csv exists\ntraining on 20200921\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200921_time_series_with_window.csv exists\ntraining on 20200922\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200922_time_series_with_window.csv exists\ntraining on 20200923\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200923_time_series_with_window.csv exists\ntraining on 20200924\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200924_time_series_with_window.csv exists\ntraining on 20200925\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200925_time_series_with_window.csv exists\ntraining on 20200926\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200926_time_series_with_window.csv exists\ntraining on 20200927\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200927_time_series_with_window.csv exists\ntraining on 20200928\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200928_time_series_with_window.csv exists\ntraining on 20200929\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200929_time_series_with_window.csv exists\ntraining on 20200930\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200930_time_series_with_window.csv exists\ntraining on 20201001\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201001_time_series_with_window.csv exists\ntraining on 20201002\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201002_time_series_with_window.csv exists\ntraining on 20201003\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201003_time_series_with_window.csv exists\ntraining on 20201004\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201004_time_series_with_window.csv exists\ntraining on 20201005\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201005_time_series_with_window.csv exists\ntraining on 20201006\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201006_time_series_with_window.csv exists\ntraining on 20201007\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201007_time_series_with_window.csv exists\ntraining on 20201008\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201008_time_series_with_window.csv exists\ntraining on 20201009\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201009_time_series_with_window.csv exists\ntraining on 20201010\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201010_time_series_with_window.csv exists\ntraining on 20201011\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201011_time_series_with_window.csv exists\ntraining on 20201012\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201012_time_series_with_window.csv exists\ntraining on 20201013\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201013_time_series_with_window.csv exists\ntraining on 20201014\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201014_time_series_with_window.csv exists\ntraining on 20201015\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201015_time_series_with_window.csv exists\ntraining on 20201016\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201016_time_series_with_window.csv exists\ntraining on 20201017\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201017_time_series_with_window.csv exists\ntraining on 20201018\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201018_time_series_with_window.csv exists\ntraining on 20201019\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201019_time_series_with_window.csv exists\ntraining on 20201020\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201020_time_series_with_window.csv exists\ntraining on 20201021\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201021_time_series_with_window.csv exists\ntraining on 20201022\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201022_time_series_with_window.csv exists\ntraining on 20201023\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201023_time_series_with_window.csv exists\ntraining on 20201024\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201024_time_series_with_window.csv exists\ntraining on 20201025\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201025_time_series_with_window.csv exists\ntraining on 20201026\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201026_time_series_with_window.csv exists\ntraining on 20201027\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201027_time_series_with_window.csv exists\ntraining on 20201028\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201028_time_series_with_window.csv exists\ntraining on 20201029\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201029_time_series_with_window.csv exists\ntraining on 20201030\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201030_time_series_with_window.csv exists\ninput columns:  Index([' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V', ' P', ' RAIN', ' CAPE',\n       ' ST', ' SM', ' FRP_1_days_ago', ' FRP_2_days_ago', ' FRP_3_days_ago',\n       ' FRP_4_days_ago', ' FRP_5_days_ago', ' FRP_6_days_ago',\n       ' FRP_7_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n          FRP\n0    1.577988\n1    0.173159\n2   -2.000000\n3   -2.000000\n4    0.268769\n..        ...\n258 -2.000000\n259 -2.000000\n260 -2.000000\n261 -2.000000\n262 -2.000000\n[32572 rows x 1 columns]\nget some statistics:  count    32572.000000\nmean        -0.827149\nstd          1.594519\nmin         -2.000000\n25%         -2.000000\n50%         -2.000000\n75%          0.708685\nmax          4.046597\nName:  FRP, dtype: float64\nMean Squared Error (MSE): 0.8950952877756448\nRoot Mean Squared Error (RMSE): 0.9460947562351484\nMean Absolute Error (MAE): 0.601636924078086\nR-squared (R2): 0.5268878549906\nThe new model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v1_latest.pkl\nThe new model is saved to /groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_20200701_20201030_20242404003955.pkl\na copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v1_latest.pkl\nall training on {training_data_folder} is done\n",
  "history_begin_time" : 1713933576882,
  "history_end_time" : 1713933596028,
  "history_notes" : "lightgbm is actually not as good as RF",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "6cpugB1zK9yT",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\n#model_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_lightgbm_model_v1_latest.pkl\"\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n#   model = XGBRegressor(n_estimators=100,\n#                        max_depth=8,\n#                        learning_rate=0.1,)\n  model = LGBMRegressor(n_jobs=-1, random_state=42)\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = ' FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    # use log10 to reduce the value range\n    X[target_col] = np.log10(X[target_col]+1e-2)\n    \n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"/groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200701\"\n  end_date_str = \"20201030\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "Traceback (most recent call last):\n  File \"fc_model_creation.py\", line 147, in <module>\n    train_model(start_date_str, end_date_str, training_data_folder)\n  File \"fc_model_creation.py\", line 47, in train_model\n    model = LGBMRegressor(n_jobs=-1, random_state=42)\nNameError: name 'LGBMRegressor' is not defined\n",
  "history_begin_time" : 1713932591638,
  "history_end_time" : 1713932593625,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "bcrj1zjj9tPP",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=8,\n                       learning_rate=0.1,)\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = ' FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    # use log10 to reduce the value range\n    X[target_col] = np.log10(X[target_col]+1e-2)\n    \n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"/groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200701\"\n  end_date_str = \"20201030\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "training on 20200701\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200701_time_series_with_window.csv exists\ntraining on 20200702\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200702_time_series_with_window.csv exists\ntraining on 20200703\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200703_time_series_with_window.csv exists\ntraining on 20200704\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200704_time_series_with_window.csv exists\ntraining on 20200705\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200705_time_series_with_window.csv exists\ntraining on 20200706\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200706_time_series_with_window.csv exists\ntraining on 20200707\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200707_time_series_with_window.csv exists\ntraining on 20200708\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200708_time_series_with_window.csv exists\ntraining on 20200709\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200709_time_series_with_window.csv exists\ntraining on 20200710\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200710_time_series_with_window.csv exists\ntraining on 20200711\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200711_time_series_with_window.csv exists\ntraining on 20200712\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200712_time_series_with_window.csv exists\ntraining on 20200713\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200713_time_series_with_window.csv exists\ntraining on 20200714\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200714_time_series_with_window.csv exists\ntraining on 20200715\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200715_time_series_with_window.csv exists\ntraining on 20200716\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200716_time_series_with_window.csv exists\ntraining on 20200717\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200717_time_series_with_window.csv exists\ntraining on 20200718\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200718_time_series_with_window.csv exists\ntraining on 20200719\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200719_time_series_with_window.csv exists\ntraining on 20200720\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200720_time_series_with_window.csv exists\ntraining on 20200721\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200721_time_series_with_window.csv exists\ntraining on 20200722\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200722_time_series_with_window.csv exists\ntraining on 20200723\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200723_time_series_with_window.csv exists\ntraining on 20200724\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200724_time_series_with_window.csv exists\ntraining on 20200725\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200725_time_series_with_window.csv exists\ntraining on 20200726\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200726_time_series_with_window.csv exists\ntraining on 20200727\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200727_time_series_with_window.csv exists\ntraining on 20200728\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200728_time_series_with_window.csv exists\ntraining on 20200729\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200729_time_series_with_window.csv exists\ntraining on 20200730\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200730_time_series_with_window.csv exists\ntraining on 20200731\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200731_time_series_with_window.csv exists\ntraining on 20200801\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200801_time_series_with_window.csv exists\ntraining on 20200802\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200802_time_series_with_window.csv exists\ntraining on 20200803\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200803_time_series_with_window.csv exists\ntraining on 20200804\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200804_time_series_with_window.csv exists\ntraining on 20200805\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200805_time_series_with_window.csv exists\ntraining on 20200806\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200806_time_series_with_window.csv exists\ntraining on 20200807\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200807_time_series_with_window.csv exists\ntraining on 20200808\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200808_time_series_with_window.csv exists\ntraining on 20200809\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200809_time_series_with_window.csv exists\ntraining on 20200810\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200810_time_series_with_window.csv exists\ntraining on 20200811\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200811_time_series_with_window.csv exists\ntraining on 20200812\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200812_time_series_with_window.csv exists\ntraining on 20200813\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200813_time_series_with_window.csv exists\ntraining on 20200814\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200814_time_series_with_window.csv exists\ntraining on 20200815\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200815_time_series_with_window.csv exists\ntraining on 20200816\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200816_time_series_with_window.csv exists\ntraining on 20200817\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200817_time_series_with_window.csv exists\ntraining on 20200818\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200818_time_series_with_window.csv exists\ntraining on 20200819\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200819_time_series_with_window.csv exists\ntraining on 20200820\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200820_time_series_with_window.csv exists\ntraining on 20200821\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200821_time_series_with_window.csv exists\ntraining on 20200822\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200822_time_series_with_window.csv exists\ntraining on 20200823\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200823_time_series_with_window.csv exists\ntraining on 20200824\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200824_time_series_with_window.csv exists\ntraining on 20200825\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200825_time_series_with_window.csv exists\ntraining on 20200826\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200826_time_series_with_window.csv exists\ntraining on 20200827\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200827_time_series_with_window.csv exists\ntraining on 20200828\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200828_time_series_with_window.csv exists\ntraining on 20200829\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200829_time_series_with_window.csv exists\ntraining on 20200830\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200830_time_series_with_window.csv exists\ntraining on 20200831\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200831_time_series_with_window.csv exists\ntraining on 20200901\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200901_time_series_with_window.csv exists\ntraining on 20200902\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200902_time_series_with_window.csv exists\ntraining on 20200903\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200903_time_series_with_window.csv exists\ntraining on 20200904\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200904_time_series_with_window.csv exists\ntraining on 20200905\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200905_time_series_with_window.csv exists\ntraining on 20200906\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200906_time_series_with_window.csv exists\ntraining on 20200907\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200907_time_series_with_window.csv exists\ntraining on 20200908\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200908_time_series_with_window.csv exists\ntraining on 20200909\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200909_time_series_with_window.csv exists\ntraining on 20200910\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200910_time_series_with_window.csv exists\ntraining on 20200911\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200911_time_series_with_window.csv exists\ntraining on 20200912\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200912_time_series_with_window.csv exists\ntraining on 20200913\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200913_time_series_with_window.csv exists\ntraining on 20200914\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200914_time_series_with_window.csv exists\ntraining on 20200915\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200915_time_series_with_window.csv exists\ntraining on 20200916\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200916_time_series_with_window.csv exists\ntraining on 20200917\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200917_time_series_with_window.csv exists\ntraining on 20200918\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200918_time_series_with_window.csv exists\ntraining on 20200919\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200919_time_series_with_window.csv exists\ntraining on 20200920\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200920_time_series_with_window.csv exists\ntraining on 20200921\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200921_time_series_with_window.csv exists\ntraining on 20200922\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200922_time_series_with_window.csv exists\ntraining on 20200923\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200923_time_series_with_window.csv exists\ntraining on 20200924\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200924_time_series_with_window.csv exists\ntraining on 20200925\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200925_time_series_with_window.csv exists\ntraining on 20200926\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200926_time_series_with_window.csv exists\ntraining on 20200927\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200927_time_series_with_window.csv exists\ntraining on 20200928\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200928_time_series_with_window.csv exists\ntraining on 20200929\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200929_time_series_with_window.csv exists\ntraining on 20200930\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200930_time_series_with_window.csv exists\ntraining on 20201001\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201001_time_series_with_window.csv exists\ntraining on 20201002\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201002_time_series_with_window.csv exists\ntraining on 20201003\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201003_time_series_with_window.csv exists\ntraining on 20201004\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201004_time_series_with_window.csv exists\ntraining on 20201005\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201005_time_series_with_window.csv exists\ntraining on 20201006\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201006_time_series_with_window.csv exists\ntraining on 20201007\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201007_time_series_with_window.csv exists\ntraining on 20201008\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201008_time_series_with_window.csv exists\ntraining on 20201009\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201009_time_series_with_window.csv exists\ntraining on 20201010\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201010_time_series_with_window.csv exists\ntraining on 20201011\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201011_time_series_with_window.csv exists\ntraining on 20201012\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201012_time_series_with_window.csv exists\ntraining on 20201013\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201013_time_series_with_window.csv exists\ntraining on 20201014\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201014_time_series_with_window.csv exists\ntraining on 20201015\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201015_time_series_with_window.csv exists\ntraining on 20201016\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201016_time_series_with_window.csv exists\ntraining on 20201017\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201017_time_series_with_window.csv exists\ntraining on 20201018\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201018_time_series_with_window.csv exists\ntraining on 20201019\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201019_time_series_with_window.csv exists\ntraining on 20201020\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201020_time_series_with_window.csv exists\ntraining on 20201021\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201021_time_series_with_window.csv exists\ntraining on 20201022\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201022_time_series_with_window.csv exists\ntraining on 20201023\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201023_time_series_with_window.csv exists\ntraining on 20201024\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201024_time_series_with_window.csv exists\ntraining on 20201025\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201025_time_series_with_window.csv exists\ntraining on 20201026\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201026_time_series_with_window.csv exists\ntraining on 20201027\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201027_time_series_with_window.csv exists\ntraining on 20201028\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201028_time_series_with_window.csv exists\ntraining on 20201029\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201029_time_series_with_window.csv exists\ntraining on 20201030\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201030_time_series_with_window.csv exists\ninput columns:  Index([' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V', ' P', ' RAIN', ' CAPE',\n       ' ST', ' SM', ' FRP_1_days_ago', ' FRP_2_days_ago', ' FRP_3_days_ago',\n       ' FRP_4_days_ago', ' FRP_5_days_ago', ' FRP_6_days_ago',\n       ' FRP_7_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n          FRP\n0    1.577988\n1    0.173159\n2   -2.000000\n3   -2.000000\n4    0.268769\n..        ...\n258 -2.000000\n259 -2.000000\n260 -2.000000\n261 -2.000000\n262 -2.000000\n[32572 rows x 1 columns]\nget some statistics:  count    32572.000000\nmean        -0.827149\nstd          1.594519\nmin         -2.000000\n25%         -2.000000\n50%         -2.000000\n75%          0.708685\nmax          4.046597\nName:  FRP, dtype: float64\nMean Squared Error (MSE): 0.8884208932872489\nRoot Mean Squared Error (RMSE): 0.9425608167578625\nMean Absolute Error (MAE): 0.5968784400592164\nR-squared (R2): 0.5304156772640152\nThe new model is saved to /groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\nThe new model is saved to /groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_20200701_20201030_20242404001046.pkl\na copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\nall training on {training_data_folder} is done\n",
  "history_begin_time" : 1713931811808,
  "history_end_time" : 1713931847170,
  "history_notes" : "random forest on log10 training data",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Z0iEfKxKSgtJ",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=8,\n                       learning_rate=0.1,)\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = ' FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    # use log10 to reduce the value range\n    X[target_col] = np.log10(X[target_col]+1e-2)\n    \n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"/groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\"\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200701\"\n  end_date_str = \"20201030\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "  File \"fc_model_creation.py\", line 139\n    if __name__ == \"__main__\":\n                             ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1713931740236,
  "history_end_time" : 1713931740277,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "0IYK5Qda8aae",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=8,\n                       learning_rate=0.1,)\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = ' FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    \n    # use log10 to reduce the value range\n    X[target_col] = np.log10(X[target_col]+1e-2)\n    \n    \n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"/groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\"\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200701\"\n  end_date_str = \"20201030\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "  File \"fc_model_creation.py\", line 141\n    if __name__ == \"__main__\":\n                             ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1713931702795,
  "history_end_time" : 1713931702856,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "k6u7k4xl1dl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712452760498,
  "history_end_time" : 1712452760498,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qayl30walav",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712452402373,
  "history_end_time" : 1712452749957,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "l2vkmak81r1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712445947127,
  "history_end_time" : 1712445947127,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8EVPDeR5w2Lh",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=8,\n                       learning_rate=0.1,)\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = ' FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"/groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200701\"\n  end_date_str = \"20201030\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "training on 20200701\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200701_time_series_with_window.csv exists\ntraining on 20200702\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200702_time_series_with_window.csv exists\ntraining on 20200703\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200703_time_series_with_window.csv exists\ntraining on 20200704\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200704_time_series_with_window.csv exists\ntraining on 20200705\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200705_time_series_with_window.csv exists\ntraining on 20200706\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200706_time_series_with_window.csv exists\ntraining on 20200707\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200707_time_series_with_window.csv exists\ntraining on 20200708\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200708_time_series_with_window.csv exists\ntraining on 20200709\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200709_time_series_with_window.csv exists\ntraining on 20200710\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200710_time_series_with_window.csv exists\ntraining on 20200711\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200711_time_series_with_window.csv exists\ntraining on 20200712\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200712_time_series_with_window.csv exists\ntraining on 20200713\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200713_time_series_with_window.csv exists\ntraining on 20200714\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200714_time_series_with_window.csv exists\ntraining on 20200715\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200715_time_series_with_window.csv exists\ntraining on 20200716\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200716_time_series_with_window.csv exists\ntraining on 20200717\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200717_time_series_with_window.csv exists\ntraining on 20200718\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200718_time_series_with_window.csv exists\ntraining on 20200719\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200719_time_series_with_window.csv exists\ntraining on 20200720\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200720_time_series_with_window.csv exists\ntraining on 20200721\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200721_time_series_with_window.csv exists\ntraining on 20200722\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200722_time_series_with_window.csv exists\ntraining on 20200723\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200723_time_series_with_window.csv exists\ntraining on 20200724\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200724_time_series_with_window.csv exists\ntraining on 20200725\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200725_time_series_with_window.csv exists\ntraining on 20200726\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200726_time_series_with_window.csv exists\ntraining on 20200727\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200727_time_series_with_window.csv exists\ntraining on 20200728\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200728_time_series_with_window.csv exists\ntraining on 20200729\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200729_time_series_with_window.csv exists\ntraining on 20200730\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200730_time_series_with_window.csv exists\ntraining on 20200731\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200731_time_series_with_window.csv exists\ntraining on 20200801\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200801_time_series_with_window.csv exists\ntraining on 20200802\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200802_time_series_with_window.csv exists\ntraining on 20200803\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200803_time_series_with_window.csv exists\ntraining on 20200804\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200804_time_series_with_window.csv exists\ntraining on 20200805\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200805_time_series_with_window.csv exists\ntraining on 20200806\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200806_time_series_with_window.csv exists\ntraining on 20200807\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200807_time_series_with_window.csv exists\ntraining on 20200808\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200808_time_series_with_window.csv exists\ntraining on 20200809\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200809_time_series_with_window.csv exists\ntraining on 20200810\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200810_time_series_with_window.csv exists\ntraining on 20200811\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200811_time_series_with_window.csv exists\ntraining on 20200812\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200812_time_series_with_window.csv exists\ntraining on 20200813\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200813_time_series_with_window.csv exists\ntraining on 20200814\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200814_time_series_with_window.csv exists\ntraining on 20200815\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200815_time_series_with_window.csv exists\ntraining on 20200816\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200816_time_series_with_window.csv exists\ntraining on 20200817\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200817_time_series_with_window.csv exists\ntraining on 20200818\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200818_time_series_with_window.csv exists\ntraining on 20200819\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200819_time_series_with_window.csv exists\ntraining on 20200820\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200820_time_series_with_window.csv exists\ntraining on 20200821\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200821_time_series_with_window.csv exists\ntraining on 20200822\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200822_time_series_with_window.csv exists\ntraining on 20200823\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200823_time_series_with_window.csv exists\ntraining on 20200824\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200824_time_series_with_window.csv exists\ntraining on 20200825\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200825_time_series_with_window.csv exists\ntraining on 20200826\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200826_time_series_with_window.csv exists\ntraining on 20200827\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200827_time_series_with_window.csv exists\ntraining on 20200828\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200828_time_series_with_window.csv exists\ntraining on 20200829\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200829_time_series_with_window.csv exists\ntraining on 20200830\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200830_time_series_with_window.csv exists\ntraining on 20200831\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200831_time_series_with_window.csv exists\ntraining on 20200901\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200901_time_series_with_window.csv exists\ntraining on 20200902\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200902_time_series_with_window.csv exists\ntraining on 20200903\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200903_time_series_with_window.csv exists\ntraining on 20200904\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200904_time_series_with_window.csv exists\ntraining on 20200905\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200905_time_series_with_window.csv exists\ntraining on 20200906\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200906_time_series_with_window.csv exists\ntraining on 20200907\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200907_time_series_with_window.csv exists\ntraining on 20200908\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200908_time_series_with_window.csv exists\ntraining on 20200909\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200909_time_series_with_window.csv exists\ntraining on 20200910\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200910_time_series_with_window.csv exists\ntraining on 20200911\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200911_time_series_with_window.csv exists\ntraining on 20200912\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200912_time_series_with_window.csv exists\ntraining on 20200913\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200913_time_series_with_window.csv exists\ntraining on 20200914\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200914_time_series_with_window.csv exists\ntraining on 20200915\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200915_time_series_with_window.csv exists\ntraining on 20200916\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200916_time_series_with_window.csv exists\ntraining on 20200917\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200917_time_series_with_window.csv exists\ntraining on 20200918\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200918_time_series_with_window.csv exists\ntraining on 20200919\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200919_time_series_with_window.csv exists\ntraining on 20200920\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200920_time_series_with_window.csv exists\ntraining on 20200921\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200921_time_series_with_window.csv exists\ntraining on 20200922\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200922_time_series_with_window.csv exists\ntraining on 20200923\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200923_time_series_with_window.csv exists\ntraining on 20200924\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200924_time_series_with_window.csv exists\ntraining on 20200925\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200925_time_series_with_window.csv exists\ntraining on 20200926\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200926_time_series_with_window.csv exists\ntraining on 20200927\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200927_time_series_with_window.csv exists\ntraining on 20200928\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200928_time_series_with_window.csv exists\ntraining on 20200929\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200929_time_series_with_window.csv exists\ntraining on 20200930\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200930_time_series_with_window.csv exists\ntraining on 20201001\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201001_time_series_with_window.csv exists\ntraining on 20201002\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201002_time_series_with_window.csv exists\ntraining on 20201003\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201003_time_series_with_window.csv exists\ntraining on 20201004\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201004_time_series_with_window.csv exists\ntraining on 20201005\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201005_time_series_with_window.csv exists\ntraining on 20201006\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201006_time_series_with_window.csv exists\ntraining on 20201007\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201007_time_series_with_window.csv exists\ntraining on 20201008\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201008_time_series_with_window.csv exists\ntraining on 20201009\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201009_time_series_with_window.csv exists\ntraining on 20201010\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201010_time_series_with_window.csv exists\ntraining on 20201011\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201011_time_series_with_window.csv exists\ntraining on 20201012\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201012_time_series_with_window.csv exists\ntraining on 20201013\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201013_time_series_with_window.csv exists\ntraining on 20201014\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201014_time_series_with_window.csv exists\ntraining on 20201015\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201015_time_series_with_window.csv exists\ntraining on 20201016\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201016_time_series_with_window.csv exists\ntraining on 20201017\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201017_time_series_with_window.csv exists\ntraining on 20201018\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201018_time_series_with_window.csv exists\ntraining on 20201019\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201019_time_series_with_window.csv exists\ntraining on 20201020\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201020_time_series_with_window.csv exists\ntraining on 20201021\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201021_time_series_with_window.csv exists\ntraining on 20201022\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201022_time_series_with_window.csv exists\ntraining on 20201023\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201023_time_series_with_window.csv exists\ntraining on 20201024\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201024_time_series_with_window.csv exists\ntraining on 20201025\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201025_time_series_with_window.csv exists\ntraining on 20201026\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201026_time_series_with_window.csv exists\ntraining on 20201027\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201027_time_series_with_window.csv exists\ntraining on 20201028\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201028_time_series_with_window.csv exists\ntraining on 20201029\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201029_time_series_with_window.csv exists\ntraining on 20201030\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201030_time_series_with_window.csv exists\ninput columns:  Index([' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V', ' P', ' RAIN', ' CAPE',\n       ' ST', ' SM', ' FRP_1_days_ago', ' FRP_2_days_ago', ' FRP_3_days_ago',\n       ' FRP_4_days_ago', ' FRP_5_days_ago', ' FRP_6_days_ago',\n       ' FRP_7_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n           FRP\n0    37.833199\n1     1.479905\n2     0.000000\n3     0.000000\n4     1.846816\n..         ...\n258   0.000000\n259   0.000000\n260   0.000000\n261   0.000000\n262   0.000000\n[32572 rows x 1 columns]\nget some statistics:  count    32572.000000\nmean        34.107672\nstd        224.213415\nmin          0.000000\n25%          0.000000\n50%          0.000000\n75%          5.103112\nmax      11132.594727\nName:  FRP, dtype: float64\nMean Squared Error (MSE): 20805.26032473802\nRoot Mean Squared Error (RMSE): 144.24028676045407\nMean Absolute Error (MAE): 24.041870029767175\nR-squared (R2): 0.03236460245747008\nThe new model is saved to /groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\nThe new model is saved to /groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_20200701_20201030_20240504154454.pkl\na copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\nall training on {training_data_folder} is done\n",
  "history_begin_time" : 1712346272558,
  "history_end_time" : 1712346295313,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "cUD2FlOgpMqx",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score,\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=8,\n                       learning_rate=0.1,)\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = ' FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  \n  # Calculate Mean Squared Error (MSE)\n  mse = mean_squared_error(y_test, y_pred_test)\n  print(\"Mean Squared Error (MSE):\", mse)\n  # Calculate Root Mean Squared Error (RMSE)\n  rmse = np.sqrt(mse)\n  print(\"Root Mean Squared Error (RMSE):\", rmse)\n\n  # Calculate Mean Absolute Error (MAE)\n  mae = mean_absolute_error(y_test, y_pred_test)\n  print(\"Mean Absolute Error (MAE):\", mae)\n\n  # Calculate R-squared\n  r2 = r2_score(y_test, y_pred_test)\n  print(\"R-squared (R2):\", r2)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"/groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200701\"\n  end_date_str = \"20201030\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "  File \"fc_model_creation.py\", line 10\n    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score,\n                                ^\nSyntaxError: trailing comma not allowed without surrounding parentheses\n",
  "history_begin_time" : 1712346259767,
  "history_end_time" : 1712346259832,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "Gi5x9SGHWsLU",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=8, \n                       #n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = ' FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=[target_col])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[target_col].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  test_accuracy = mean_squared_error(y_test, y_pred_test)\n  print(\"Current iteration Validation test accuracy:\", test_accuracy)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"/groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200701\"\n  end_date_str = \"20201030\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "training on 20200701\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200701_time_series_with_window.csv exists\ntraining on 20200702\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200702_time_series_with_window.csv exists\ntraining on 20200703\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200703_time_series_with_window.csv exists\ntraining on 20200704\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200704_time_series_with_window.csv exists\ntraining on 20200705\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200705_time_series_with_window.csv exists\ntraining on 20200706\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200706_time_series_with_window.csv exists\ntraining on 20200707\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200707_time_series_with_window.csv exists\ntraining on 20200708\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200708_time_series_with_window.csv exists\ntraining on 20200709\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200709_time_series_with_window.csv exists\ntraining on 20200710\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200710_time_series_with_window.csv exists\ntraining on 20200711\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200711_time_series_with_window.csv exists\ntraining on 20200712\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200712_time_series_with_window.csv exists\ntraining on 20200713\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200713_time_series_with_window.csv exists\ntraining on 20200714\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200714_time_series_with_window.csv exists\ntraining on 20200715\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200715_time_series_with_window.csv exists\ntraining on 20200716\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200716_time_series_with_window.csv exists\ntraining on 20200717\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200717_time_series_with_window.csv exists\ntraining on 20200718\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200718_time_series_with_window.csv exists\ntraining on 20200719\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200719_time_series_with_window.csv exists\ntraining on 20200720\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200720_time_series_with_window.csv exists\ntraining on 20200721\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200721_time_series_with_window.csv exists\ntraining on 20200722\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200722_time_series_with_window.csv exists\ntraining on 20200723\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200723_time_series_with_window.csv exists\ntraining on 20200724\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200724_time_series_with_window.csv exists\ntraining on 20200725\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200725_time_series_with_window.csv exists\ntraining on 20200726\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200726_time_series_with_window.csv exists\ntraining on 20200727\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200727_time_series_with_window.csv exists\ntraining on 20200728\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200728_time_series_with_window.csv exists\ntraining on 20200729\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200729_time_series_with_window.csv exists\ntraining on 20200730\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200730_time_series_with_window.csv exists\ntraining on 20200731\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200731_time_series_with_window.csv exists\ntraining on 20200801\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200801_time_series_with_window.csv exists\ntraining on 20200802\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200802_time_series_with_window.csv exists\ntraining on 20200803\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200803_time_series_with_window.csv exists\ntraining on 20200804\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200804_time_series_with_window.csv exists\ntraining on 20200805\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200805_time_series_with_window.csv exists\ntraining on 20200806\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200806_time_series_with_window.csv exists\ntraining on 20200807\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200807_time_series_with_window.csv exists\ntraining on 20200808\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200808_time_series_with_window.csv exists\ntraining on 20200809\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200809_time_series_with_window.csv exists\ntraining on 20200810\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200810_time_series_with_window.csv exists\ntraining on 20200811\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200811_time_series_with_window.csv exists\ntraining on 20200812\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200812_time_series_with_window.csv exists\ntraining on 20200813\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200813_time_series_with_window.csv exists\ntraining on 20200814\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200814_time_series_with_window.csv exists\ntraining on 20200815\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200815_time_series_with_window.csv exists\ntraining on 20200816\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200816_time_series_with_window.csv exists\ntraining on 20200817\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200817_time_series_with_window.csv exists\ntraining on 20200818\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200818_time_series_with_window.csv exists\ntraining on 20200819\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200819_time_series_with_window.csv exists\ntraining on 20200820\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200820_time_series_with_window.csv exists\ntraining on 20200821\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200821_time_series_with_window.csv exists\ntraining on 20200822\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200822_time_series_with_window.csv exists\ntraining on 20200823\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200823_time_series_with_window.csv exists\ntraining on 20200824\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200824_time_series_with_window.csv exists\ntraining on 20200825\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200825_time_series_with_window.csv exists\ntraining on 20200826\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200826_time_series_with_window.csv exists\ntraining on 20200827\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200827_time_series_with_window.csv exists\ntraining on 20200828\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200828_time_series_with_window.csv exists\ntraining on 20200829\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200829_time_series_with_window.csv exists\ntraining on 20200830\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200830_time_series_with_window.csv exists\ntraining on 20200831\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200831_time_series_with_window.csv exists\ntraining on 20200901\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200901_time_series_with_window.csv exists\ntraining on 20200902\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200902_time_series_with_window.csv exists\ntraining on 20200903\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200903_time_series_with_window.csv exists\ntraining on 20200904\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200904_time_series_with_window.csv exists\ntraining on 20200905\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200905_time_series_with_window.csv exists\ntraining on 20200906\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200906_time_series_with_window.csv exists\ntraining on 20200907\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200907_time_series_with_window.csv exists\ntraining on 20200908\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200908_time_series_with_window.csv exists\ntraining on 20200909\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200909_time_series_with_window.csv exists\ntraining on 20200910\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200910_time_series_with_window.csv exists\ntraining on 20200911\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200911_time_series_with_window.csv exists\ntraining on 20200912\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200912_time_series_with_window.csv exists\ntraining on 20200913\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200913_time_series_with_window.csv exists\ntraining on 20200914\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200914_time_series_with_window.csv exists\ntraining on 20200915\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200915_time_series_with_window.csv exists\ntraining on 20200916\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200916_time_series_with_window.csv exists\ntraining on 20200917\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200917_time_series_with_window.csv exists\ntraining on 20200918\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200918_time_series_with_window.csv exists\ntraining on 20200919\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200919_time_series_with_window.csv exists\ntraining on 20200920\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200920_time_series_with_window.csv exists\ntraining on 20200921\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200921_time_series_with_window.csv exists\ntraining on 20200922\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200922_time_series_with_window.csv exists\ntraining on 20200923\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200923_time_series_with_window.csv exists\ntraining on 20200924\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200924_time_series_with_window.csv exists\ntraining on 20200925\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200925_time_series_with_window.csv exists\ntraining on 20200926\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200926_time_series_with_window.csv exists\ntraining on 20200927\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200927_time_series_with_window.csv exists\ntraining on 20200928\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200928_time_series_with_window.csv exists\ntraining on 20200929\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200929_time_series_with_window.csv exists\ntraining on 20200930\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200930_time_series_with_window.csv exists\ntraining on 20201001\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201001_time_series_with_window.csv exists\ntraining on 20201002\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201002_time_series_with_window.csv exists\ntraining on 20201003\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201003_time_series_with_window.csv exists\ntraining on 20201004\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201004_time_series_with_window.csv exists\ntraining on 20201005\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201005_time_series_with_window.csv exists\ntraining on 20201006\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201006_time_series_with_window.csv exists\ntraining on 20201007\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201007_time_series_with_window.csv exists\ntraining on 20201008\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201008_time_series_with_window.csv exists\ntraining on 20201009\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201009_time_series_with_window.csv exists\ntraining on 20201010\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201010_time_series_with_window.csv exists\ntraining on 20201011\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201011_time_series_with_window.csv exists\ntraining on 20201012\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201012_time_series_with_window.csv exists\ntraining on 20201013\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201013_time_series_with_window.csv exists\ntraining on 20201014\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201014_time_series_with_window.csv exists\ntraining on 20201015\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201015_time_series_with_window.csv exists\ntraining on 20201016\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201016_time_series_with_window.csv exists\ntraining on 20201017\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201017_time_series_with_window.csv exists\ntraining on 20201018\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201018_time_series_with_window.csv exists\ntraining on 20201019\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201019_time_series_with_window.csv exists\ntraining on 20201020\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201020_time_series_with_window.csv exists\ntraining on 20201021\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201021_time_series_with_window.csv exists\ntraining on 20201022\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201022_time_series_with_window.csv exists\ntraining on 20201023\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201023_time_series_with_window.csv exists\ntraining on 20201024\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201024_time_series_with_window.csv exists\ntraining on 20201025\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201025_time_series_with_window.csv exists\ntraining on 20201026\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201026_time_series_with_window.csv exists\ntraining on 20201027\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201027_time_series_with_window.csv exists\ntraining on 20201028\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201028_time_series_with_window.csv exists\ntraining on 20201029\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201029_time_series_with_window.csv exists\ntraining on 20201030\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201030_time_series_with_window.csv exists\ninput columns:  Index([' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V', ' P', ' RAIN', ' CAPE',\n       ' ST', ' SM', ' FRP_1_days_ago', ' FRP_2_days_ago', ' FRP_3_days_ago',\n       ' FRP_4_days_ago', ' FRP_5_days_ago', ' FRP_6_days_ago',\n       ' FRP_7_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\n           FRP\n0    37.833199\n1     1.479905\n2     0.000000\n3     0.000000\n4     1.846816\n..         ...\n258   0.000000\n259   0.000000\n260   0.000000\n261   0.000000\n262   0.000000\n[32572 rows x 1 columns]\nget some statistics:  count    32572.000000\nmean        34.107672\nstd        224.213415\nmin          0.000000\n25%          0.000000\n50%          0.000000\n75%          5.103112\nmax      11132.594727\nName:  FRP, dtype: float64\nCurrent iteration Validation test accuracy: 18703.874221113296\nThe new model is saved to /groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\nThe new model is saved to /groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_20200701_20201030_20240504153954.pkl\na copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\nall training on {training_data_folder} is done\n",
  "history_begin_time" : 1712345974022,
  "history_end_time" : 1712345994600,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "hzO6WKtBPI1E",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=8, \n                       #n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = ' FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(all_train_file_path, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=['training_frp'])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[\"training_frp\"].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  test_accuracy = mean_squared_error(y_test, y_pred_test)\n  print(\"Current iteration Validation test accuracy:\", test_accuracy)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"/groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200701\"\n  end_date_str = \"20201030\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "training on 20200701\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200701_time_series_with_window.csv exists\ntraining on 20200702\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200702_time_series_with_window.csv exists\ntraining on 20200703\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200703_time_series_with_window.csv exists\ntraining on 20200704\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200704_time_series_with_window.csv exists\ntraining on 20200705\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200705_time_series_with_window.csv exists\ntraining on 20200706\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200706_time_series_with_window.csv exists\ntraining on 20200707\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200707_time_series_with_window.csv exists\ntraining on 20200708\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200708_time_series_with_window.csv exists\ntraining on 20200709\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200709_time_series_with_window.csv exists\ntraining on 20200710\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200710_time_series_with_window.csv exists\ntraining on 20200711\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200711_time_series_with_window.csv exists\ntraining on 20200712\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200712_time_series_with_window.csv exists\ntraining on 20200713\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200713_time_series_with_window.csv exists\ntraining on 20200714\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200714_time_series_with_window.csv exists\ntraining on 20200715\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200715_time_series_with_window.csv exists\ntraining on 20200716\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200716_time_series_with_window.csv exists\ntraining on 20200717\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200717_time_series_with_window.csv exists\ntraining on 20200718\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200718_time_series_with_window.csv exists\ntraining on 20200719\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200719_time_series_with_window.csv exists\ntraining on 20200720\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200720_time_series_with_window.csv exists\ntraining on 20200721\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200721_time_series_with_window.csv exists\ntraining on 20200722\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200722_time_series_with_window.csv exists\ntraining on 20200723\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200723_time_series_with_window.csv exists\ntraining on 20200724\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200724_time_series_with_window.csv exists\ntraining on 20200725\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200725_time_series_with_window.csv exists\ntraining on 20200726\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200726_time_series_with_window.csv exists\ntraining on 20200727\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200727_time_series_with_window.csv exists\ntraining on 20200728\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200728_time_series_with_window.csv exists\ntraining on 20200729\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200729_time_series_with_window.csv exists\ntraining on 20200730\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200730_time_series_with_window.csv exists\ntraining on 20200731\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200731_time_series_with_window.csv exists\ntraining on 20200801\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200801_time_series_with_window.csv exists\ntraining on 20200802\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200802_time_series_with_window.csv exists\ntraining on 20200803\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200803_time_series_with_window.csv exists\ntraining on 20200804\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200804_time_series_with_window.csv exists\ntraining on 20200805\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200805_time_series_with_window.csv exists\ntraining on 20200806\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200806_time_series_with_window.csv exists\ntraining on 20200807\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200807_time_series_with_window.csv exists\ntraining on 20200808\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200808_time_series_with_window.csv exists\ntraining on 20200809\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200809_time_series_with_window.csv exists\ntraining on 20200810\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200810_time_series_with_window.csv exists\ntraining on 20200811\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200811_time_series_with_window.csv exists\ntraining on 20200812\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200812_time_series_with_window.csv exists\ntraining on 20200813\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200813_time_series_with_window.csv exists\ntraining on 20200814\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200814_time_series_with_window.csv exists\ntraining on 20200815\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200815_time_series_with_window.csv exists\ntraining on 20200816\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200816_time_series_with_window.csv exists\ntraining on 20200817\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200817_time_series_with_window.csv exists\ntraining on 20200818\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200818_time_series_with_window.csv exists\ntraining on 20200819\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200819_time_series_with_window.csv exists\ntraining on 20200820\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200820_time_series_with_window.csv exists\ntraining on 20200821\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200821_time_series_with_window.csv exists\ntraining on 20200822\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200822_time_series_with_window.csv exists\ntraining on 20200823\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200823_time_series_with_window.csv exists\ntraining on 20200824\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200824_time_series_with_window.csv exists\ntraining on 20200825\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200825_time_series_with_window.csv exists\ntraining on 20200826\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200826_time_series_with_window.csv exists\ntraining on 20200827\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200827_time_series_with_window.csv exists\ntraining on 20200828\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200828_time_series_with_window.csv exists\ntraining on 20200829\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200829_time_series_with_window.csv exists\ntraining on 20200830\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200830_time_series_with_window.csv exists\ntraining on 20200831\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200831_time_series_with_window.csv exists\ntraining on 20200901\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200901_time_series_with_window.csv exists\ntraining on 20200902\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200902_time_series_with_window.csv exists\ntraining on 20200903\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200903_time_series_with_window.csv exists\ntraining on 20200904\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200904_time_series_with_window.csv exists\ntraining on 20200905\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200905_time_series_with_window.csv exists\ntraining on 20200906\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200906_time_series_with_window.csv exists\ntraining on 20200907\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200907_time_series_with_window.csv exists\ntraining on 20200908\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200908_time_series_with_window.csv exists\ntraining on 20200909\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200909_time_series_with_window.csv exists\ntraining on 20200910\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200910_time_series_with_window.csv exists\ntraining on 20200911\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200911_time_series_with_window.csv exists\ntraining on 20200912\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200912_time_series_with_window.csv exists\ntraining on 20200913\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200913_time_series_with_window.csv exists\ntraining on 20200914\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200914_time_series_with_window.csv exists\ntraining on 20200915\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200915_time_series_with_window.csv exists\ntraining on 20200916\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200916_time_series_with_window.csv exists\ntraining on 20200917\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200917_time_series_with_window.csv exists\ntraining on 20200918\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200918_time_series_with_window.csv exists\ntraining on 20200919\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200919_time_series_with_window.csv exists\ntraining on 20200920\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200920_time_series_with_window.csv exists\ntraining on 20200921\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200921_time_series_with_window.csv exists\ntraining on 20200922\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200922_time_series_with_window.csv exists\ntraining on 20200923\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200923_time_series_with_window.csv exists\ntraining on 20200924\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200924_time_series_with_window.csv exists\ntraining on 20200925\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200925_time_series_with_window.csv exists\ntraining on 20200926\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200926_time_series_with_window.csv exists\ntraining on 20200927\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200927_time_series_with_window.csv exists\ntraining on 20200928\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200928_time_series_with_window.csv exists\ntraining on 20200929\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200929_time_series_with_window.csv exists\ntraining on 20200930\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200930_time_series_with_window.csv exists\ntraining on 20201001\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201001_time_series_with_window.csv exists\ntraining on 20201002\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201002_time_series_with_window.csv exists\ntraining on 20201003\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201003_time_series_with_window.csv exists\ntraining on 20201004\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201004_time_series_with_window.csv exists\ntraining on 20201005\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201005_time_series_with_window.csv exists\ntraining on 20201006\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201006_time_series_with_window.csv exists\ntraining on 20201007\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201007_time_series_with_window.csv exists\ntraining on 20201008\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201008_time_series_with_window.csv exists\ntraining on 20201009\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201009_time_series_with_window.csv exists\ntraining on 20201010\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201010_time_series_with_window.csv exists\ntraining on 20201011\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201011_time_series_with_window.csv exists\ntraining on 20201012\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201012_time_series_with_window.csv exists\ntraining on 20201013\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201013_time_series_with_window.csv exists\ntraining on 20201014\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201014_time_series_with_window.csv exists\ntraining on 20201015\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201015_time_series_with_window.csv exists\ntraining on 20201016\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201016_time_series_with_window.csv exists\ntraining on 20201017\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201017_time_series_with_window.csv exists\ntraining on 20201018\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201018_time_series_with_window.csv exists\ntraining on 20201019\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201019_time_series_with_window.csv exists\ntraining on 20201020\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201020_time_series_with_window.csv exists\ntraining on 20201021\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201021_time_series_with_window.csv exists\ntraining on 20201022\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201022_time_series_with_window.csv exists\ntraining on 20201023\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201023_time_series_with_window.csv exists\ntraining on 20201024\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201024_time_series_with_window.csv exists\ntraining on 20201025\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201025_time_series_with_window.csv exists\ntraining on 20201026\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201026_time_series_with_window.csv exists\ntraining on 20201027\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201027_time_series_with_window.csv exists\ntraining on 20201028\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201028_time_series_with_window.csv exists\ntraining on 20201029\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201029_time_series_with_window.csv exists\ntraining on 20201030\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201030_time_series_with_window.csv exists\ninput columns:  Index([' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V', ' P', ' RAIN', ' CAPE',\n       ' ST', ' SM', ' FRP_1_days_ago', ' FRP_2_days_ago', ' FRP_3_days_ago',\n       ' FRP_4_days_ago', ' FRP_5_days_ago', ' FRP_6_days_ago',\n       ' FRP_7_days_ago', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\nEmpty DataFrame\nColumns: [training_frp]\nIndex: []\nget some statistics:  count       0\nunique      0\ntop       NaN\nfreq      NaN\nName: training_frp, dtype: object\nCurrent iteration Validation test accuracy: 18703.874221113296\nThe new model is saved to /groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\nThe new model is saved to /groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_20200701_20201030_20240504153802.pkl\na copy of the model is saved to /groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\nall training on {training_data_folder} is done\n",
  "history_begin_time" : 1712345855440,
  "history_end_time" : 1712345882323,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Jnw9fj37zBrg",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=8, \n                       #n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = ' FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  all_data_combined.to_csv(output_file, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=['training_frp'])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[\"training_frp\"].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  test_accuracy = mean_squared_error(y_test, y_pred_test)\n  print(\"Current iteration Validation test accuracy:\", test_accuracy)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"/groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200701\"\n  end_date_str = \"20201030\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "training on 20200701\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200701_time_series_with_window.csv exists\ntraining on 20200702\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200702_time_series_with_window.csv exists\ntraining on 20200703\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200703_time_series_with_window.csv exists\ntraining on 20200704\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200704_time_series_with_window.csv exists\ntraining on 20200705\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200705_time_series_with_window.csv exists\ntraining on 20200706\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200706_time_series_with_window.csv exists\ntraining on 20200707\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200707_time_series_with_window.csv exists\ntraining on 20200708\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200708_time_series_with_window.csv exists\ntraining on 20200709\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200709_time_series_with_window.csv exists\ntraining on 20200710\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200710_time_series_with_window.csv exists\ntraining on 20200711\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200711_time_series_with_window.csv exists\ntraining on 20200712\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200712_time_series_with_window.csv exists\ntraining on 20200713\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200713_time_series_with_window.csv exists\ntraining on 20200714\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200714_time_series_with_window.csv exists\ntraining on 20200715\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200715_time_series_with_window.csv exists\ntraining on 20200716\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200716_time_series_with_window.csv exists\ntraining on 20200717\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200717_time_series_with_window.csv exists\ntraining on 20200718\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200718_time_series_with_window.csv exists\ntraining on 20200719\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200719_time_series_with_window.csv exists\ntraining on 20200720\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200720_time_series_with_window.csv exists\ntraining on 20200721\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200721_time_series_with_window.csv exists\ntraining on 20200722\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200722_time_series_with_window.csv exists\ntraining on 20200723\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200723_time_series_with_window.csv exists\ntraining on 20200724\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200724_time_series_with_window.csv exists\ntraining on 20200725\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200725_time_series_with_window.csv exists\ntraining on 20200726\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200726_time_series_with_window.csv exists\ntraining on 20200727\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200727_time_series_with_window.csv exists\ntraining on 20200728\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200728_time_series_with_window.csv exists\ntraining on 20200729\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200729_time_series_with_window.csv exists\ntraining on 20200730\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200730_time_series_with_window.csv exists\ntraining on 20200731\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200731_time_series_with_window.csv exists\ntraining on 20200801\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200801_time_series_with_window.csv exists\ntraining on 20200802\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200802_time_series_with_window.csv exists\ntraining on 20200803\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200803_time_series_with_window.csv exists\ntraining on 20200804\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200804_time_series_with_window.csv exists\ntraining on 20200805\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200805_time_series_with_window.csv exists\ntraining on 20200806\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200806_time_series_with_window.csv exists\ntraining on 20200807\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200807_time_series_with_window.csv exists\ntraining on 20200808\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200808_time_series_with_window.csv exists\ntraining on 20200809\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200809_time_series_with_window.csv exists\ntraining on 20200810\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200810_time_series_with_window.csv exists\ntraining on 20200811\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200811_time_series_with_window.csv exists\ntraining on 20200812\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200812_time_series_with_window.csv exists\ntraining on 20200813\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200813_time_series_with_window.csv exists\ntraining on 20200814\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200814_time_series_with_window.csv exists\ntraining on 20200815\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200815_time_series_with_window.csv exists\ntraining on 20200816\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200816_time_series_with_window.csv exists\ntraining on 20200817\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200817_time_series_with_window.csv exists\ntraining on 20200818\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200818_time_series_with_window.csv exists\ntraining on 20200819\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200819_time_series_with_window.csv exists\ntraining on 20200820\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200820_time_series_with_window.csv exists\ntraining on 20200821\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200821_time_series_with_window.csv exists\ntraining on 20200822\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200822_time_series_with_window.csv exists\ntraining on 20200823\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200823_time_series_with_window.csv exists\ntraining on 20200824\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200824_time_series_with_window.csv exists\ntraining on 20200825\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200825_time_series_with_window.csv exists\ntraining on 20200826\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200826_time_series_with_window.csv exists\ntraining on 20200827\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200827_time_series_with_window.csv exists\ntraining on 20200828\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200828_time_series_with_window.csv exists\ntraining on 20200829\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200829_time_series_with_window.csv exists\ntraining on 20200830\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200830_time_series_with_window.csv exists\ntraining on 20200831\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200831_time_series_with_window.csv exists\ntraining on 20200901\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200901_time_series_with_window.csv exists\ntraining on 20200902\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200902_time_series_with_window.csv exists\ntraining on 20200903\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200903_time_series_with_window.csv exists\ntraining on 20200904\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200904_time_series_with_window.csv exists\ntraining on 20200905\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200905_time_series_with_window.csv exists\ntraining on 20200906\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200906_time_series_with_window.csv exists\ntraining on 20200907\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200907_time_series_with_window.csv exists\ntraining on 20200908\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200908_time_series_with_window.csv exists\ntraining on 20200909\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200909_time_series_with_window.csv exists\ntraining on 20200910\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200910_time_series_with_window.csv exists\ntraining on 20200911\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200911_time_series_with_window.csv exists\ntraining on 20200912\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200912_time_series_with_window.csv exists\ntraining on 20200913\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200913_time_series_with_window.csv exists\ntraining on 20200914\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200914_time_series_with_window.csv exists\ntraining on 20200915\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200915_time_series_with_window.csv exists\ntraining on 20200916\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200916_time_series_with_window.csv exists\ntraining on 20200917\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200917_time_series_with_window.csv exists\ntraining on 20200918\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200918_time_series_with_window.csv exists\ntraining on 20200919\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200919_time_series_with_window.csv exists\ntraining on 20200920\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200920_time_series_with_window.csv exists\ntraining on 20200921\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200921_time_series_with_window.csv exists\ntraining on 20200922\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200922_time_series_with_window.csv exists\ntraining on 20200923\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200923_time_series_with_window.csv exists\ntraining on 20200924\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200924_time_series_with_window.csv exists\ntraining on 20200925\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200925_time_series_with_window.csv exists\ntraining on 20200926\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200926_time_series_with_window.csv exists\ntraining on 20200927\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200927_time_series_with_window.csv exists\ntraining on 20200928\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200928_time_series_with_window.csv exists\ntraining on 20200929\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200929_time_series_with_window.csv exists\ntraining on 20200930\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200930_time_series_with_window.csv exists\ntraining on 20201001\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201001_time_series_with_window.csv exists\ntraining on 20201002\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201002_time_series_with_window.csv exists\ntraining on 20201003\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201003_time_series_with_window.csv exists\ntraining on 20201004\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201004_time_series_with_window.csv exists\ntraining on 20201005\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201005_time_series_with_window.csv exists\ntraining on 20201006\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201006_time_series_with_window.csv exists\ntraining on 20201007\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201007_time_series_with_window.csv exists\ntraining on 20201008\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201008_time_series_with_window.csv exists\ntraining on 20201009\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201009_time_series_with_window.csv exists\ntraining on 20201010\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201010_time_series_with_window.csv exists\ntraining on 20201011\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201011_time_series_with_window.csv exists\ntraining on 20201012\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201012_time_series_with_window.csv exists\ntraining on 20201013\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201013_time_series_with_window.csv exists\ntraining on 20201014\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201014_time_series_with_window.csv exists\ntraining on 20201015\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201015_time_series_with_window.csv exists\ntraining on 20201016\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201016_time_series_with_window.csv exists\ntraining on 20201017\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201017_time_series_with_window.csv exists\ntraining on 20201018\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201018_time_series_with_window.csv exists\ntraining on 20201019\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201019_time_series_with_window.csv exists\ntraining on 20201020\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201020_time_series_with_window.csv exists\ntraining on 20201021\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201021_time_series_with_window.csv exists\ntraining on 20201022\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201022_time_series_with_window.csv exists\ntraining on 20201023\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201023_time_series_with_window.csv exists\ntraining on 20201024\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201024_time_series_with_window.csv exists\ntraining on 20201025\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201025_time_series_with_window.csv exists\ntraining on 20201026\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201026_time_series_with_window.csv exists\ntraining on 20201027\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201027_time_series_with_window.csv exists\ntraining on 20201028\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201028_time_series_with_window.csv exists\ntraining on 20201029\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201029_time_series_with_window.csv exists\ntraining on 20201030\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201030_time_series_with_window.csv exists\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 137, in <module>\n    train_model(start_date_str, end_date_str, training_data_folder)\n  File \"fc_model_creation.py\", line 79, in train_model\n    all_data_combined.to_csv(output_file, index=False)\nNameError: name 'output_file' is not defined\n",
  "history_begin_time" : 1712345802257,
  "history_end_time" : 1712345804502,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "qJEfsDdtsIfL",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport xgboost as xgb\nimport warnings\nimport shutil\nfrom datetime import datetime, timedelta\nfrom fc_train_data_preprocess import training_data_folder\n\nimport pickle\n\nfrom fc_train_data_preprocess import  prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_latest.pkl\"\n\n\n\n\ndef train_model(start_date_str, end_date_str, training_data_folder=training_data_folder):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=8, \n                       #n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  target_col = ' FRP'\n  \n  all_train_file_path = f\"{training_data_folder}/{start_date_str}_{end_date_str}_all.csv\"\n  \n  all_data = []\n  \n  while current_date <= end_date:\n    dates_between.append(current_date)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str, training_data_folder)\n    # merge all X, y into one file first\n    # Append X and y to the respective lists\n    X[target_col] = y\n    all_data.append(X)\n    current_date += timedelta(days=1)\n    \n  # Concatenate all X and y DataFrames vertically\n  all_data_combined = pd.concat(all_data, axis=0)\n    \n  data_combined.to_csv(output_file, index=False)\n  \n  X = all_data_combined.drop(columns=[target_col])\n  y = all_data_combined[target_col]\n  \n  print(\"input columns: \", X.columns)\n  y_df = pd.DataFrame(y, columns=['training_frp'])\n  print(y_df)\n  y_df.dropna(inplace=True)\n  print(\"get some statistics: \", y_df[\"training_frp\"].describe())\n    \n  \n\n  # Define sample weights based on the threshold\n  #sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n  sample_weights = 10 * y\n  # Split the data into training and testing sets\n  #X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n\n  #model.fit(X_train, y_train, sample_weight=sw_train)\n  model.fit(X_train, y_train)\n  # Evaluate the model on test set\n  y_pred_test = model.predict(X_test)\n  test_accuracy = mean_squared_error(y_test, y_pred_test)\n  print(\"Current iteration Validation test accuracy:\", test_accuracy)\n\n#   label += 1\n\n#     if label % 30 == 0:\n#       # save the model for every month\n#       with open(model_path, 'wb') as model_file:\n#         pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_path}\")\n      \n  now = datetime.now()\n  date_time = now.strftime(\"%Y%d%m%H%M%S\")\n  random_model_path = f\"/groups/ESS3/zsun/firecasting//model/fc_xgb_model_v1_{start_date_str}_{end_date_str}_{date_time}.pkl\"\n  # Save the model to a file\n  with open(random_model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {random_model_path}\")\n\n  # copy a version to the latest file placeholder\n  #shutil.copy(random_model_path, model_path)\n  print(f\"a copy of the model is saved to {model_path}\")\n\nif __name__ == \"__main__\":\n  # Define your start and end dates as strings\n  # Define your start and end dates as strings\n  start_date_str = \"20200701\"\n  end_date_str = \"20201030\"\n  training_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\"\n  # all_cells_new_6 - this training will not use weight. Directly train the model on all rows because we already filterred out the non-fire cells.\n  train_model(start_date_str, end_date_str, training_data_folder)\n  print(\"all training on {training_data_folder} is done\")",
  "history_output" : "training on 20200701\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200701_time_series_with_window.csv exists\ntraining on 20200702\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200702_time_series_with_window.csv exists\ntraining on 20200703\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200703_time_series_with_window.csv exists\ntraining on 20200704\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200704_time_series_with_window.csv exists\ntraining on 20200705\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200705_time_series_with_window.csv exists\ntraining on 20200706\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200706_time_series_with_window.csv exists\ntraining on 20200707\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200707_time_series_with_window.csv exists\ntraining on 20200708\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200708_time_series_with_window.csv exists\ntraining on 20200709\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200709_time_series_with_window.csv exists\ntraining on 20200710\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200710_time_series_with_window.csv exists\ntraining on 20200711\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200711_time_series_with_window.csv exists\ntraining on 20200712\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200712_time_series_with_window.csv exists\ntraining on 20200713\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200713_time_series_with_window.csv exists\ntraining on 20200714\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200714_time_series_with_window.csv exists\ntraining on 20200715\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200715_time_series_with_window.csv exists\ntraining on 20200716\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200716_time_series_with_window.csv exists\ntraining on 20200717\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200717_time_series_with_window.csv exists\ntraining on 20200718\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200718_time_series_with_window.csv exists\ntraining on 20200719\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200719_time_series_with_window.csv exists\ntraining on 20200720\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200720_time_series_with_window.csv exists\ntraining on 20200721\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200721_time_series_with_window.csv exists\ntraining on 20200722\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200722_time_series_with_window.csv exists\ntraining on 20200723\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200723_time_series_with_window.csv exists\ntraining on 20200724\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200724_time_series_with_window.csv exists\ntraining on 20200725\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200725_time_series_with_window.csv exists\ntraining on 20200726\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200726_time_series_with_window.csv exists\ntraining on 20200727\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200727_time_series_with_window.csv exists\ntraining on 20200728\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200728_time_series_with_window.csv exists\ntraining on 20200729\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200729_time_series_with_window.csv exists\ntraining on 20200730\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200730_time_series_with_window.csv exists\ntraining on 20200731\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200731_time_series_with_window.csv exists\ntraining on 20200801\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200801_time_series_with_window.csv exists\ntraining on 20200802\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200802_time_series_with_window.csv exists\ntraining on 20200803\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200803_time_series_with_window.csv exists\ntraining on 20200804\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200804_time_series_with_window.csv exists\ntraining on 20200805\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200805_time_series_with_window.csv exists\ntraining on 20200806\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200806_time_series_with_window.csv exists\ntraining on 20200807\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200807_time_series_with_window.csv exists\ntraining on 20200808\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200808_time_series_with_window.csv exists\ntraining on 20200809\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200809_time_series_with_window.csv exists\ntraining on 20200810\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200810_time_series_with_window.csv exists\ntraining on 20200811\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200811_time_series_with_window.csv exists\ntraining on 20200812\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200812_time_series_with_window.csv exists\ntraining on 20200813\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200813_time_series_with_window.csv exists\ntraining on 20200814\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200814_time_series_with_window.csv exists\ntraining on 20200815\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200815_time_series_with_window.csv exists\ntraining on 20200816\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200816_time_series_with_window.csv exists\ntraining on 20200817\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200817_time_series_with_window.csv exists\ntraining on 20200818\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200818_time_series_with_window.csv exists\ntraining on 20200819\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200819_time_series_with_window.csv exists\ntraining on 20200820\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200820_time_series_with_window.csv exists\ntraining on 20200821\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200821_time_series_with_window.csv exists\ntraining on 20200822\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200822_time_series_with_window.csv exists\ntraining on 20200823\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200823_time_series_with_window.csv exists\ntraining on 20200824\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200824_time_series_with_window.csv exists\ntraining on 20200825\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200825_time_series_with_window.csv exists\ntraining on 20200826\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200826_time_series_with_window.csv exists\ntraining on 20200827\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200827_time_series_with_window.csv exists\ntraining on 20200828\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200828_time_series_with_window.csv exists\ntraining on 20200829\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200829_time_series_with_window.csv exists\ntraining on 20200830\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200830_time_series_with_window.csv exists\ntraining on 20200831\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200831_time_series_with_window.csv exists\ntraining on 20200901\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200901_time_series_with_window.csv exists\ntraining on 20200902\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200902_time_series_with_window.csv exists\ntraining on 20200903\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200903_time_series_with_window.csv exists\ntraining on 20200904\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200904_time_series_with_window.csv exists\ntraining on 20200905\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200905_time_series_with_window.csv exists\ntraining on 20200906\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200906_time_series_with_window.csv exists\ntraining on 20200907\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200907_time_series_with_window.csv exists\ntraining on 20200908\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200908_time_series_with_window.csv exists\ntraining on 20200909\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200909_time_series_with_window.csv exists\ntraining on 20200910\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200910_time_series_with_window.csv exists\ntraining on 20200911\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200911_time_series_with_window.csv exists\ntraining on 20200912\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200912_time_series_with_window.csv exists\ntraining on 20200913\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200913_time_series_with_window.csv exists\ntraining on 20200914\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200914_time_series_with_window.csv exists\ntraining on 20200915\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200915_time_series_with_window.csv exists\ntraining on 20200916\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200916_time_series_with_window.csv exists\ntraining on 20200917\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200917_time_series_with_window.csv exists\ntraining on 20200918\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200918_time_series_with_window.csv exists\ntraining on 20200919\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200919_time_series_with_window.csv exists\ntraining on 20200920\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200920_time_series_with_window.csv exists\ntraining on 20200921\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200921_time_series_with_window.csv exists\ntraining on 20200922\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200922_time_series_with_window.csv exists\ntraining on 20200923\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200923_time_series_with_window.csv exists\ntraining on 20200924\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200924_time_series_with_window.csv exists\ntraining on 20200925\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200925_time_series_with_window.csv exists\ntraining on 20200926\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200926_time_series_with_window.csv exists\ntraining on 20200927\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200927_time_series_with_window.csv exists\ntraining on 20200928\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200928_time_series_with_window.csv exists\ntraining on 20200929\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200929_time_series_with_window.csv exists\ntraining on 20200930\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20200930_time_series_with_window.csv exists\ntraining on 20201001\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201001_time_series_with_window.csv exists\ntraining on 20201002\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201002_time_series_with_window.csv exists\ntraining on 20201003\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201003_time_series_with_window.csv exists\ntraining on 20201004\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201004_time_series_with_window.csv exists\ntraining on 20201005\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201005_time_series_with_window.csv exists\ntraining on 20201006\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201006_time_series_with_window.csv exists\ntraining on 20201007\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201007_time_series_with_window.csv exists\ntraining on 20201008\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201008_time_series_with_window.csv exists\ntraining on 20201009\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201009_time_series_with_window.csv exists\ntraining on 20201010\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201010_time_series_with_window.csv exists\ntraining on 20201011\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201011_time_series_with_window.csv exists\ntraining on 20201012\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201012_time_series_with_window.csv exists\ntraining on 20201013\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201013_time_series_with_window.csv exists\ntraining on 20201014\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201014_time_series_with_window.csv exists\ntraining on 20201015\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201015_time_series_with_window.csv exists\ntraining on 20201016\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201016_time_series_with_window.csv exists\ntraining on 20201017\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201017_time_series_with_window.csv exists\ntraining on 20201018\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201018_time_series_with_window.csv exists\ntraining on 20201019\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201019_time_series_with_window.csv exists\ntraining on 20201020\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201020_time_series_with_window.csv exists\ntraining on 20201021\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201021_time_series_with_window.csv exists\ntraining on 20201022\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201022_time_series_with_window.csv exists\ntraining on 20201023\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201023_time_series_with_window.csv exists\ntraining on 20201024\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201024_time_series_with_window.csv exists\ntraining on 20201025\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201025_time_series_with_window.csv exists\ntraining on 20201026\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201026_time_series_with_window.csv exists\ntraining on 20201027\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201027_time_series_with_window.csv exists\ntraining on 20201028\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201028_time_series_with_window.csv exists\ntraining on 20201029\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201029_time_series_with_window.csv exists\ntraining on 20201030\nThe file '/groups/ESS3/zsun/firecasting/data/others//grid_cell_nearest_neight_mapper.csv' exists.\nFolder already exists: /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6/\nFile /groups/ESS3/zsun/firecasting/data/train/all_cells_new_6//20201030_time_series_with_window.csv exists\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 137, in <module>\n    train_model(start_date_str, end_date_str, training_data_folder)\n  File \"fc_model_creation.py\", line 79, in train_model\n    data_combined.to_csv(output_file, index=False)\nNameError: name 'data_combined' is not defined\n",
  "history_begin_time" : 1712345776328,
  "history_end_time" : 1712345784105,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "7rmzxkihtph",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711723378012,
  "history_end_time" : 1711723378012,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "l9njoassa7k",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711722163431,
  "history_end_time" : 1711723321969,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "wxgt5ja4e17",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711203851064,
  "history_end_time" : 1712452724072,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "9ql5iupztzh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711136729434,
  "history_end_time" : 1711136729434,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nlpbo6q5jko",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711136573083,
  "history_end_time" : 1711136662807,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "0tx2zwa6vrr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709930548086,
  "history_end_time" : 1712452725017,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "457efd4c8f2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709930050109,
  "history_end_time" : 1709930509953,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "hnhohntewp8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709444795626,
  "history_end_time" : 1712452725784,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "qqs5twdt540",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709444438265,
  "history_end_time" : 1709444687341,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "TNFxhrdKzAcv",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=7, \n                       n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      \n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n    \n    label += 1\n    \n    if label % 30 == 0:\n      # save the model for every month\n      with open(model_path, 'wb') as model_file:\n        pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_file}\")\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200801\"\nend_date_str = \"20200805\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "training on 20200802\npreparing training data for  20200802\n20200801\n20200731\n20200730\n20200729\n20200728\n20200727\n20200726\ntraining on 20200803\npreparing training data for  20200803\n20200802\n20200801\n20200731\n20200730\n20200729\n20200728\n20200727\ntraining on 20200804\npreparing training data for  20200804\n20200803\n20200802\n20200801\n20200731\n20200730\n20200729\n20200728\ntraining on 20200805\npreparing training data for  20200805\n20200804\n20200803\n20200802\n20200801\n20200731\n20200730\n20200729\ntraining on 20200806\npreparing training data for  20200806\n20200805\n20200804\n20200803\n20200802\n20200801\n20200731\n20200730\nThe new model is saved to <_io.BufferedWriter name='/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl'>\n",
  "history_begin_time" : 1695414030933,
  "history_end_time" : 1695414104759,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Cu4tYzIdSEz7",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=7, \n                       n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      \n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n    \n    label += 1\n    \n    if label % 30 == 0:\n      # save the model for every month\n      with open(model_path, 'wb') as model_file:\n        pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_file}\")\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "training on 20200116\npreparing training data for  20200116\n20200115\n20200114\n20200113\n20200112\n20200111\n20200110\n20200109\ntraining on 20200117\npreparing training data for  20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n20200111\n20200110\ntraining on 20200118\npreparing training data for  20200118\n20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n20200111\ntraining on 20200119\npreparing training data for  20200119\n20200118\n20200117\n20200116\n20200115\n20200114\n20200113\n20200112\nThe new model is saved to <_io.BufferedWriter name='/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl'>\n",
  "history_begin_time" : 1695413775377,
  "history_end_time" : 1695413835261,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ZfMUJDoY8O7M",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=7, \n                       n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      \n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n    \n    label += 1\n    \n    if label % 30 == 0:\n      # save the model for every month\n      with open(model_path, 'wb') as model_file:\n        pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "training on 20200116\npreparing training data for  20200116\n20200115\n20200114\n20200113\n20200112\n20200111\n20200110\n20200109\ntraining on 20200117\npreparing training data for  20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n20200111\n20200110\ntraining on 20200118\npreparing training data for  20200118\n20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n20200111\ntraining on 20200119\npreparing training data for  20200119\n20200118\n20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n",
  "history_begin_time" : 1695390559897,
  "history_end_time" : 1695390634634,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "pmK1AZyfTJlM",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=10, \n                       n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      \n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n    \n    label += 1\n    \n    if label % 30 == 0:\n      # save the model for every month\n      with open(model_path, 'wb') as model_file:\n        pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1694962506070,
  "history_end_time" : 1694969188078,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "b79MGDghyJw1",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=10, \n                       n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      \n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n    \n    label += 1\n    \n    if label % 30 == 0:\n      # save the model for every month\n  \t  with open(model_path, 'wb') as model_file:\n        pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "  File \"fc_model_creation.py\", line 78\n    pickle.dump(model, model_file)\n                                 ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1694962354137,
  "history_end_time" : 1694962354216,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "NW4TCavFVJjF",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  print(\"check point 1\")\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  print(\"check point 2\")\n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=5, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  print(\"check point 3\")\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  print(\"check point 4\")\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "check point 1\ncheck point 2\ncheck point 3\ntraining on 20200116\npreparing training data for  20200116\n20200115\n20200114\n20200113\n20200112\n20200111\n20200110\n20200109\nNew time series dataframe:      LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\ntraining on 20200117\npreparing training data for  20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n20200111\n20200110\nNew time series dataframe:      LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\ntraining on 20200118\npreparing training data for  20200118\n20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n20200111\nNew time series dataframe:      LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\ntraining on 20200119\npreparing training data for  20200119\n20200118\n20200117\n20200116\n20200115\n20200114\n20200113\n20200112\nNew time series dataframe:      LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\ncheck point 4\n",
  "history_begin_time" : 1694959959825,
  "history_end_time" : 1694960360823,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "dtxHhRApZkSA",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  print(\"check point 1\")\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  print(\"check point 2\")\n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=10, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  print(\"check point 3\")\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  print(\"check point 4\")\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1694959655789,
  "history_end_time" : 1694959909426,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "lzF4BPFvYfab",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=10, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1694959503738,
  "history_end_time" : 1694959530222,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "tUtuYc5qXoEE",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=10, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200110\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1694959432027,
  "history_end_time" : 1694959462121,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "9WS9fnmZsG9d",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=15, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20201231\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1694959110538,
  "history_end_time" : 1694959372621,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "14ZrBIx2il34",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=15, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20201231\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1694958219476,
  "history_end_time" : 1694959530126,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "PZOHATmWvkDO",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_30.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, \n                       max_depth=30, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20201231\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1694828236530,
  "history_end_time" : 1694897580937,
  "history_notes" : "weighted xgboost on 2020 yearly with depth 30",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "GLq53AQuTV50",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020.pkl\"\n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  #print(\"target column is \", target_col)\n\n  #print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  #print(\"original dataframe shape: \", df.shape)\n  #print(\"df head:\", df.head())\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  #print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  #print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  #print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  #print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  #print(f\"Mean: {y.mean()}\")\n  #print(f\"Median: {y.median()}\")\n#   print(f\"Standard Deviation: {y.std()}\")\n#   print(f\"Minimum: {y.min()}\")\n#   print(f\"Maximum: {y.max()}\")\n#   print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, \n                       max_depth=5, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20201231\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "training on 20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\ntraining on 20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\ntraining on 20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\ntraining on 20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\ntraining on 20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\ntraining on 20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\ntraining on 20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\ntraining on 20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\ntraining on 20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\ntraining on 20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\ntraining on 20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\ntraining on 20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\ntraining on 20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\ntraining on 20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\ntraining on 20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\ntraining on 20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\ntraining on 20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\ntraining on 20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\ntraining on 20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\ntraining on 20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\ntraining on 20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\ntraining on 20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\ntraining on 20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\ntraining on 20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\ntraining on 20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\ntraining on 20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\ntraining on 20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\ntraining on 20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\ntraining on 20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\ntraining on 20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\ntraining on 20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\ntraining on 20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\ntraining on 20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\ntraining on 20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\ntraining on 20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\ntraining on 20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\ntraining on 20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\ntraining on 20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\ntraining on 20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\ntraining on 20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\ntraining on 20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\ntraining on 20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\ntraining on 20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\ntraining on 20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\ntraining on 20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\ntraining on 20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\ntraining on 20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\ntraining on 20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\ntraining on 20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\ntraining on 20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\ntraining on 20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\ntraining on 20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\ntraining on 20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\ntraining on 20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\ntraining on 20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\ntraining on 20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\ntraining on 20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\ntraining on 20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\ntraining on 20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\ntraining on 20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\ntraining on 20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\ntraining on 20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\ntraining on 20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\ntraining on 20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\ntraining on 20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\ntraining on 20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\ntraining on 20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\ntraining on 20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\ntraining on 20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\ntraining on 20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\ntraining on 20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\ntraining on 20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\ntraining on 20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\ntraining on 20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\ntraining on 20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\ntraining on 20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\ntraining on 20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\ntraining on 20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\ntraining on 20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\ntraining on 20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\ntraining on 20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\ntraining on 20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\ntraining on 20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\ntraining on 20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\ntraining on 20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\ntraining on 20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\ntraining on 20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\ntraining on 20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\ntraining on 20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\ntraining on 20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\ntraining on 20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\ntraining on 20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\ntraining on 20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\ntraining on 20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\ntraining on 20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\ntraining on 20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\ntraining on 20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\ntraining on 20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\ntraining on 20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\ntraining on 20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\ntraining on 20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\ntraining on 20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\ntraining on 20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\ntraining on 20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\ntraining on 20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\ntraining on 20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\ntraining on 20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\ntraining on 20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\ntraining on 20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\ntraining on 20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\ntraining on 20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\ntraining on 20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\ntraining on 20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\ntraining on 20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\ntraining on 20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\ntraining on 20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\ntraining on 20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\ntraining on 20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\ntraining on 20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\ntraining on 20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\ntraining on 20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\ntraining on 20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\ntraining on 20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\ntraining on 20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\ntraining on 20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\ntraining on 20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\ntraining on 20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\ntraining on 20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\ntraining on 20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\ntraining on 20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\ntraining on 20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\ntraining on 20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\ntraining on 20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\ntraining on 20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\ntraining on 20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\ntraining on 20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\ntraining on 20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\ntraining on 20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\ntraining on 20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\ntraining on 20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\ntraining on 20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\ntraining on 20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\ntraining on 20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\ntraining on 20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\ntraining on 20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\ntraining on 20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\ntraining on 20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\ntraining on 20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\ntraining on 20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\ntraining on 20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\ntraining on 20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\ntraining on 20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\ntraining on 20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\ntraining on 20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\ntraining on 20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\ntraining on 20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\ntraining on 20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\ntraining on 20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\ntraining on 20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\ntraining on 20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\ntraining on 20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\ntraining on 20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\ntraining on 20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\ntraining on 20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\ntraining on 20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\ntraining on 20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\ntraining on 20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\ntraining on 20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\ntraining on 20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\ntraining on 20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\ntraining on 20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\ntraining on 20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\ntraining on 20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\ntraining on 20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\ntraining on 20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\ntraining on 20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\ntraining on 20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\ntraining on 20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\ntraining on 20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\ntraining on 20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\ntraining on 20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\ntraining on 20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\ntraining on 20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\ntraining on 20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\ntraining on 20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\ntraining on 20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\ntraining on 20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\ntraining on 20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\ntraining on 20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\ntraining on 20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\ntraining on 20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\ntraining on 20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\ntraining on 20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\ntraining on 20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\ntraining on 20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\ntraining on 20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\ntraining on 20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\ntraining on 20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\ntraining on 20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\ntraining on 20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\ntraining on 20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\ntraining on 20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\ntraining on 20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\ntraining on 20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\ntraining on 20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\ntraining on 20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\ntraining on 20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\ntraining on 20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\ntraining on 20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\ntraining on 20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\ntraining on 20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\ntraining on 20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\ntraining on 20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\ntraining on 20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\ntraining on 20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\ntraining on 20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\ntraining on 20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\ntraining on 20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\ntraining on 20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\ntraining on 20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\ntraining on 20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\ntraining on 20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\ntraining on 20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\ntraining on 20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\ntraining on 20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\ntraining on 20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\ntraining on 20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\ntraining on 20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\ntraining on 20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ntraining on 20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\ntraining on 20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\ntraining on 20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\ntraining on 20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\ntraining on 20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\ntraining on 20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\ntraining on 20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\ntraining on 20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\ntraining on 20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\ntraining on 20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\ntraining on 20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\ntraining on 20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\ntraining on 20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\ntraining on 20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\ntraining on 20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\ntraining on 20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\ntraining on 20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\ntraining on 20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\ntraining on 20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\ntraining on 20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\ntraining on 20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\ntraining on 20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\ntraining on 20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\ntraining on 20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\ntraining on 20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\ntraining on 20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\ntraining on 20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\ntraining on 20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\ntraining on 20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\ntraining on 20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\ntraining on 20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\ntraining on 20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\ntraining on 20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\ntraining on 20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\ntraining on 20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\ntraining on 20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\ntraining on 20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\ntraining on 20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\ntraining on 20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\ntraining on 20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\ntraining on 20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\ntraining on 20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\ntraining on 20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\ntraining on 20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\ntraining on 20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\ntraining on 20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\ntraining on 20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\ntraining on 20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\ntraining on 20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\ntraining on 20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\ntraining on 20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\ntraining on 20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\ntraining on 20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\ntraining on 20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\ntraining on 20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\ntraining on 20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\ntraining on 20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\ntraining on 20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\ntraining on 20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\ntraining on 20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\ntraining on 20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\ntraining on 20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\ntraining on 20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\ntraining on 20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\ntraining on 20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\ntraining on 20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\ntraining on 20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\ntraining on 20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\ntraining on 20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\ntraining on 20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\ntraining on 20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\ntraining on 20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\ntraining on 20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\ntraining on 20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\ntraining on 20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\ntraining on 20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\ntraining on 20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\ntraining on 20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\ntraining on 20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\ntraining on 20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\ntraining on 20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\ntraining on 20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\ntraining on 20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\ntraining on 20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\ntraining on 20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\ntraining on 20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\ntraining on 20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\ntraining on 20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\ntraining on 20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\ntraining on 20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\ntraining on 20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\ntraining on 20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\ntraining on 20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\ntraining on 20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\ntraining on 20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\ntraining on 20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\ntraining on 20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\ntraining on 20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\ntraining on 20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\ntraining on 20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\ntraining on 20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\ntraining on 20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\ntraining on 20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\ntraining on 20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\ntraining on 20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\ntraining on 20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\ntraining on 20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\ntraining on 20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\ntraining on 20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\ntraining on 20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\ntraining on 20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\ntraining on 20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\ntraining on 20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\ntraining on 20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\ntraining on 20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\ntraining on 20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\ntraining on 20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\ntraining on 20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\ntraining on 20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\ntraining on 20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\ntraining on 20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\ntraining on 20201231\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201231.txt\n20201231\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201231.txt\n20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\ntraining on 20210101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210101.txt\n20210101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210101.txt\n20201231\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201231.txt\n20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n",
  "history_begin_time" : 1694209677791,
  "history_end_time" : 1694223744846,
  "history_notes" : "weighted xgboost on 2020 yearly, this model is not good, depth is too shallow",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "sJXkKOIoCIcX",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v3_weighted_one_month_202007.pkl\"\n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  #print(\"target column is \", target_col)\n\n  #print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  #print(\"original dataframe shape: \", df.shape)\n  #print(\"df head:\", df.head())\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  #print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  #print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  #print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  #print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  #print(f\"Mean: {y.mean()}\")\n  #print(f\"Median: {y.median()}\")\n#   print(f\"Standard Deviation: {y.std()}\")\n#   print(f\"Minimum: {y.min()}\")\n#   print(f\"Maximum: {y.max()}\")\n#   print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, \n                       max_depth=5, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200701\"\nend_date_str = \"20200731\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "training on 20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\ntraining on 20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\ntraining on 20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\ntraining on 20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\ntraining on 20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\ntraining on 20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\ntraining on 20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\ntraining on 20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\ntraining on 20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\ntraining on 20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\ntraining on 20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\ntraining on 20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\ntraining on 20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\ntraining on 20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\ntraining on 20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\ntraining on 20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\ntraining on 20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\ntraining on 20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\ntraining on 20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\ntraining on 20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\ntraining on 20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\ntraining on 20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\ntraining on 20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\ntraining on 20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\ntraining on 20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\ntraining on 20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\ntraining on 20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\ntraining on 20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\ntraining on 20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\ntraining on 20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\ntraining on 20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n",
  "history_begin_time" : 1694203893504,
  "history_end_time" : 1694204709674,
  "history_notes" : "weighted training july 2020 first time this is the best model so far",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "5Ti346ODirNE",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v3_weighted_one_month_202007.pkl\"\n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  #print(\"target column is \", target_col)\n\n  #print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  #print(\"original dataframe shape: \", df.shape)\n  #print(\"df head:\", df.head())\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  #print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  #print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  #print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  #print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  #print(f\"Mean: {y.mean()}\")\n  #print(f\"Median: {y.median()}\")\n#   print(f\"Standard Deviation: {y.std()}\")\n#   print(f\"Minimum: {y.min()}\")\n#   print(f\"Maximum: {y.max()}\")\n#   print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, \n                       max_depth=5, \n                       learning_rate=0.1,\n                       eval_metric=rmse,\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200701\"\nend_date_str = \"20200731\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"fc_model_creation.py\", line 128, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 92, in train_model\n    eval_metric=rmse,\nNameError: name 'rmse' is not defined\n",
  "history_begin_time" : 1694203850269,
  "history_end_time" : 1694203862458,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "bvFJWBFdcsjN",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v2_one_month_202007.pkl\"\n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  #print(\"target column is \", target_col)\n\n  #print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  #print(\"original dataframe shape: \", df.shape)\n  #print(\"df head:\", df.head())\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  #print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  #print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  #print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  #print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  #print(f\"Mean: {y.mean()}\")\n  #print(f\"Median: {y.median()}\")\n#   print(f\"Standard Deviation: {y.std()}\")\n#   print(f\"Minimum: {y.min()}\")\n#   print(f\"Maximum: {y.max()}\")\n#   print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    if label == 0:\n      model.fit(X_train, y_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200701\"\nend_date_str = \"20200731\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "training on 20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\ntraining on 20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\ntraining on 20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\ntraining on 20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\ntraining on 20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\ntraining on 20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\ntraining on 20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\ntraining on 20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\ntraining on 20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\ntraining on 20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\ntraining on 20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\ntraining on 20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\ntraining on 20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\ntraining on 20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\ntraining on 20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\ntraining on 20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\ntraining on 20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\ntraining on 20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\ntraining on 20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\ntraining on 20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\ntraining on 20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\ntraining on 20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\ntraining on 20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\ntraining on 20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\ntraining on 20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\ntraining on 20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\ntraining on 20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\ntraining on 20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\ntraining on 20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\ntraining on 20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\ntraining on 20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n",
  "history_begin_time" : 1693630131610,
  "history_end_time" : 1693630829362,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "2Ur6UA0IKrEu",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v2_one_year_2020.pkl\"\n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  #print(\"target column is \", target_col)\n\n  #print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  #print(\"original dataframe shape: \", df.shape)\n  #print(\"df head:\", df.head())\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  #print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  #print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  #print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  #print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  #print(f\"Mean: {y.mean()}\")\n  #print(f\"Median: {y.median()}\")\n#   print(f\"Standard Deviation: {y.std()}\")\n#   print(f\"Minimum: {y.min()}\")\n#   print(f\"Maximum: {y.max()}\")\n#   print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    if label == 0:\n      model.fit(X_train, y_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200108\"\nend_date_str = \"20201231\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "training on 20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200108.txt\n20200107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200107.txt\n20200106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200106.txt\n20200105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200105.txt\n20200104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200104.txt\n20200103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200103.txt\ntraining on 20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200108.txt\n20200107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200107.txt\n20200106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200106.txt\n20200105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200105.txt\n20200104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200104.txt\ntraining on 20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200108.txt\n20200107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200107.txt\n20200106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200106.txt\n20200105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200105.txt\ntraining on 20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200108.txt\n20200107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200107.txt\n20200106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200106.txt\ntraining on 20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200108.txt\n20200107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200107.txt\ntraining on 20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200108.txt\ntraining on 20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\ntraining on 20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\ntraining on 20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\ntraining on 20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\ntraining on 20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\ntraining on 20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\ntraining on 20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\ntraining on 20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\ntraining on 20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\ntraining on 20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\ntraining on 20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\ntraining on 20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\ntraining on 20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\ntraining on 20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\ntraining on 20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\ntraining on 20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\ntraining on 20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\ntraining on 20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\ntraining on 20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\ntraining on 20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\ntraining on 20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\ntraining on 20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\ntraining on 20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\ntraining on 20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\ntraining on 20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\ntraining on 20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\ntraining on 20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\ntraining on 20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\ntraining on 20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\ntraining on 20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\ntraining on 20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\ntraining on 20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\ntraining on 20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\ntraining on 20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\ntraining on 20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\ntraining on 20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\ntraining on 20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\ntraining on 20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\ntraining on 20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\ntraining on 20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\ntraining on 20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\ntraining on 20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\ntraining on 20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\ntraining on 20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\ntraining on 20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\ntraining on 20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\ntraining on 20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\ntraining on 20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\ntraining on 20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\ntraining on 20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\ntraining on 20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\ntraining on 20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\ntraining on 20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\ntraining on 20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\ntraining on 20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\ntraining on 20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\ntraining on 20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\ntraining on 20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\ntraining on 20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\ntraining on 20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\ntraining on 20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\ntraining on 20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\ntraining on 20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\ntraining on 20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\ntraining on 20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\ntraining on 20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\ntraining on 20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\ntraining on 20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\ntraining on 20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\ntraining on 20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\ntraining on 20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\ntraining on 20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\ntraining on 20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\ntraining on 20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\ntraining on 20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\ntraining on 20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\ntraining on 20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\ntraining on 20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\ntraining on 20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\ntraining on 20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\ntraining on 20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\ntraining on 20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\ntraining on 20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\ntraining on 20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\ntraining on 20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\ntraining on 20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\ntraining on 20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\ntraining on 20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\ntraining on 20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\ntraining on 20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\ntraining on 20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\ntraining on 20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\ntraining on 20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\ntraining on 20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\ntraining on 20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\ntraining on 20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\ntraining on 20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\ntraining on 20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\ntraining on 20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\ntraining on 20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\ntraining on 20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\ntraining on 20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\ntraining on 20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\ntraining on 20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\ntraining on 20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\ntraining on 20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\ntraining on 20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\ntraining on 20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\ntraining on 20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\ntraining on 20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\ntraining on 20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\ntraining on 20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\ntraining on 20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\ntraining on 20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\ntraining on 20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\ntraining on 20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\ntraining on 20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\ntraining on 20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\ntraining on 20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\ntraining on 20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\ntraining on 20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\ntraining on 20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\ntraining on 20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\ntraining on 20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\ntraining on 20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\ntraining on 20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\ntraining on 20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\ntraining on 20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\ntraining on 20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\ntraining on 20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\ntraining on 20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\ntraining on 20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\ntraining on 20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\ntraining on 20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\ntraining on 20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\ntraining on 20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\ntraining on 20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\ntraining on 20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\ntraining on 20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\ntraining on 20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\ntraining on 20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\ntraining on 20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\ntraining on 20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\ntraining on 20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\ntraining on 20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\ntraining on 20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\ntraining on 20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\ntraining on 20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\ntraining on 20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\ntraining on 20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\ntraining on 20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\ntraining on 20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\ntraining on 20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\ntraining on 20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\ntraining on 20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\ntraining on 20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\ntraining on 20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\ntraining on 20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\ntraining on 20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\ntraining on 20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\ntraining on 20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\ntraining on 20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\ntraining on 20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\ntraining on 20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\ntraining on 20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\ntraining on 20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\ntraining on 20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\ntraining on 20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\ntraining on 20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\ntraining on 20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\ntraining on 20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\ntraining on 20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\ntraining on 20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\ntraining on 20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\ntraining on 20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\ntraining on 20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\ntraining on 20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\ntraining on 20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\ntraining on 20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\ntraining on 20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\ntraining on 20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\ntraining on 20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\ntraining on 20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\ntraining on 20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\ntraining on 20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\ntraining on 20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\ntraining on 20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\ntraining on 20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\ntraining on 20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\ntraining on 20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\ntraining on 20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\ntraining on 20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\ntraining on 20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\ntraining on 20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\ntraining on 20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\ntraining on 20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\ntraining on 20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\ntraining on 20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\ntraining on 20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\ntraining on 20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\ntraining on 20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\ntraining on 20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\ntraining on 20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\ntraining on 20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\ntraining on 20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\ntraining on 20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\ntraining on 20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\ntraining on 20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\ntraining on 20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\ntraining on 20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\ntraining on 20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\ntraining on 20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\ntraining on 20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\ntraining on 20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\ntraining on 20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\ntraining on 20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\ntraining on 20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\ntraining on 20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\ntraining on 20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\ntraining on 20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\ntraining on 20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\ntraining on 20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\ntraining on 20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\ntraining on 20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\ntraining on 20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\ntraining on 20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\ntraining on 20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\ntraining on 20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\ntraining on 20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\ntraining on 20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ntraining on 20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\ntraining on 20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\ntraining on 20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\ntraining on 20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\ntraining on 20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\ntraining on 20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\ntraining on 20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\ntraining on 20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\ntraining on 20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\ntraining on 20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\ntraining on 20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\ntraining on 20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\ntraining on 20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\ntraining on 20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\ntraining on 20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\ntraining on 20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\ntraining on 20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\ntraining on 20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\ntraining on 20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\ntraining on 20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\ntraining on 20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\ntraining on 20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\ntraining on 20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\ntraining on 20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\ntraining on 20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\ntraining on 20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\ntraining on 20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\ntraining on 20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\ntraining on 20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\ntraining on 20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\ntraining on 20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\ntraining on 20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\ntraining on 20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\ntraining on 20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\ntraining on 20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\ntraining on 20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\ntraining on 20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\ntraining on 20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\ntraining on 20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\ntraining on 20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\ntraining on 20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\ntraining on 20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\ntraining on 20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\ntraining on 20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\ntraining on 20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\ntraining on 20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\ntraining on 20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\ntraining on 20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\ntraining on 20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\ntraining on 20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\ntraining on 20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\ntraining on 20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\ntraining on 20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\ntraining on 20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\ntraining on 20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\ntraining on 20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\ntraining on 20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\ntraining on 20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\ntraining on 20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\ntraining on 20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\ntraining on 20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\ntraining on 20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\ntraining on 20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\ntraining on 20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\ntraining on 20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\ntraining on 20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\ntraining on 20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\ntraining on 20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\ntraining on 20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\ntraining on 20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\ntraining on 20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\ntraining on 20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\ntraining on 20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\ntraining on 20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\ntraining on 20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\ntraining on 20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\ntraining on 20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\ntraining on 20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\ntraining on 20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\ntraining on 20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\ntraining on 20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\ntraining on 20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\ntraining on 20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\ntraining on 20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\ntraining on 20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\ntraining on 20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\ntraining on 20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\ntraining on 20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\ntraining on 20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\ntraining on 20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\ntraining on 20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\ntraining on 20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\ntraining on 20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\ntraining on 20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\ntraining on 20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\ntraining on 20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\ntraining on 20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\ntraining on 20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\ntraining on 20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\ntraining on 20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\ntraining on 20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\ntraining on 20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\ntraining on 20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\ntraining on 20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\ntraining on 20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\ntraining on 20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\ntraining on 20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\ntraining on 20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\ntraining on 20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\ntraining on 20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\ntraining on 20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\ntraining on 20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\ntraining on 20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\ntraining on 20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\ntraining on 20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\ntraining on 20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\ntraining on 20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\ntraining on 20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\ntraining on 20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\ntraining on 20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\ntraining on 20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\ntraining on 20201231\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201231.txt\n20201231\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201231.txt\n20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\ntraining on 20210101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210101.txt\n20210101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210101.txt\n20201231\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201231.txt\n20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n",
  "history_begin_time" : 1693603547357,
  "history_end_time" : 1693615499889,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "kMK3GbYs6GTO",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v2_one_year_2020.pkl\"\n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    if label == 0:\n      model.fit(X_train, y_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200108\"\nend_date_str = \"20201231\"\n#train_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "",
  "history_begin_time" : 1693603384507,
  "history_end_time" : 1693603387371,
  "history_notes" : "one year training",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "b8GjVtMHH1kg",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    if label == 0:\n      model.fit(X_train, y_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200801\"\nend_date_str = \"20200831\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"20200901\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03533253377831329\nMedian: 0.0\nStandard Deviation: 5.001435622347957\nMinimum: 0.0\nMaximum: 1444.431152\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.022544933680137203\nMedian: 0.0\nStandard Deviation: 1.5951113321164974\nMinimum: 0.0\nMaximum: 347.888428\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.039940102868144395\nMedian: 0.0\nStandard Deviation: 4.108068973454069\nMinimum: 0.0\nMaximum: 915.541687\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.02423764787933266\nMedian: 0.0\nStandard Deviation: 2.2273558170808725\nMinimum: 0.0\nMaximum: 597.731689\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.02334024906127079\nMedian: 0.0\nStandard Deviation: 1.6719107056725073\nMinimum: 0.0\nMaximum: 400.929138\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03531522947705293\nMedian: 0.0\nStandard Deviation: 4.8624039265614565\nMinimum: 0.0\nMaximum: 1350.101196\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.02300005454510682\nMedian: 0.0\nStandard Deviation: 2.097558730070113\nMinimum: 0.0\nMaximum: 415.325684\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.018297085113571893\nMedian: 0.0\nStandard Deviation: 2.3039239946139074\nMinimum: 0.0\nMaximum: 622.261414\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.02899671977738252\nMedian: 0.0\nStandard Deviation: 3.506417825227414\nMinimum: 0.0\nMaximum: 1218.387695\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03492281980862036\nMedian: 0.0\nStandard Deviation: 3.8934602756445496\nMinimum: 0.0\nMaximum: 864.288452\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.028137244330968182\nMedian: 0.0\nStandard Deviation: 3.7695721628322545\nMinimum: 0.0\nMaximum: 953.560852\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.036501024480272336\nMedian: 0.0\nStandard Deviation: 3.919910102308357\nMinimum: 0.0\nMaximum: 964.2453\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.04471167255723221\nMedian: 0.0\nStandard Deviation: 4.920418894596109\nMinimum: 0.0\nMaximum: 1130.158691\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.0630194331414437\nMedian: 0.0\nStandard Deviation: 8.82880556550971\nMinimum: 0.0\nMaximum: 3105.80957\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.08531473363041162\nMedian: 0.0\nStandard Deviation: 8.0962047270988\nMinimum: 0.0\nMaximum: 2333.725586\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.06103562084265685\nMedian: 0.0\nStandard Deviation: 4.709315937404089\nMinimum: 0.0\nMaximum: 1144.665649\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.0995423980913038\nMedian: 0.0\nStandard Deviation: 6.710609323419244\nMinimum: 0.0\nMaximum: 1609.110718\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.4485391714575324\nMedian: 0.0\nStandard Deviation: 28.616510784925392\nMinimum: 0.0\nMaximum: 5089.8125\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.2554723482956249\nMedian: 0.0\nStandard Deviation: 14.743279322330583\nMinimum: 0.0\nMaximum: 2923.033691\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.1413884706459862\nMedian: 0.0\nStandard Deviation: 8.345563833805095\nMinimum: 0.0\nMaximum: 1685.769897\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.09757328884808843\nMedian: 0.0\nStandard Deviation: 6.240220740211191\nMinimum: 0.0\nMaximum: 1350.516235\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.11889789131141593\nMedian: 0.0\nStandard Deviation: 8.777749767671489\nMinimum: 0.0\nMaximum: 1782.675415\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.10435461272081649\nMedian: 0.0\nStandard Deviation: 10.104240154667304\nMinimum: 0.0\nMaximum: 3329.859863\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.05188678857077285\nMedian: 0.0\nStandard Deviation: 4.028409250819509\nMinimum: 0.0\nMaximum: 1185.154785\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03053791145663993\nMedian: 0.0\nStandard Deviation: 1.8012685442533103\nMinimum: 0.0\nMaximum: 324.255859\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.044297021439363496\nMedian: 0.0\nStandard Deviation: 2.7230431217632898\nMinimum: 0.0\nMaximum: 416.81958\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.04088418667482673\nMedian: 0.0\nStandard Deviation: 2.682222605595241\nMinimum: 0.0\nMaximum: 424.124695\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.05412846362703285\nMedian: 0.0\nStandard Deviation: 4.6594372211743345\nMinimum: 0.0\nMaximum: 1032.230225\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.034954487788551626\nMedian: 0.0\nStandard Deviation: 2.8787336470006166\nMinimum: 0.0\nMaximum: 546.808228\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03682909143764224\nMedian: 0.0\nStandard Deviation: 3.227510322570268\nMinimum: 0.0\nMaximum: 731.856323\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.0660691098169717\nMedian: 0.0\nStandard Deviation: 6.099316187769047\nMinimum: 0.0\nMaximum: 1712.544189\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.0660691098169717\nMedian: 0.0\nStandard Deviation: 6.099316187769047\nMinimum: 0.0\nMaximum: 1712.544189\nCount: 156861\ny_pred :  [3.8357502e-05 3.8357502e-05 3.8357502e-05 ... 3.8357502e-05 3.8357502e-05\n 3.8357502e-05]\nX_test shape:  (156861, 21)\ny_pred_df shape:  (156861, 1)\ny_pred_df head:     Predicted_FRP\n0       0.000038\n1       0.000038\n2       0.000038\n3       0.000038\n4       0.000038\nmerged_df shape:  (156861, 22)\nthe final merged df is:      LAT         LON    FWI  ...   FRP_day5   FRP_day6  Predicted_FRP\n0  24.5 -126.000000 -999.0  ...        0.0        0.0       0.000038\n1  24.5 -125.899994 -999.0  ...        0.0        0.0       0.000038\n2  24.5 -125.800003 -999.0  ...        0.0        0.0       0.000038\n3  24.5 -125.699997 -999.0  ...        0.0        0.0       0.000038\n4  24.5 -125.599998 -999.0  ...        0.0        0.0       0.000038\n[5 rows x 22 columns]\nMean Absolute Error (MAE): 0.013359157486141526\nMean Squared Error (MSE): 11.94979451349453\nRoot Mean Squared Error (RMSE): 3.4568474819544077\nR-squared (R2) Score: 0.6787812331330938\nExplained Variance Score: 0.6787842344201083\nMean Squared Log Error (MSLE): 0.0009845978097196442\nMedian Absolute Error (MedAE): 3.83575024898164e-05\nMax Error: 1366.0460201874998\n",
  "history_begin_time" : 1693601415881,
  "history_end_time" : 1693602251672,
  "history_notes" : "old approach, look away",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "1p14WQ2N2SDI",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    \n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200801\"\nend_date_str = \"20200831\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"20200901\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03533253377831329\nMedian: 0.0\nStandard Deviation: 5.001435622347957\nMinimum: 0.0\nMaximum: 1444.431152\nCount: 156861\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 112, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 102, in train_model\n    model.fit(X_train, y_train, xgb_model=model)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 532, in inner_f\n    return f(**kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 958, in fit\n    model, metric, params, early_stopping_rounds, callbacks = self._configure_fit(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 788, in _configure_fit\n    model: Optional[Union[Booster, str]] = booster.get_booster()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 590, in get_booster\n    raise NotFittedError('need to call fit or load_model beforehand')\nsklearn.exceptions.NotFittedError: need to call fit or load_model beforehand\n",
  "history_begin_time" : 1693601348655,
  "history_end_time" : 1693601353627,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "Y0oSm2vndJtv",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror',\n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    \n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200801\"\nend_date_str = \"20200831\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"20200901\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"fc_model_creation.py\", line 112, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 89, in train_model\n    scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\nUnboundLocalError: local variable 'y_train' referenced before assignment\n",
  "history_begin_time" : 1693601326316,
  "history_end_time" : 1693601330845,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "rhI3pCBOLMo9",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Initialize and train a model (e.g., Linear Regression)\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror', \n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200801\"\nend_date_str = \"20200831\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"20200901\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03533253377831329\nMedian: 0.0\nStandard Deviation: 5.001435622347957\nMinimum: 0.0\nMaximum: 1444.431152\nCount: 156861\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 110, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 100, in train_model\n    model.fit(X_train, y_train, xgb_model=model)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 532, in inner_f\n    return f(**kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 958, in fit\n    model, metric, params, early_stopping_rounds, callbacks = self._configure_fit(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 788, in _configure_fit\n    model: Optional[Union[Booster, str]] = booster.get_booster()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 590, in get_booster\n    raise NotFittedError('need to call fit or load_model beforehand')\nsklearn.exceptions.NotFittedError: need to call fit or load_model beforehand\n",
  "history_begin_time" : 1693601231859,
  "history_end_time" : 1693601243009,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "ha75q5CEVGAS",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y-%m-%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Initialize and train a model (e.g., Linear Regression)\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror', \n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"2020-08-01\"\nend_date_str = \"2020-08-31\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"2020-09-01\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_2020-08-02.txt\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 110, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 92, in train_model\n    X, y = prepare_training_data(date_str)\n  File \"fc_model_creation.py\", line 34, in prepare_training_data\n    original_df = get_one_day_time_series_training_data(target_date)\n  File \"/home/zsun/gw-workspace/ha75q5CEVGAS/fc_train_data_preprocess.py\", line 47, in get_one_day_time_series_training_data\n    df = read_original_txt_files(target_day)\n  File \"/home/zsun/gw-workspace/ha75q5CEVGAS/fc_train_data_preprocess.py\", line 29, in read_original_txt_files\n    file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 575, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n    self.handles = get_handle(  # type: ignore[call-overload]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\", line 789, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/groups/ESS3/yli74/data/AI_Emis/firedata/firedata_2020-08-02.txt'\n",
  "history_begin_time" : 1693601200666,
  "history_end_time" : 1693601204789,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "jeXuWjEmbJKX",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data()\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y-%m-%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Initialize and train a model (e.g., Linear Regression)\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror', \n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"2020-08-01\"\nend_date_str = \"2020-08-31\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"2020-09-01\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 110, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 92, in train_model\n    X, y = prepare_training_data(date_str)\n  File \"fc_model_creation.py\", line 34, in prepare_training_data\n    original_df = get_one_day_time_series_training_data()\nTypeError: get_one_day_time_series_training_data() missing 1 required positional argument: 'target_day'\n",
  "history_begin_time" : 1693601158192,
  "history_end_time" : 1693601160432,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "X5Qt6dKJ2US3",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data()\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y-%m-%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Initialize and train a model (e.g., Linear Regression)\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror', \n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"2020-08-01\"\nend_date_str = \"2020-08-31\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"2020-09-01\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"fc_model_creation.py\", line 110, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 90, in train_model\n    current_date += timedelta(days=1)\nNameError: name 'timedelta' is not defined\n",
  "history_begin_time" : 1693601133194,
  "history_end_time" : 1693601135474,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "UW465y9HCqBR",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data()\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y-%m-%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Initialize and train a model (e.g., Linear Regression)\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror', \n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"2020-08-01\"\nend_date_str = \"2020-08-31\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"2020-09-01\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"fc_model_creation.py\", line 109, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 79, in train_model\n    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\nNameError: name 'datetime' is not defined\n",
  "history_begin_time" : 1693601110256,
  "history_end_time" : 1693601113461,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "m7jxSasxja09",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data()\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y-%m-%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Initialize and train a model (e.g., Linear Regression)\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror', \n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n  \tmodel.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"2020-08-01\"\nend_date_str = \"2020-08-31\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"2020-09-01\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "  File \"fc_model_creation.py\", line 99\n    model.fit(X_train, y_train, xgb_model=model)\n                                               ^\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1693601077211,
  "history_end_time" : 1693601077285,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "VG9xEBXEwoyx",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X_test.shape)\ny_pred_df = pd.DataFrame(y_pred)\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nmerged_df = X_test.join(y_pred_df)\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nX_test shape:  (28, 20)\ny_pred_df shape:  (28, 1)\nmerged_df shape:  (28, 21)\nthe final merged df is:               LAT         LON        FWI  ...   FRP_day5   FRP_day6   0\n94388  40.199997 -122.899994  50.840454  ...        0.0        0.0 NaN\n96914  40.600006 -110.699997  43.610882  ...        0.0        0.0 NaN\n96915  40.600006 -110.599998  45.627563  ...        0.0        0.0 NaN\n97125  40.600006  -89.599998  31.058390  ...        0.0        0.0 NaN\n97515  40.699997 -110.699997  49.625000  ...        0.0        0.0 NaN\n[5 rows x 21 columns]\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693597974393,
  "history_end_time" : 1693597990145,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Nd09ErX9TFH7",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X_test.shape)\ny_pred_df = pd.DataFrame(y_pred)\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nmerged_df = pd.concat([X_test, y_pred_df], axis=1)\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nX_test shape:  (28, 20)\ny_pred_df shape:  (28, 1)\nmerged_df shape:  (56, 21)\nthe final merged df is:               LAT         LON        FWI  ...   FRP_day5   FRP_day6   0\n94388  40.199997 -122.899994  50.840454  ...        0.0        0.0 NaN\n96914  40.600006 -110.699997  43.610882  ...        0.0        0.0 NaN\n96915  40.600006 -110.599998  45.627563  ...        0.0        0.0 NaN\n97125  40.600006  -89.599998  31.058390  ...        0.0        0.0 NaN\n97515  40.699997 -110.699997  49.625000  ...        0.0        0.0 NaN\n[5 rows x 21 columns]\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693597848042,
  "history_end_time" : 1693597858371,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "SRhx7WMx7Ort",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X_test.shape)\ny_pred_df = pd.DataFrame(y_pred)\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nmerged_df = pd.concat([X_test, y_pred_df], axis=0)\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nX_test shape:  (28, 20)\ny_pred_df shape:  (28, 1)\nmerged_df shape:  (56, 21)\nthe final merged df is:               LAT         LON        FWI  ...   FRP_day5   FRP_day6   0\n94388  40.199997 -122.899994  50.840454  ...        0.0        0.0 NaN\n96914  40.600006 -110.699997  43.610882  ...        0.0        0.0 NaN\n96915  40.600006 -110.599998  45.627563  ...        0.0        0.0 NaN\n97125  40.600006  -89.599998  31.058390  ...        0.0        0.0 NaN\n97515  40.699997 -110.699997  49.625000  ...        0.0        0.0 NaN\n[5 rows x 21 columns]\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693597765698,
  "history_end_time" : 1693597776569,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "gvSoi3i8Bpvc",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X_test.shape)\ny_pred_df = pd.DataFrame(y_pred)\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nmerged_df = pd.concat([X_test, y_pred_df], axis=1)\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nX_test shape:  (28, 20)\ny_pred_df shape:  (28, 1)\nmerged_df shape:  (56, 21)\nthe final merged df is:               LAT         LON        FWI  ...   FRP_day5   FRP_day6   0\n94388  40.199997 -122.899994  50.840454  ...        0.0        0.0 NaN\n96914  40.600006 -110.699997  43.610882  ...        0.0        0.0 NaN\n96915  40.600006 -110.599998  45.627563  ...        0.0        0.0 NaN\n97125  40.600006  -89.599998  31.058390  ...        0.0        0.0 NaN\n97515  40.699997 -110.699997  49.625000  ...        0.0        0.0 NaN\n[5 rows x 21 columns]\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693597671760,
  "history_end_time" : 1693597685011,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "VTFSUjlxmyR8",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X_test.shape)\ny_pred_df = pd.DataFrame(y_pred)\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nmerged_df = pd.concat([X_test, y_pred_df], axis=1)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nX_test shape:  (28, 20)\ny_pred_df shape:  (28, 1)\nthe final merged df is:               LAT         LON        FWI  ...   FRP_day5   FRP_day6   0\n94388  40.199997 -122.899994  50.840454  ...        0.0        0.0 NaN\n96914  40.600006 -110.699997  43.610882  ...        0.0        0.0 NaN\n96915  40.600006 -110.599998  45.627563  ...        0.0        0.0 NaN\n97125  40.600006  -89.599998  31.058390  ...        0.0        0.0 NaN\n97515  40.699997 -110.699997  49.625000  ...        0.0        0.0 NaN\n[5 rows x 21 columns]\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693597614981,
  "history_end_time" : 1693597627664,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "RI3CE7XJ1YFg",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\ny_pred_df = pd.DataFrame(y_pred)\nmerged_df = pd.concat([X_test, y_pred_df], axis=1)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nthe final merged df is:               LAT         LON        FWI  ...   FRP_day5   FRP_day6   0\n94388  40.199997 -122.899994  50.840454  ...        0.0        0.0 NaN\n96914  40.600006 -110.699997  43.610882  ...        0.0        0.0 NaN\n96915  40.600006 -110.599998  45.627563  ...        0.0        0.0 NaN\n97125  40.600006  -89.599998  31.058390  ...        0.0        0.0 NaN\n97515  40.699997 -110.699997  49.625000  ...        0.0        0.0 NaN\n[5 rows x 21 columns]\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693597490894,
  "history_end_time" : 1693597504550,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "96mvvF54gQBY",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\nmerged_df = pd.concat([X_test_scaled, y_pred], axis=1)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 85, in <module>\n    merged_df = pd.concat([X_test_scaled, y_pred], axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 436, in __init__\n    raise TypeError(msg)\nTypeError: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid\n",
  "history_begin_time" : 1693597354799,
  "history_end_time" : 1693597378410,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "0BPoJ6KCvTPe",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693206673377,
  "history_end_time" : 1693206686019,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "rYgJTzSpPBRg",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (82397, 21)\nDF shape 3:  (115, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 48.05469853913042\nMedian: 9.052997\nStandard Deviation: 109.29507441107424\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 115\nMean Absolute Error (MAE): 5.271915000394738\nMean Squared Error (MSE): 521.3498118891711\nRoot Mean Squared Error (RMSE): 22.833085903775054\nR-squared (R2) Score: 0.9763716966839361\nExplained Variance Score: 0.9772021949521695\nMean Squared Log Error (MSLE): 0.001706330429541936\nMedian Absolute Error (MedAE): 0.05398959977722173\nMax Error: 109.02972387890622\n",
  "history_begin_time" : 1693206448569,
  "history_end_time" : 1693206457192,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ss9AW4A1mFHr",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200829\n20200828\n20200827\n20200826\n  File \"fc_model_creation.py\", line 28, in <module>\nNameError: name 'df' is not defined\n",
  "history_begin_time" : 1693206409945,
  "history_end_time" : 1693206421639,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "lYU3GFPM2g7s",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20200831\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (82397, 21)\nDF shape 3:  (115, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 48.05469853913042\nMedian: 9.052997\nStandard Deviation: 109.29507441107424\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 115\nMean Absolute Error (MAE): 5.271915000394738\nMean Squared Error (MSE): 521.3498118891711\nRoot Mean Squared Error (RMSE): 22.833085903775054\nR-squared (R2) Score: 0.9763716966839361\nExplained Variance Score: 0.9772021949521695\nMean Squared Log Error (MSLE): 0.001706330429541936\nMedian Absolute Error (MedAE): 0.05398959977722173\nMax Error: 109.02972387890622\n",
  "history_begin_time" : 1692995649047,
  "history_end_time" : 1692995657098,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "7rrjasvpIWPM",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20200831\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\n# df = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1692995413928,
  "history_end_time" : 1692995424414,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "qf6Tkog9b1L6",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20200831\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 48.05469853913042\nMedian: 9.052997\nStandard Deviation: 109.29507441107424\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 115\nMean Absolute Error (MAE): 5.271915000394738\nMean Squared Error (MSE): 521.3498118891711\nRoot Mean Squared Error (RMSE): 22.833085903775054\nR-squared (R2) Score: 0.9763716966839361\nExplained Variance Score: 0.9772021949521695\nMean Squared Log Error (MSLE): 0.001706330429541936\nMedian Absolute Error (MedAE): 0.05398959977722173\nMax Error: 109.02972387890622\n",
  "history_begin_time" : 1692995314226,
  "history_end_time" : 1692995330218,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "CxZ9FapGj7rC",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20210218\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210218.txt\n20210218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210218.txt\n20210217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210217.txt\n20210216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210216.txt\n20210215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210215.txt\n20210214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210214.txt\n20210213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210213.txt\n20210212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210212.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 36.666039975000004\nMedian: 8.217869499999999\nStandard Deviation: 143.1139189739819\nMinimum: 1.094497\nMaximum: 911.57196\nCount: 40\nMean Absolute Error (MAE): 4.947174662240982\nMean Squared Error (MSE): 83.35387210652895\nRoot Mean Squared Error (RMSE): 9.129834177383998\nR-squared (R2) Score: 0.8742441895127026\nExplained Variance Score: 0.9055395080096791\nMean Squared Log Error (MSLE): 0.5165493718232521\nMedian Absolute Error (MedAE): 0.6575485969161987\nMax Error: 21.456614556518556\n",
  "history_begin_time" : 1692995218542,
  "history_end_time" : 1692995232914,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "vIGKRSau47Bp",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20210718\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210718.txt\n20210718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210718.txt\n20210717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210717.txt\n20210716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210716.txt\n20210715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210715.txt\n20210714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\n20210713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\n20210712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 530.6795509732616\nMedian: 25.199823\nStandard Deviation: 1684.3803246506955\nMinimum: 1.549921\nMaximum: 13514.680664\nCount: 187\nMean Absolute Error (MAE): 15.9335517238115\nMean Squared Error (MSE): 2205.2001352060215\nRoot Mean Squared Error (RMSE): 46.95955850735845\nR-squared (R2) Score: 0.9965059261518785\nExplained Variance Score: 0.9965193195935235\nMean Squared Log Error (MSLE): 0.0015996365916858897\nMedian Absolute Error (MedAE): 0.7955913493652336\nMax Error: 211.891113578125\n",
  "history_begin_time" : 1692995157714,
  "history_end_time" : 1692995170474,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "QCmK1BedpRTW",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20210718\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210718.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST         SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0   1.25 -999.000000 -999.00000\n...      ...         ...   ...         ...  ...    ...    ...         ...        ...\n156856  50.5  -66.400002   0.0    7.942285  ...    0.0   0.00  288.724976    0.22775\n156857  50.5  -66.299995   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156858  50.5  -66.199997   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156859  50.5  -66.099998   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n156860  50.5  -66.000000   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n[156861 rows x 15 columns]\n20210718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210718.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST         SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0   1.25 -999.000000 -999.00000\n...      ...         ...   ...         ...  ...    ...    ...         ...        ...\n156856  50.5  -66.400002   0.0    7.942285  ...    0.0   0.00  288.724976    0.22775\n156857  50.5  -66.299995   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156858  50.5  -66.199997   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156859  50.5  -66.099998   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n156860  50.5  -66.000000   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n[156861 rows x 15 columns]\n20210717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210717.txt\n         LAT         LON   FRP  ...   CAPE          ST        SM\n0       24.5 -126.000000   0.0  ...  11.00 -999.000000 -999.0000\n1       24.5 -125.899994   0.0  ...  11.00 -999.000000 -999.0000\n2       24.5 -125.800003   0.0  ...   7.75 -999.000000 -999.0000\n3       24.5 -125.699997   0.0  ...   7.75 -999.000000 -999.0000\n4       24.5 -125.599998   0.0  ...   6.75 -999.000000 -999.0000\n...      ...         ...   ...  ...    ...         ...       ...\n156856  50.5  -66.400002   0.0  ...  14.00  287.457092    0.2525\n156857  50.5  -66.299995   0.0  ...  11.75  287.657074    0.2545\n156858  50.5  -66.199997   0.0  ...  11.75  287.657074    0.2545\n156859  50.5  -66.099998   0.0  ...  12.50  287.457092    0.2635\n156860  50.5  -66.000000   0.0  ...  12.50  287.457092    0.2635\n[156861 rows x 15 columns]\n20210716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210716.txt\n         LAT         LON   FRP  ...   CAPE          ST         SM\n0       24.5 -126.000000   0.0  ...   4.50 -999.000000 -999.00000\n1       24.5 -125.899994   0.0  ...   4.50 -999.000000 -999.00000\n2       24.5 -125.800003   0.0  ...   4.25 -999.000000 -999.00000\n3       24.5 -125.699997   0.0  ...   4.25 -999.000000 -999.00000\n4       24.5 -125.599998   0.0  ...   8.25 -999.000000 -999.00000\n...      ...         ...   ...  ...    ...         ...        ...\n156856  50.5  -66.400002   0.0  ...   6.75  289.084656    0.26425\n156857  50.5  -66.299995   0.0  ...   3.75  288.959656    0.26125\n156858  50.5  -66.199997   0.0  ...   3.75  288.959656    0.26125\n156859  50.5  -66.099998   0.0  ...   4.75  288.759644    0.26625\n156860  50.5  -66.000000   0.0  ...   4.75  288.759644    0.26625\n[156861 rows x 15 columns]\n20210715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210715.txt\n         LAT         LON   FRP  ...   CAPE          ST         SM\n0       24.5 -126.000000   0.0  ...   3.00 -999.000000 -999.00000\n1       24.5 -125.899994   0.0  ...   3.00 -999.000000 -999.00000\n2       24.5 -125.800003   0.0  ...   3.25 -999.000000 -999.00000\n3       24.5 -125.699997   0.0  ...   3.25 -999.000000 -999.00000\n4       24.5 -125.599998   0.0  ...   4.00 -999.000000 -999.00000\n...      ...         ...   ...  ...    ...         ...        ...\n156856  50.5  -66.400002   0.0  ...   4.75  287.614502    0.25250\n156857  50.5  -66.299995   0.0  ...   7.00  287.839508    0.24525\n156858  50.5  -66.199997   0.0  ...   7.00  287.839508    0.24525\n156859  50.5  -66.099998   0.0  ...   9.25  287.914490    0.25500\n156860  50.5  -66.000000   0.0  ...   9.25  287.914490    0.25500\n[156861 rows x 15 columns]\n20210714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\n         LAT         LON   FRP  ...   CAPE          ST         SM\n0       24.5 -126.000000   0.0  ...   1.25 -999.000000 -999.00000\n1       24.5 -125.899994   0.0  ...   1.25 -999.000000 -999.00000\n2       24.5 -125.800003   0.0  ...   1.00 -999.000000 -999.00000\n3       24.5 -125.699997   0.0  ...   1.00 -999.000000 -999.00000\n4       24.5 -125.599998   0.0  ...   2.25 -999.000000 -999.00000\n...      ...         ...   ...  ...    ...         ...        ...\n156856  50.5  -66.400002   0.0  ...   0.50  288.689514    0.20850\n156857  50.5  -66.299995   0.0  ...   0.50  288.689484    0.20625\n156858  50.5  -66.199997   0.0  ...   0.50  288.689484    0.20625\n156859  50.5  -66.099998   0.0  ...   0.00  288.589508    0.21550\n156860  50.5  -66.000000   0.0  ...   0.00  288.589508    0.21550\n[156861 rows x 15 columns]\n20210713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\n         LAT         LON   FRP  ...   CAPE          ST         SM\n0       24.5 -126.000000   0.0  ...   2.75 -999.000000 -999.00000\n1       24.5 -125.899994   0.0  ...   2.75 -999.000000 -999.00000\n2       24.5 -125.800003   0.0  ...   2.25 -999.000000 -999.00000\n3       24.5 -125.699997   0.0  ...   2.25 -999.000000 -999.00000\n4       24.5 -125.599998   0.0  ...   2.25 -999.000000 -999.00000\n...      ...         ...   ...  ...    ...         ...        ...\n156856  50.5  -66.400002   0.0  ...   0.00  287.959656    0.21025\n156857  50.5  -66.299995   0.0  ...   0.00  287.909668    0.21025\n156858  50.5  -66.199997   0.0  ...   0.00  287.909668    0.21025\n156859  50.5  -66.099998   0.0  ...   0.00  287.409668    0.22325\n156860  50.5  -66.000000   0.0  ...   0.00  287.409668    0.22325\n[156861 rows x 15 columns]\n20210712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\n         LAT         LON   FRP  ...   CAPE          ST         SM\n0       24.5 -126.000000   0.0  ...   2.50 -999.000000 -999.00000\n1       24.5 -125.899994   0.0  ...   2.50 -999.000000 -999.00000\n2       24.5 -125.800003   0.0  ...   1.75 -999.000000 -999.00000\n3       24.5 -125.699997   0.0  ...   1.75 -999.000000 -999.00000\n4       24.5 -125.599998   0.0  ...   1.50 -999.000000 -999.00000\n...      ...         ...   ...  ...    ...         ...        ...\n156856  50.5  -66.400002   0.0  ...  25.50  286.714478    0.19900\n156857  50.5  -66.299995   0.0  ...  25.50  286.664490    0.19500\n156858  50.5  -66.199997   0.0  ...  25.50  286.664490    0.19500\n156859  50.5  -66.099998   0.0  ...  21.00  285.964478    0.20625\n156860  50.5  -66.000000   0.0  ...  21.00  285.964478    0.20625\n[156861 rows x 15 columns]\nNew time series dataframe:      LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 28, in <module>\n    print(\"df head:\", df.head())\nAttributeError: 'NoneType' object has no attribute 'head'\n",
  "history_begin_time" : 1692995097247,
  "history_end_time" : 1692995104500,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "lfOnEw1poC1j",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20210718\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 26, in <module>\n    df = get_one_day_time_series_training_data(\"20210718\")\nNameError: name 'get_one_day_time_series_training_data' is not defined\n",
  "history_begin_time" : 1692995075050,
  "history_end_time" : 1692995077087,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "uCqi97jN8wTr",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files(\"20210718\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210718.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST         SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0   1.25 -999.000000 -999.00000\n...      ...         ...   ...         ...  ...    ...    ...         ...        ...\n156856  50.5  -66.400002   0.0    7.942285  ...    0.0   0.00  288.724976    0.22775\n156857  50.5  -66.299995   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156858  50.5  -66.199997   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156859  50.5  -66.099998   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n156860  50.5  -66.000000   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0   0.75 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0   0.75 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0   1.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0   1.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0   1.25 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 530.6795509732616\nMedian: 25.199823\nStandard Deviation: 1684.3803246506955\nMinimum: 1.549921\nMaximum: 13514.680664\nCount: 187\nMean Absolute Error (MAE): 396.13433185127985\nMean Squared Error (MSE): 609103.5879448707\nRoot Mean Squared Error (RMSE): 780.4508875931084\nR-squared (R2) Score: 0.03489353031610776\nExplained Variance Score: 0.04466233519385432\nMean Squared Log Error (MSLE): 8.470113886759837\nMedian Absolute Error (MedAE): 158.75452503808594\nMax Error: 3949.305908421875\n",
  "history_begin_time" : 1692994468960,
  "history_end_time" : 1692994479303,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "mglMy7eZ7MJ3",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files(\"20210718\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210718.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST         SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0   1.25 -999.000000 -999.00000\n...      ...         ...   ...         ...  ...    ...    ...         ...        ...\n156856  50.5  -66.400002   0.0    7.942285  ...    0.0   0.00  288.724976    0.22775\n156857  50.5  -66.299995   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156858  50.5  -66.199997   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156859  50.5  -66.099998   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n156860  50.5  -66.000000   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0   0.75 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0   0.75 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0   1.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0   1.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0   1.25 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 530.6795509732616\nMedian: 25.199823\nStandard Deviation: 1684.3803246506955\nMinimum: 1.549921\nMaximum: 13514.680664\nCount: 187\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 83, in <module>\n    msle = mean_squared_log_error(y_test, y_pred)\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 521, in mean_squared_log_error\n    raise ValueError(\nValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
  "history_begin_time" : 1692994360977,
  "history_end_time" : 1692994373105,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "TCzhmOM9HBrg",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 10.92559504232805\nMedian: 4.6991705\nStandard Deviation: 21.966998026788197\nMinimum: 0.965435\nMaximum: 347.776581\nCount: 378\nMean Absolute Error (MAE): 12.799336186072699\nMean Squared Error (MSE): 281.5354821767195\nRoot Mean Squared Error (RMSE): 16.779019106512738\nR-squared (R2) Score: -0.2847023496273453\nExplained Variance Score: -0.284699465243478\nMean Squared Log Error (MSLE): 1.0377558642742204\nMedian Absolute Error (MedAE): 9.37986898965454\nMax Error: 61.46578656231689\n",
  "history_begin_time" : 1692993626935,
  "history_end_time" : 1692993639823,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "vQ5VDoSipi5D",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 17.985333120689653\nMedian: 4.751074\nStandard Deviation: 94.21813114242096\nMinimum: 0.965435\nMaximum: 1646.294556\nCount: 406\nMean Absolute Error (MAE): 11.794470010610627\nMean Squared Error (MSE): 264.47291503063815\nRoot Mean Squared Error (RMSE): 16.26262325182005\nR-squared (R2) Score: -0.2601266873676482\nExplained Variance Score: -0.2548748308648898\nMean Squared Log Error (MSLE): 0.9326069215147905\nMedian Absolute Error (MedAE): 8.603539597595214\nMax Error: 63.44861994778442\n",
  "history_begin_time" : 1692993456785,
  "history_end_time" : 1692993465928,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "KlQQfHpCb8u9",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 17.985333120689653\nMedian: 4.751074\nStandard Deviation: 94.21813114242096\nMinimum: 0.965435\nMaximum: 1646.294556\nCount: 406\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 73, in <module>\n    mae = mean_absolute_error(y_test, y_pred)\nNameError: name 'mean_absolute_error' is not defined\n",
  "history_begin_time" : 1692993413399,
  "history_end_time" : 1692993423523,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "CEbCotuSoW7u",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 17.985333120689653\nMedian: 4.751074\nStandard Deviation: 94.21813114242096\nMinimum: 0.965435\nMaximum: 1646.294556\nCount: 406\nMean Squared Error: 264.47291503063815\n",
  "history_begin_time" : 1692993318688,
  "history_end_time" : 1692993327208,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "QsAV1jI8Cj0O",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 17.985333120689653\nMedian: 4.751074\nStandard Deviation: 94.21813114242096\nMinimum: 0.965435\nMaximum: 1646.294556\nCount: 406\nMean Squared Error: 264.47291503063815\n",
  "history_begin_time" : 1692993179093,
  "history_end_time" : 1692993186617,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "WbNzFIEpNaQa",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: nan\nMedian: nan\nStandard Deviation: nan\nMinimum: nan\nMaximum: nan\nCount: 0\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 58, in <module>\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2420, in train_test_split\n    n_train, n_test = _validate_shuffle_split(\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2098, in _validate_shuffle_split\n    raise ValueError(\nValueError: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n",
  "history_begin_time" : 1692993150278,
  "history_end_time" : 1692993152556,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "4lEbyWJVpNDW",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.04655105633012667\nMedian: 0.0\nStandard Deviation: 4.873902465653481\nMinimum: 0.0\nMaximum: 1646.294556\nCount: 156861\nMean Squared Error: 0.9566758446781316\n",
  "history_begin_time" : 1692992899256,
  "history_end_time" : 1692992927818,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "vaEFadIBYD7V",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\nMean Squared Error: 0.9566758446781316\n",
  "history_begin_time" : 1692992735081,
  "history_end_time" : 1692992754942,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "6u3leqcajIum",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 49, in <module>\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nNameError: name 'XGBRegressor' is not defined\n",
  "history_begin_time" : 1692992537769,
  "history_end_time" : 1692992542416,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "MIGKKlARN3f2",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\n#warnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "fc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\n",
  "history_begin_time" : 1692992453793,
  "history_end_time" : 1692992482323,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "NO8oZH54xxmA",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "",
  "history_begin_time" : 1692992384939,
  "history_end_time" : 1692992410059,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "O2Gv4xIewqWR",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\n\nprint(\"read the txt files into python dataframes\")\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1692988193082,
  "history_end_time" : 1692992221834,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "0GIWHDJLcarH",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "",
  "history_begin_time" : 1692389635664,
  "history_end_time" : 1692390046556,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "PQK7nrMSMmLb",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = 'FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ...\n       ' HT_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' T_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' RH_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' U_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' V_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' P_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' RAIN_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' CAPE_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' ST_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' SM_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7'],\n      dtype='object', length=1920)\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 32, in <module>\n    X = df.drop([target_col], axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 4948, in drop\n    return super().drop(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4279, in drop\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4323, in _drop_axis\n    new_axis = axis.drop(labels, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 6644, in drop\n    raise KeyError(f\"{list(labels[mask])} not found in axis\")\nKeyError: \"['FRP'] not found in axis\"\n",
  "history_begin_time" : 1692389597380,
  "history_end_time" : 1692389607600,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "tsku6bTnS1MO",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = 'FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 31, in <module>\n    X = df.drop([target_col], axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 4948, in drop\n    return super().drop(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4279, in drop\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4323, in _drop_axis\n    new_axis = axis.drop(labels, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 6644, in drop\n    raise KeyError(f\"{list(labels[mask])} not found in axis\")\nKeyError: \"['FRP'] not found in axis\"\n",
  "history_begin_time" : 1692389530756,
  "history_end_time" : 1692389541665,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "tagkcP7hmeJd",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = 'FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nX = df.drop(target_col, axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 31, in <module>\n    X = df.drop(target_col, axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 4948, in drop\n    return super().drop(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4279, in drop\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4323, in _drop_axis\n    new_axis = axis.drop(labels, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 6644, in drop\n    raise KeyError(f\"{list(labels[mask])} not found in axis\")\nKeyError: \"['FRP'] not found in axis\"\n",
  "history_begin_time" : 1692389336295,
  "history_end_time" : 1692389347332,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "cGUkMJlAsct0",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = 'FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nX = df.drop(target_col, axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 31, in <module>\n    X = df.drop(target_col, axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 4948, in drop\n    return super().drop(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4279, in drop\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4323, in _drop_axis\n    new_axis = axis.drop(labels, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 6644, in drop\n    raise KeyError(f\"{list(labels[mask])} not found in axis\")\nKeyError: \"['FRP'] not found in axis\"\n",
  "history_begin_time" : 1692389287462,
  "history_end_time" : 1692389308721,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "Zqs0KWMkZn6v",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = 'FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nX = df.drop(target_col, axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 13, in <module>\n    warnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\nNameError: name 'warnings' is not defined\n",
  "history_begin_time" : 1692389256429,
  "history_end_time" : 1692389260965,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "kgkZrhMh05ZB",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n\n# Assuming 'target' is the column to predict\ntarget_col = 'FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nX = df.drop(target_col, axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "fc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 27, in <module>\n    X = df.drop(target_col, axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 4948, in drop\n    return super().drop(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4279, in drop\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4323, in _drop_axis\n    new_axis = axis.drop(labels, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 6644, in drop\n    raise KeyError(f\"{list(labels[mask])} not found in axis\")\nKeyError: \"['FRP'] not found in axis\"\n",
  "history_begin_time" : 1692389194072,
  "history_end_time" : 1692389214366,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "v6arpyjo2v8",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1692388306774,
  "history_end_time" : 1692388310312,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Done"
},]
