[{
  "history_id" : "TNFxhrdKzAcv",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=7, \n                       n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      \n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n    \n    label += 1\n    \n    if label % 30 == 0:\n      # save the model for every month\n      with open(model_path, 'wb') as model_file:\n        pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_file}\")\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200801\"\nend_date_str = \"20200805\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "training on 20200802\npreparing training data for  20200802\n20200801\n20200731\n20200730\n20200729\n20200728\n20200727\n20200726\ntraining on 20200803\npreparing training data for  20200803\n20200802\n20200801\n20200731\n20200730\n20200729\n20200728\n20200727\ntraining on 20200804\npreparing training data for  20200804\n20200803\n20200802\n20200801\n20200731\n20200730\n20200729\n20200728\ntraining on 20200805\npreparing training data for  20200805\n20200804\n20200803\n20200802\n20200801\n20200731\n20200730\n20200729\ntraining on 20200806\npreparing training data for  20200806\n20200805\n20200804\n20200803\n20200802\n20200801\n20200731\n20200730\nThe new model is saved to <_io.BufferedWriter name='/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl'>\n",
  "history_begin_time" : 1695414030933,
  "history_end_time" : 1695414104759,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Cu4tYzIdSEz7",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=7, \n                       n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      \n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n    \n    label += 1\n    \n    if label % 30 == 0:\n      # save the model for every month\n      with open(model_path, 'wb') as model_file:\n        pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n      print(f\"The new model is saved to {model_file}\")\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "training on 20200116\npreparing training data for  20200116\n20200115\n20200114\n20200113\n20200112\n20200111\n20200110\n20200109\ntraining on 20200117\npreparing training data for  20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n20200111\n20200110\ntraining on 20200118\npreparing training data for  20200118\n20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n20200111\ntraining on 20200119\npreparing training data for  20200119\n20200118\n20200117\n20200116\n20200115\n20200114\n20200113\n20200112\nThe new model is saved to <_io.BufferedWriter name='/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl'>\n",
  "history_begin_time" : 1695413775377,
  "history_end_time" : 1695413835261,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ZfMUJDoY8O7M",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=7, \n                       n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      \n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n    \n    label += 1\n    \n    if label % 30 == 0:\n      # save the model for every month\n      with open(model_path, 'wb') as model_file:\n        pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "training on 20200116\npreparing training data for  20200116\n20200115\n20200114\n20200113\n20200112\n20200111\n20200110\n20200109\ntraining on 20200117\npreparing training data for  20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n20200111\n20200110\ntraining on 20200118\npreparing training data for  20200118\n20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n20200111\ntraining on 20200119\npreparing training data for  20200119\n20200118\n20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n",
  "history_begin_time" : 1695390559897,
  "history_end_time" : 1695390634634,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "pmK1AZyfTJlM",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=10, \n                       n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      \n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n    \n    label += 1\n    \n    if label % 30 == 0:\n      # save the model for every month\n      with open(model_path, 'wb') as model_file:\n        pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1694962506070,
  "history_end_time" : 1694969188078,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "b79MGDghyJw1",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=10, \n                       n_jobs = 16,\n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      \n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n    \n    label += 1\n    \n    if label % 30 == 0:\n      # save the model for every month\n  \t  with open(model_path, 'wb') as model_file:\n        pickle.dump(model, model_file)\n  \n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "  File \"fc_model_creation.py\", line 78\n    pickle.dump(model, model_file)\n                                 ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1694962354137,
  "history_end_time" : 1694962354216,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "NW4TCavFVJjF",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  print(\"check point 1\")\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  print(\"check point 2\")\n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=5, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  print(\"check point 3\")\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  print(\"check point 4\")\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "check point 1\ncheck point 2\ncheck point 3\ntraining on 20200116\npreparing training data for  20200116\n20200115\n20200114\n20200113\n20200112\n20200111\n20200110\n20200109\nNew time series dataframe:      LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\ntraining on 20200117\npreparing training data for  20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n20200111\n20200110\nNew time series dataframe:      LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\ntraining on 20200118\npreparing training data for  20200118\n20200117\n20200116\n20200115\n20200114\n20200113\n20200112\n20200111\nNew time series dataframe:      LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\ntraining on 20200119\npreparing training data for  20200119\n20200118\n20200117\n20200116\n20200115\n20200114\n20200113\n20200112\nNew time series dataframe:      LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\ncheck point 4\n",
  "history_begin_time" : 1694959959825,
  "history_end_time" : 1694960360823,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "dtxHhRApZkSA",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import  get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  print(\"check point 1\")\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  print(\"check point 2\")\n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=10, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  print(\"check point 3\")\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  print(\"check point 4\")\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1694959655789,
  "history_end_time" : 1694959909426,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "lzF4BPFvYfab",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=10, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200118\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1694959503738,
  "history_end_time" : 1694959530222,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "tUtuYc5qXoEE",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=10, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20200110\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1694959432027,
  "history_end_time" : 1694959462121,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "9WS9fnmZsG9d",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15_no_slurm.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=15, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20201231\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1694959110538,
  "history_end_time" : 1694959372621,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "14ZrBIx2il34",
  "history_input" : "\n# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_15.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100,\n                       max_depth=15, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20201231\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1694958219476,
  "history_end_time" : 1694959530126,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "PZOHATmWvkDO",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data, prepare_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020_maxdepth_30.pkl\"\n\n\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, \n                       max_depth=30, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20201231\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1694828236530,
  "history_end_time" : 1694897580937,
  "history_notes" : "weighted xgboost on 2020 yearly with depth 30",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "GLq53AQuTV50",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1_weighted_one_year_2020.pkl\"\n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  #print(\"target column is \", target_col)\n\n  #print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  #print(\"original dataframe shape: \", df.shape)\n  #print(\"df head:\", df.head())\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  #print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  #print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  #print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  #print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  #print(f\"Mean: {y.mean()}\")\n  #print(f\"Median: {y.median()}\")\n#   print(f\"Standard Deviation: {y.std()}\")\n#   print(f\"Minimum: {y.min()}\")\n#   print(f\"Maximum: {y.max()}\")\n#   print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, \n                       max_depth=5, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200115\"\nend_date_str = \"20201231\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "training on 20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\ntraining on 20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\ntraining on 20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\ntraining on 20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\ntraining on 20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\ntraining on 20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\ntraining on 20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\ntraining on 20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\ntraining on 20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\ntraining on 20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\ntraining on 20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\ntraining on 20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\ntraining on 20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\ntraining on 20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\ntraining on 20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\ntraining on 20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\ntraining on 20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\ntraining on 20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\ntraining on 20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\ntraining on 20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\ntraining on 20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\ntraining on 20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\ntraining on 20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\ntraining on 20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\ntraining on 20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\ntraining on 20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\ntraining on 20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\ntraining on 20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\ntraining on 20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\ntraining on 20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\ntraining on 20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\ntraining on 20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\ntraining on 20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\ntraining on 20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\ntraining on 20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\ntraining on 20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\ntraining on 20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\ntraining on 20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\ntraining on 20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\ntraining on 20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\ntraining on 20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\ntraining on 20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\ntraining on 20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\ntraining on 20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\ntraining on 20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\ntraining on 20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\ntraining on 20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\ntraining on 20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\ntraining on 20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\ntraining on 20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\ntraining on 20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\ntraining on 20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\ntraining on 20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\ntraining on 20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\ntraining on 20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\ntraining on 20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\ntraining on 20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\ntraining on 20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\ntraining on 20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\ntraining on 20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\ntraining on 20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\ntraining on 20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\ntraining on 20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\ntraining on 20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\ntraining on 20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\ntraining on 20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\ntraining on 20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\ntraining on 20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\ntraining on 20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\ntraining on 20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\ntraining on 20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\ntraining on 20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\ntraining on 20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\ntraining on 20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\ntraining on 20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\ntraining on 20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\ntraining on 20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\ntraining on 20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\ntraining on 20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\ntraining on 20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\ntraining on 20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\ntraining on 20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\ntraining on 20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\ntraining on 20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\ntraining on 20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\ntraining on 20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\ntraining on 20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\ntraining on 20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\ntraining on 20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\ntraining on 20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\ntraining on 20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\ntraining on 20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\ntraining on 20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\ntraining on 20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\ntraining on 20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\ntraining on 20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\ntraining on 20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\ntraining on 20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\ntraining on 20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\ntraining on 20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\ntraining on 20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\ntraining on 20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\ntraining on 20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\ntraining on 20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\ntraining on 20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\ntraining on 20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\ntraining on 20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\ntraining on 20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\ntraining on 20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\ntraining on 20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\ntraining on 20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\ntraining on 20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\ntraining on 20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\ntraining on 20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\ntraining on 20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\ntraining on 20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\ntraining on 20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\ntraining on 20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\ntraining on 20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\ntraining on 20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\ntraining on 20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\ntraining on 20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\ntraining on 20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\ntraining on 20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\ntraining on 20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\ntraining on 20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\ntraining on 20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\ntraining on 20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\ntraining on 20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\ntraining on 20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\ntraining on 20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\ntraining on 20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\ntraining on 20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\ntraining on 20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\ntraining on 20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\ntraining on 20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\ntraining on 20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\ntraining on 20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\ntraining on 20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\ntraining on 20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\ntraining on 20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\ntraining on 20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\ntraining on 20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\ntraining on 20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\ntraining on 20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\ntraining on 20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\ntraining on 20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\ntraining on 20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\ntraining on 20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\ntraining on 20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\ntraining on 20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\ntraining on 20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\ntraining on 20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\ntraining on 20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\ntraining on 20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\ntraining on 20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\ntraining on 20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\ntraining on 20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\ntraining on 20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\ntraining on 20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\ntraining on 20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\ntraining on 20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\ntraining on 20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\ntraining on 20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\ntraining on 20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\ntraining on 20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\ntraining on 20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\ntraining on 20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\ntraining on 20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\ntraining on 20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\ntraining on 20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\ntraining on 20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\ntraining on 20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\ntraining on 20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\ntraining on 20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\ntraining on 20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\ntraining on 20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\ntraining on 20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\ntraining on 20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\ntraining on 20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\ntraining on 20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\ntraining on 20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\ntraining on 20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\ntraining on 20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\ntraining on 20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\ntraining on 20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\ntraining on 20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\ntraining on 20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\ntraining on 20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\ntraining on 20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\ntraining on 20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\ntraining on 20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\ntraining on 20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\ntraining on 20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\ntraining on 20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\ntraining on 20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\ntraining on 20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\ntraining on 20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\ntraining on 20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\ntraining on 20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\ntraining on 20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\ntraining on 20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\ntraining on 20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\ntraining on 20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\ntraining on 20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\ntraining on 20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\ntraining on 20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\ntraining on 20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\ntraining on 20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\ntraining on 20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\ntraining on 20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\ntraining on 20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\ntraining on 20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\ntraining on 20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\ntraining on 20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\ntraining on 20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\ntraining on 20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\ntraining on 20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\ntraining on 20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\ntraining on 20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\ntraining on 20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\ntraining on 20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\ntraining on 20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\ntraining on 20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\ntraining on 20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\ntraining on 20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\ntraining on 20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\ntraining on 20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\ntraining on 20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ntraining on 20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\ntraining on 20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\ntraining on 20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\ntraining on 20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\ntraining on 20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\ntraining on 20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\ntraining on 20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\ntraining on 20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\ntraining on 20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\ntraining on 20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\ntraining on 20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\ntraining on 20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\ntraining on 20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\ntraining on 20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\ntraining on 20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\ntraining on 20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\ntraining on 20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\ntraining on 20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\ntraining on 20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\ntraining on 20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\ntraining on 20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\ntraining on 20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\ntraining on 20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\ntraining on 20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\ntraining on 20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\ntraining on 20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\ntraining on 20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\ntraining on 20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\ntraining on 20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\ntraining on 20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\ntraining on 20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\ntraining on 20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\ntraining on 20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\ntraining on 20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\ntraining on 20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\ntraining on 20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\ntraining on 20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\ntraining on 20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\ntraining on 20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\ntraining on 20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\ntraining on 20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\ntraining on 20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\ntraining on 20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\ntraining on 20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\ntraining on 20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\ntraining on 20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\ntraining on 20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\ntraining on 20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\ntraining on 20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\ntraining on 20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\ntraining on 20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\ntraining on 20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\ntraining on 20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\ntraining on 20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\ntraining on 20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\ntraining on 20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\ntraining on 20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\ntraining on 20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\ntraining on 20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\ntraining on 20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\ntraining on 20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\ntraining on 20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\ntraining on 20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\ntraining on 20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\ntraining on 20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\ntraining on 20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\ntraining on 20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\ntraining on 20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\ntraining on 20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\ntraining on 20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\ntraining on 20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\ntraining on 20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\ntraining on 20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\ntraining on 20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\ntraining on 20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\ntraining on 20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\ntraining on 20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\ntraining on 20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\ntraining on 20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\ntraining on 20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\ntraining on 20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\ntraining on 20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\ntraining on 20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\ntraining on 20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\ntraining on 20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\ntraining on 20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\ntraining on 20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\ntraining on 20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\ntraining on 20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\ntraining on 20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\ntraining on 20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\ntraining on 20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\ntraining on 20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\ntraining on 20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\ntraining on 20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\ntraining on 20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\ntraining on 20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\ntraining on 20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\ntraining on 20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\ntraining on 20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\ntraining on 20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\ntraining on 20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\ntraining on 20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\ntraining on 20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\ntraining on 20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\ntraining on 20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\ntraining on 20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\ntraining on 20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\ntraining on 20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\ntraining on 20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\ntraining on 20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\ntraining on 20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\ntraining on 20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\ntraining on 20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\ntraining on 20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\ntraining on 20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\ntraining on 20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\ntraining on 20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\ntraining on 20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\ntraining on 20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\ntraining on 20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\ntraining on 20201231\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201231.txt\n20201231\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201231.txt\n20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\ntraining on 20210101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210101.txt\n20210101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210101.txt\n20201231\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201231.txt\n20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n",
  "history_begin_time" : 1694209677791,
  "history_end_time" : 1694223744846,
  "history_notes" : "weighted xgboost on 2020 yearly, this model is not good, depth is too shallow",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "sJXkKOIoCIcX",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v3_weighted_one_month_202007.pkl\"\n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  #print(\"target column is \", target_col)\n\n  #print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  #print(\"original dataframe shape: \", df.shape)\n  #print(\"df head:\", df.head())\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  #print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  #print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  #print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  #print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  #print(f\"Mean: {y.mean()}\")\n  #print(f\"Median: {y.median()}\")\n#   print(f\"Standard Deviation: {y.std()}\")\n#   print(f\"Minimum: {y.min()}\")\n#   print(f\"Maximum: {y.max()}\")\n#   print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, \n                       max_depth=5, \n                       learning_rate=0.1,\n                       eval_metric=\"rmse\",\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200701\"\nend_date_str = \"20200731\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "training on 20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\ntraining on 20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\ntraining on 20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\ntraining on 20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\ntraining on 20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\ntraining on 20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\ntraining on 20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\ntraining on 20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\ntraining on 20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\ntraining on 20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\ntraining on 20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\ntraining on 20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\ntraining on 20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\ntraining on 20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\ntraining on 20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\ntraining on 20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\ntraining on 20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\ntraining on 20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\ntraining on 20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\ntraining on 20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\ntraining on 20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\ntraining on 20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\ntraining on 20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\ntraining on 20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\ntraining on 20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\ntraining on 20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\ntraining on 20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\ntraining on 20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\ntraining on 20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\ntraining on 20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\ntraining on 20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n",
  "history_begin_time" : 1694203893504,
  "history_end_time" : 1694204709674,
  "history_notes" : "weighted training july 2020 first time this is the best model so far",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "5Ti346ODirNE",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v3_weighted_one_month_202007.pkl\"\n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  #print(\"target column is \", target_col)\n\n  #print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  #print(\"original dataframe shape: \", df.shape)\n  #print(\"df head:\", df.head())\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  #print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  #print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  #print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  #print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  #print(f\"Mean: {y.mean()}\")\n  #print(f\"Median: {y.median()}\")\n#   print(f\"Standard Deviation: {y.std()}\")\n#   print(f\"Minimum: {y.min()}\")\n#   print(f\"Maximum: {y.max()}\")\n#   print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Introduce a threshold for target values\n  threshold = 100\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, \n                       max_depth=5, \n                       learning_rate=0.1,\n                       eval_metric=rmse,\n                       eta=0.1,\n                       subsample=0.8,\n                       colsample_bytree=0.8,\n                       min_child_weight=1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Define sample weights based on the threshold\n    sample_weights = np.where(y > threshold, 10.0, 1.0)  # Assign a weight of 2 to values > 100\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weights, test_size=0.2, random_state=42, shuffle=False)\n    \n    if label == 0:\n      model.fit(X_train, y_train, sample_weight=sw_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model, sample_weight=sw_train)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200701\"\nend_date_str = \"20200731\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"fc_model_creation.py\", line 128, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 92, in train_model\n    eval_metric=rmse,\nNameError: name 'rmse' is not defined\n",
  "history_begin_time" : 1694203850269,
  "history_end_time" : 1694203862458,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "bvFJWBFdcsjN",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v2_one_month_202007.pkl\"\n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  #print(\"target column is \", target_col)\n\n  #print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  #print(\"original dataframe shape: \", df.shape)\n  #print(\"df head:\", df.head())\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  #print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  #print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  #print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  #print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  #print(f\"Mean: {y.mean()}\")\n  #print(f\"Median: {y.median()}\")\n#   print(f\"Standard Deviation: {y.std()}\")\n#   print(f\"Minimum: {y.min()}\")\n#   print(f\"Maximum: {y.max()}\")\n#   print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    if label == 0:\n      model.fit(X_train, y_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200701\"\nend_date_str = \"20200731\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "training on 20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\ntraining on 20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\ntraining on 20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\ntraining on 20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\ntraining on 20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\ntraining on 20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\ntraining on 20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\ntraining on 20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\ntraining on 20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\ntraining on 20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\ntraining on 20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\ntraining on 20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\ntraining on 20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\ntraining on 20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\ntraining on 20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\ntraining on 20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\ntraining on 20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\ntraining on 20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\ntraining on 20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\ntraining on 20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\ntraining on 20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\ntraining on 20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\ntraining on 20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\ntraining on 20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\ntraining on 20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\ntraining on 20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\ntraining on 20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\ntraining on 20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\ntraining on 20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\ntraining on 20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\ntraining on 20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n",
  "history_begin_time" : 1693630131610,
  "history_end_time" : 1693630829362,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "2Ur6UA0IKrEu",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v2_one_year_2020.pkl\"\n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  #print(\"target column is \", target_col)\n\n  #print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  #print(\"original dataframe shape: \", df.shape)\n  #print(\"df head:\", df.head())\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  #print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  #print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  #print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  #print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  #print(f\"Mean: {y.mean()}\")\n  #print(f\"Median: {y.median()}\")\n#   print(f\"Standard Deviation: {y.std()}\")\n#   print(f\"Minimum: {y.min()}\")\n#   print(f\"Maximum: {y.max()}\")\n#   print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    print(f\"training on {date_str}\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    if label == 0:\n      model.fit(X_train, y_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200108\"\nend_date_str = \"20201231\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "training on 20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200108.txt\n20200107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200107.txt\n20200106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200106.txt\n20200105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200105.txt\n20200104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200104.txt\n20200103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200103.txt\ntraining on 20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200108.txt\n20200107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200107.txt\n20200106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200106.txt\n20200105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200105.txt\n20200104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200104.txt\ntraining on 20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200108.txt\n20200107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200107.txt\n20200106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200106.txt\n20200105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200105.txt\ntraining on 20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200108.txt\n20200107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200107.txt\n20200106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200106.txt\ntraining on 20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200108.txt\n20200107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200107.txt\ntraining on 20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\n20200108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200108.txt\ntraining on 20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\n20200109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200109.txt\ntraining on 20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\n20200110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200110.txt\ntraining on 20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\n20200111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200111.txt\ntraining on 20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\n20200112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200112.txt\ntraining on 20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\n20200113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200113.txt\ntraining on 20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\n20200114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200114.txt\ntraining on 20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\n20200115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200115.txt\ntraining on 20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\n20200116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200116.txt\ntraining on 20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\n20200117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200117.txt\ntraining on 20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\n20200118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200118.txt\ntraining on 20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\n20200119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200119.txt\ntraining on 20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\n20200120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200120.txt\ntraining on 20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\n20200121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200121.txt\ntraining on 20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\n20200122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200122.txt\ntraining on 20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\n20200123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200123.txt\ntraining on 20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\n20200124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200124.txt\ntraining on 20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\n20200125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200125.txt\ntraining on 20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\n20200126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200126.txt\ntraining on 20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\n20200127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200127.txt\ntraining on 20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\n20200128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200128.txt\ntraining on 20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\n20200129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200129.txt\ntraining on 20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\n20200130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200130.txt\ntraining on 20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\n20200131\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200131.txt\ntraining on 20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\n20200201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200201.txt\ntraining on 20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\n20200202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200202.txt\ntraining on 20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\n20200203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200203.txt\ntraining on 20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\n20200204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200204.txt\ntraining on 20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\n20200205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200205.txt\ntraining on 20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\n20200206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200206.txt\ntraining on 20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\n20200207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200207.txt\ntraining on 20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\n20200208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200208.txt\ntraining on 20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\n20200209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200209.txt\ntraining on 20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\n20200210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200210.txt\ntraining on 20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\n20200211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200211.txt\ntraining on 20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\n20200212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200212.txt\ntraining on 20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\n20200213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200213.txt\ntraining on 20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\n20200214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200214.txt\ntraining on 20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\n20200215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200215.txt\ntraining on 20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\n20200216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200216.txt\ntraining on 20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\n20200217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200217.txt\ntraining on 20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\n20200218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200218.txt\ntraining on 20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\n20200219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200219.txt\ntraining on 20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\n20200220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200220.txt\ntraining on 20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\n20200221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200221.txt\ntraining on 20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\n20200222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200222.txt\ntraining on 20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\n20200223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200223.txt\ntraining on 20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\n20200224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200224.txt\ntraining on 20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\n20200225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200225.txt\ntraining on 20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\n20200226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200226.txt\ntraining on 20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\n20200227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200227.txt\ntraining on 20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\n20200228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200228.txt\ntraining on 20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\n20200229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200229.txt\ntraining on 20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\n20200301\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200301.txt\ntraining on 20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\n20200302\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200302.txt\ntraining on 20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\n20200303\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200303.txt\ntraining on 20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\n20200304\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200304.txt\ntraining on 20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\n20200305\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200305.txt\ntraining on 20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\n20200306\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200306.txt\ntraining on 20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\n20200307\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200307.txt\ntraining on 20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\n20200308\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200308.txt\ntraining on 20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\n20200309\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200309.txt\ntraining on 20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\n20200310\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200310.txt\ntraining on 20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\n20200311\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200311.txt\ntraining on 20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\n20200312\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200312.txt\ntraining on 20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\n20200313\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200313.txt\ntraining on 20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\n20200314\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200314.txt\ntraining on 20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\n20200315\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200315.txt\ntraining on 20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\n20200316\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200316.txt\ntraining on 20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\n20200317\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200317.txt\ntraining on 20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\n20200318\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200318.txt\ntraining on 20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\n20200319\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200319.txt\ntraining on 20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\n20200320\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200320.txt\ntraining on 20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\n20200321\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200321.txt\ntraining on 20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\n20200322\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200322.txt\ntraining on 20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\n20200323\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200323.txt\ntraining on 20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\n20200324\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200324.txt\ntraining on 20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\n20200325\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200325.txt\ntraining on 20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\n20200326\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200326.txt\ntraining on 20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\n20200327\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200327.txt\ntraining on 20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\n20200328\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200328.txt\ntraining on 20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\n20200329\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200329.txt\ntraining on 20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\n20200330\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200330.txt\ntraining on 20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\n20200331\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200331.txt\ntraining on 20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\n20200401\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200401.txt\ntraining on 20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\n20200402\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200402.txt\ntraining on 20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\n20200403\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200403.txt\ntraining on 20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\n20200404\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200404.txt\ntraining on 20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\n20200405\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200405.txt\ntraining on 20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\n20200406\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200406.txt\ntraining on 20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\n20200407\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200407.txt\ntraining on 20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\n20200408\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200408.txt\ntraining on 20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\n20200409\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200409.txt\ntraining on 20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\n20200410\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200410.txt\ntraining on 20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\n20200411\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200411.txt\ntraining on 20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\n20200412\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200412.txt\ntraining on 20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\n20200413\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200413.txt\ntraining on 20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\n20200414\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200414.txt\ntraining on 20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\n20200415\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200415.txt\ntraining on 20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\n20200416\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200416.txt\ntraining on 20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\n20200417\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200417.txt\ntraining on 20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\n20200418\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200418.txt\ntraining on 20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\n20200419\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200419.txt\ntraining on 20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\n20200420\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200420.txt\ntraining on 20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\n20200421\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200421.txt\ntraining on 20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\n20200422\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200422.txt\ntraining on 20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\n20200423\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200423.txt\ntraining on 20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\n20200424\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200424.txt\ntraining on 20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\n20200425\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200425.txt\ntraining on 20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\n20200426\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200426.txt\ntraining on 20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\n20200427\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200427.txt\ntraining on 20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\n20200428\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200428.txt\ntraining on 20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\n20200429\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200429.txt\ntraining on 20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\n20200430\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200430.txt\ntraining on 20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\n20200501\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200501.txt\ntraining on 20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\n20200502\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200502.txt\ntraining on 20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\n20200503\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200503.txt\ntraining on 20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\n20200504\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200504.txt\ntraining on 20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\n20200505\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200505.txt\ntraining on 20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\n20200506\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200506.txt\ntraining on 20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\n20200507\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200507.txt\ntraining on 20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\n20200508\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200508.txt\ntraining on 20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\n20200509\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200509.txt\ntraining on 20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\n20200510\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200510.txt\ntraining on 20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\n20200511\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200511.txt\ntraining on 20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\n20200512\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200512.txt\ntraining on 20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\n20200513\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200513.txt\ntraining on 20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\n20200514\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200514.txt\ntraining on 20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\n20200515\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200515.txt\ntraining on 20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\n20200516\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200516.txt\ntraining on 20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\n20200517\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200517.txt\ntraining on 20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\n20200518\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200518.txt\ntraining on 20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\n20200519\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200519.txt\ntraining on 20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\n20200520\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200520.txt\ntraining on 20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\n20200521\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200521.txt\ntraining on 20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\n20200522\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200522.txt\ntraining on 20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\n20200523\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200523.txt\ntraining on 20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\n20200524\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200524.txt\ntraining on 20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\n20200525\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200525.txt\ntraining on 20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\n20200526\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200526.txt\ntraining on 20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\n20200527\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200527.txt\ntraining on 20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\n20200528\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200528.txt\ntraining on 20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\n20200529\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200529.txt\ntraining on 20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\n20200530\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200530.txt\ntraining on 20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\n20200531\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200531.txt\ntraining on 20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\n20200601\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200601.txt\ntraining on 20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\n20200602\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200602.txt\ntraining on 20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\n20200603\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200603.txt\ntraining on 20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\n20200604\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200604.txt\ntraining on 20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\n20200605\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200605.txt\ntraining on 20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\n20200606\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200606.txt\ntraining on 20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\n20200607\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200607.txt\ntraining on 20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\n20200608\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200608.txt\ntraining on 20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\n20200609\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200609.txt\ntraining on 20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\n20200610\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200610.txt\ntraining on 20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\n20200611\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200611.txt\ntraining on 20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\n20200612\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200612.txt\ntraining on 20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\n20200613\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200613.txt\ntraining on 20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\n20200614\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200614.txt\ntraining on 20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\n20200615\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200615.txt\ntraining on 20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\n20200616\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200616.txt\ntraining on 20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\n20200617\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200617.txt\ntraining on 20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\n20200618\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200618.txt\ntraining on 20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\n20200619\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200619.txt\ntraining on 20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\n20200620\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200620.txt\ntraining on 20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\n20200621\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200621.txt\ntraining on 20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\n20200622\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200622.txt\ntraining on 20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\n20200623\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200623.txt\ntraining on 20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\n20200624\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200624.txt\ntraining on 20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\n20200625\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200625.txt\ntraining on 20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\n20200626\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200626.txt\ntraining on 20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\n20200627\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200627.txt\ntraining on 20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\n20200628\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200628.txt\ntraining on 20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\n20200629\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200629.txt\ntraining on 20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\n20200630\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200630.txt\ntraining on 20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\n20200701\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200701.txt\ntraining on 20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\n20200702\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200702.txt\ntraining on 20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\n20200703\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200703.txt\ntraining on 20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\n20200704\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200704.txt\ntraining on 20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\n20200705\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200705.txt\ntraining on 20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\n20200706\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200706.txt\ntraining on 20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\n20200707\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200707.txt\ntraining on 20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\n20200708\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200708.txt\ntraining on 20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\n20200709\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200709.txt\ntraining on 20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\n20200710\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200710.txt\ntraining on 20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\n20200711\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200711.txt\ntraining on 20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\n20200712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200712.txt\ntraining on 20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\n20200713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200713.txt\ntraining on 20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\n20200714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200714.txt\ntraining on 20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\n20200715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200715.txt\ntraining on 20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\n20200716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200716.txt\ntraining on 20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\n20200717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200717.txt\ntraining on 20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\n20200718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200718.txt\ntraining on 20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\n20200719\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200719.txt\ntraining on 20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\n20200720\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200720.txt\ntraining on 20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\n20200721\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200721.txt\ntraining on 20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\n20200722\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200722.txt\ntraining on 20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\n20200723\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200723.txt\ntraining on 20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\n20200724\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200724.txt\ntraining on 20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\n20200725\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200725.txt\ntraining on 20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\n20200726\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200726.txt\ntraining on 20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\ntraining on 20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\ntraining on 20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\ntraining on 20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\ntraining on 20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\ntraining on 20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\ntraining on 20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\ntraining on 20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\ntraining on 20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\ntraining on 20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\ntraining on 20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\ntraining on 20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\ntraining on 20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\ntraining on 20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\ntraining on 20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\ntraining on 20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\ntraining on 20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\ntraining on 20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\ntraining on 20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\ntraining on 20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\ntraining on 20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\ntraining on 20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\ntraining on 20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\ntraining on 20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\ntraining on 20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\ntraining on 20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\ntraining on 20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\ntraining on 20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\ntraining on 20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\ntraining on 20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ntraining on 20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\ntraining on 20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\ntraining on 20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\ntraining on 20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\ntraining on 20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\ntraining on 20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\ntraining on 20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\ntraining on 20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\n20200902\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200902.txt\ntraining on 20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\n20200903\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200903.txt\ntraining on 20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\n20200904\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200904.txt\ntraining on 20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\n20200905\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200905.txt\ntraining on 20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\n20200906\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200906.txt\ntraining on 20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\n20200907\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200907.txt\ntraining on 20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\n20200908\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200908.txt\ntraining on 20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\n20200909\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200909.txt\ntraining on 20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\n20200910\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200910.txt\ntraining on 20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\n20200911\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200911.txt\ntraining on 20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\n20200912\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200912.txt\ntraining on 20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\n20200913\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200913.txt\ntraining on 20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\n20200914\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200914.txt\ntraining on 20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\n20200915\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200915.txt\ntraining on 20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\n20200916\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200916.txt\ntraining on 20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\n20200917\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200917.txt\ntraining on 20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\n20200918\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200918.txt\ntraining on 20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\n20200919\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200919.txt\ntraining on 20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\n20200920\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200920.txt\ntraining on 20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\n20200921\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200921.txt\ntraining on 20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\n20200922\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200922.txt\ntraining on 20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\n20200923\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200923.txt\ntraining on 20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\n20200924\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200924.txt\ntraining on 20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\n20200925\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200925.txt\ntraining on 20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\n20200926\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200926.txt\ntraining on 20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\n20200927\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200927.txt\ntraining on 20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\n20200928\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200928.txt\ntraining on 20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\n20200929\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200929.txt\ntraining on 20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\n20200930\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200930.txt\ntraining on 20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\n20201001\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201001.txt\ntraining on 20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\n20201002\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201002.txt\ntraining on 20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\n20201003\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201003.txt\ntraining on 20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\n20201004\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201004.txt\ntraining on 20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\n20201005\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201005.txt\ntraining on 20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\n20201006\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201006.txt\ntraining on 20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\n20201007\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201007.txt\ntraining on 20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\n20201008\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201008.txt\ntraining on 20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\n20201009\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201009.txt\ntraining on 20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\n20201010\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201010.txt\ntraining on 20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\n20201011\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201011.txt\ntraining on 20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\n20201012\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201012.txt\ntraining on 20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\n20201013\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201013.txt\ntraining on 20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\n20201014\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201014.txt\ntraining on 20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\n20201015\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201015.txt\ntraining on 20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\n20201016\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201016.txt\ntraining on 20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\n20201017\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201017.txt\ntraining on 20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\n20201018\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201018.txt\ntraining on 20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\n20201019\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201019.txt\ntraining on 20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\n20201020\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201020.txt\ntraining on 20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\n20201021\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201021.txt\ntraining on 20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\n20201022\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201022.txt\ntraining on 20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\n20201023\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201023.txt\ntraining on 20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\n20201024\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201024.txt\ntraining on 20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\n20201025\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201025.txt\ntraining on 20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\n20201026\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201026.txt\ntraining on 20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\n20201027\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201027.txt\ntraining on 20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\n20201028\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201028.txt\ntraining on 20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\n20201029\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201029.txt\ntraining on 20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\n20201030\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201030.txt\ntraining on 20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\n20201031\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201031.txt\ntraining on 20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\n20201101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201101.txt\ntraining on 20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\n20201102\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201102.txt\ntraining on 20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\n20201103\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201103.txt\ntraining on 20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\n20201104\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201104.txt\ntraining on 20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\n20201105\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201105.txt\ntraining on 20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\n20201106\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201106.txt\ntraining on 20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\n20201107\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201107.txt\ntraining on 20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\n20201108\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201108.txt\ntraining on 20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\n20201109\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201109.txt\ntraining on 20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\n20201110\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201110.txt\ntraining on 20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\n20201111\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201111.txt\ntraining on 20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\n20201112\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201112.txt\ntraining on 20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\n20201113\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201113.txt\ntraining on 20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\n20201114\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201114.txt\ntraining on 20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\n20201115\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201115.txt\ntraining on 20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\n20201116\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201116.txt\ntraining on 20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\n20201117\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201117.txt\ntraining on 20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\n20201118\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201118.txt\ntraining on 20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\n20201119\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201119.txt\ntraining on 20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\n20201120\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201120.txt\ntraining on 20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\n20201121\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201121.txt\ntraining on 20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\n20201122\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201122.txt\ntraining on 20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\n20201123\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201123.txt\ntraining on 20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\n20201124\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201124.txt\ntraining on 20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\n20201125\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201125.txt\ntraining on 20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\n20201126\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201126.txt\ntraining on 20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\n20201127\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201127.txt\ntraining on 20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\n20201128\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201128.txt\ntraining on 20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\n20201129\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201129.txt\ntraining on 20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\n20201130\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201130.txt\ntraining on 20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\n20201201\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201201.txt\ntraining on 20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\n20201202\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201202.txt\ntraining on 20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\n20201203\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201203.txt\ntraining on 20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\n20201204\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201204.txt\ntraining on 20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\n20201205\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201205.txt\ntraining on 20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\n20201206\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201206.txt\ntraining on 20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n20201207\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201207.txt\ntraining on 20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\n20201208\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\ntraining on 20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\n20201209\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201209.txt\ntraining on 20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\n20201210\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201210.txt\ntraining on 20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\n20201211\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201211.txt\ntraining on 20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\n20201212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201212.txt\ntraining on 20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\n20201213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201213.txt\ntraining on 20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\n20201214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201214.txt\ntraining on 20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\n20201215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201215.txt\ntraining on 20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\n20201216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201216.txt\ntraining on 20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\n20201217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201217.txt\ntraining on 20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\n20201218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201218.txt\ntraining on 20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\n20201219\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201219.txt\ntraining on 20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\n20201220\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201220.txt\ntraining on 20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\n20201221\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201221.txt\ntraining on 20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\n20201222\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201222.txt\ntraining on 20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\n20201223\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201223.txt\ntraining on 20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\n20201224\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201224.txt\ntraining on 20201231\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201231.txt\n20201231\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201231.txt\n20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n20201225\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201225.txt\ntraining on 20210101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210101.txt\n20210101\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210101.txt\n20201231\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201231.txt\n20201230\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201230.txt\n20201229\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201229.txt\n20201228\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201228.txt\n20201227\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201227.txt\n20201226\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201226.txt\n",
  "history_begin_time" : 1693603547357,
  "history_end_time" : 1693615499889,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "kMK3GbYs6GTO",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v2_one_year_2020.pkl\"\n\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    if label == 0:\n      model.fit(X_train, y_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200108\"\nend_date_str = \"20201231\"\n#train_model(start_date_str, end_date_str)\n      \n\n# # Load the saved model\n# with open(model_path, 'rb') as model_file:\n#     loaded_model = pickle.load(model_file)\n\n\n# test_date_str = \"20200901\"\n# X, y = prepare_training_data(test_date_str)\n# # Make predictions\n# y_pred = loaded_model.predict(X)\n# y_pred[y_pred < 0] = 0\n\n# print(\"y_pred : \", y_pred)\n\n# # merge the input and output into one df\n# print(\"X_test shape: \", X.shape)\n# y_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\n# print(\"y_pred_df shape: \", y_pred_df.shape)\n# print(\"y_pred_df head: \", y_pred_df.head())\n\n# #merged_df = X.join(y_pred_df)\n# #merged_df = pd.concat([X, y_pred_df], axis=1)\n# merged_df = X\n# merged_df[\"Predicted_FRP\"] = y_pred\n\n# print(\"merged_df shape: \", merged_df.shape)\n# print(\"the final merged df is: \", merged_df.head())\n\n\n\n# # Calculate metrics\n# y_test = y\n# mae = mean_absolute_error(y_test, y_pred)\n# mse = mean_squared_error(y_test, y_pred)\n# rmse = mean_squared_error(y_test, y_pred, squared=False)\n# r2 = r2_score(y_test, y_pred)\n# explained_var = explained_variance_score(y_test, y_pred)\n# msle = mean_squared_log_error(y_test, y_pred)\n# medae = median_absolute_error(y_test, y_pred)\n# max_err = max_error(y_test, y_pred)\n\n# # Print the metrics\n# print(f\"Mean Absolute Error (MAE): {mae}\")\n# print(f\"Mean Squared Error (MSE): {mse}\")\n# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n# print(f\"R-squared (R2) Score: {r2}\")\n# print(f\"Explained Variance Score: {explained_var}\")\n# print(f\"Mean Squared Log Error (MSLE): {msle}\")\n# print(f\"Median Absolute Error (MedAE): {medae}\")\n# print(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "",
  "history_begin_time" : 1693603384507,
  "history_end_time" : 1693603387371,
  "history_notes" : "one year training",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "b8GjVtMHH1kg",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  label = 0\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    if label == 0:\n      model.fit(X_train, y_train)\n      label = 1\n    else:\n      model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200801\"\nend_date_str = \"20200831\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"20200901\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03533253377831329\nMedian: 0.0\nStandard Deviation: 5.001435622347957\nMinimum: 0.0\nMaximum: 1444.431152\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.022544933680137203\nMedian: 0.0\nStandard Deviation: 1.5951113321164974\nMinimum: 0.0\nMaximum: 347.888428\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.039940102868144395\nMedian: 0.0\nStandard Deviation: 4.108068973454069\nMinimum: 0.0\nMaximum: 915.541687\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.02423764787933266\nMedian: 0.0\nStandard Deviation: 2.2273558170808725\nMinimum: 0.0\nMaximum: 597.731689\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.02334024906127079\nMedian: 0.0\nStandard Deviation: 1.6719107056725073\nMinimum: 0.0\nMaximum: 400.929138\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03531522947705293\nMedian: 0.0\nStandard Deviation: 4.8624039265614565\nMinimum: 0.0\nMaximum: 1350.101196\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.02300005454510682\nMedian: 0.0\nStandard Deviation: 2.097558730070113\nMinimum: 0.0\nMaximum: 415.325684\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\n20200803\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200803.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.018297085113571893\nMedian: 0.0\nStandard Deviation: 2.3039239946139074\nMinimum: 0.0\nMaximum: 622.261414\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\n20200804\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200804.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.02899671977738252\nMedian: 0.0\nStandard Deviation: 3.506417825227414\nMinimum: 0.0\nMaximum: 1218.387695\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\n20200805\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200805.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03492281980862036\nMedian: 0.0\nStandard Deviation: 3.8934602756445496\nMinimum: 0.0\nMaximum: 864.288452\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\n20200806\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200806.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.028137244330968182\nMedian: 0.0\nStandard Deviation: 3.7695721628322545\nMinimum: 0.0\nMaximum: 953.560852\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\n20200807\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200807.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.036501024480272336\nMedian: 0.0\nStandard Deviation: 3.919910102308357\nMinimum: 0.0\nMaximum: 964.2453\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\n20200808\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200808.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.04471167255723221\nMedian: 0.0\nStandard Deviation: 4.920418894596109\nMinimum: 0.0\nMaximum: 1130.158691\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\n20200809\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200809.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.0630194331414437\nMedian: 0.0\nStandard Deviation: 8.82880556550971\nMinimum: 0.0\nMaximum: 3105.80957\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\n20200810\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200810.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.08531473363041162\nMedian: 0.0\nStandard Deviation: 8.0962047270988\nMinimum: 0.0\nMaximum: 2333.725586\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\n20200811\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200811.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.06103562084265685\nMedian: 0.0\nStandard Deviation: 4.709315937404089\nMinimum: 0.0\nMaximum: 1144.665649\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\n20200812\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200812.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.0995423980913038\nMedian: 0.0\nStandard Deviation: 6.710609323419244\nMinimum: 0.0\nMaximum: 1609.110718\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\n20200813\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200813.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.4485391714575324\nMedian: 0.0\nStandard Deviation: 28.616510784925392\nMinimum: 0.0\nMaximum: 5089.8125\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\n20200814\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200814.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.2554723482956249\nMedian: 0.0\nStandard Deviation: 14.743279322330583\nMinimum: 0.0\nMaximum: 2923.033691\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\n20200815\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200815.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.1413884706459862\nMedian: 0.0\nStandard Deviation: 8.345563833805095\nMinimum: 0.0\nMaximum: 1685.769897\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\n20200816\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200816.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.09757328884808843\nMedian: 0.0\nStandard Deviation: 6.240220740211191\nMinimum: 0.0\nMaximum: 1350.516235\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\n20200817\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200817.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.11889789131141593\nMedian: 0.0\nStandard Deviation: 8.777749767671489\nMinimum: 0.0\nMaximum: 1782.675415\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\n20200818\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200818.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.10435461272081649\nMedian: 0.0\nStandard Deviation: 10.104240154667304\nMinimum: 0.0\nMaximum: 3329.859863\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\n20200819\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200819.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.05188678857077285\nMedian: 0.0\nStandard Deviation: 4.028409250819509\nMinimum: 0.0\nMaximum: 1185.154785\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\n20200820\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200820.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03053791145663993\nMedian: 0.0\nStandard Deviation: 1.8012685442533103\nMinimum: 0.0\nMaximum: 324.255859\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\n20200821\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200821.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.044297021439363496\nMedian: 0.0\nStandard Deviation: 2.7230431217632898\nMinimum: 0.0\nMaximum: 416.81958\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\n20200822\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200822.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.04088418667482673\nMedian: 0.0\nStandard Deviation: 2.682222605595241\nMinimum: 0.0\nMaximum: 424.124695\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\n20200823\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200823.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.05412846362703285\nMedian: 0.0\nStandard Deviation: 4.6594372211743345\nMinimum: 0.0\nMaximum: 1032.230225\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\n20200824\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200824.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.034954487788551626\nMedian: 0.0\nStandard Deviation: 2.8787336470006166\nMinimum: 0.0\nMaximum: 546.808228\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03682909143764224\nMedian: 0.0\nStandard Deviation: 3.227510322570268\nMinimum: 0.0\nMaximum: 731.856323\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.0660691098169717\nMedian: 0.0\nStandard Deviation: 6.099316187769047\nMinimum: 0.0\nMaximum: 1712.544189\nCount: 156861\ntarget column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200901\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200901.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.0660691098169717\nMedian: 0.0\nStandard Deviation: 6.099316187769047\nMinimum: 0.0\nMaximum: 1712.544189\nCount: 156861\ny_pred :  [3.8357502e-05 3.8357502e-05 3.8357502e-05 ... 3.8357502e-05 3.8357502e-05\n 3.8357502e-05]\nX_test shape:  (156861, 21)\ny_pred_df shape:  (156861, 1)\ny_pred_df head:     Predicted_FRP\n0       0.000038\n1       0.000038\n2       0.000038\n3       0.000038\n4       0.000038\nmerged_df shape:  (156861, 22)\nthe final merged df is:      LAT         LON    FWI  ...   FRP_day5   FRP_day6  Predicted_FRP\n0  24.5 -126.000000 -999.0  ...        0.0        0.0       0.000038\n1  24.5 -125.899994 -999.0  ...        0.0        0.0       0.000038\n2  24.5 -125.800003 -999.0  ...        0.0        0.0       0.000038\n3  24.5 -125.699997 -999.0  ...        0.0        0.0       0.000038\n4  24.5 -125.599998 -999.0  ...        0.0        0.0       0.000038\n[5 rows x 22 columns]\nMean Absolute Error (MAE): 0.013359157486141526\nMean Squared Error (MSE): 11.94979451349453\nRoot Mean Squared Error (RMSE): 3.4568474819544077\nR-squared (R2) Score: 0.6787812331330938\nExplained Variance Score: 0.6787842344201083\nMean Squared Log Error (MSLE): 0.0009845978097196442\nMedian Absolute Error (MedAE): 3.83575024898164e-05\nMax Error: 1366.0460201874998\n",
  "history_begin_time" : 1693601415881,
  "history_end_time" : 1693602251672,
  "history_notes" : "old approach, look away",
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "1p14WQ2N2SDI",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror')\n                       #scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    \n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200801\"\nend_date_str = \"20200831\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"20200901\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03533253377831329\nMedian: 0.0\nStandard Deviation: 5.001435622347957\nMinimum: 0.0\nMaximum: 1444.431152\nCount: 156861\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 112, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 102, in train_model\n    model.fit(X_train, y_train, xgb_model=model)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 532, in inner_f\n    return f(**kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 958, in fit\n    model, metric, params, early_stopping_rounds, callbacks = self._configure_fit(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 788, in _configure_fit\n    model: Optional[Union[Booster, str]] = booster.get_booster()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 590, in get_booster\n    raise NotFittedError('need to call fit or load_model beforehand')\nsklearn.exceptions.NotFittedError: need to call fit or load_model beforehand\n",
  "history_begin_time" : 1693601348655,
  "history_end_time" : 1693601353627,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "Y0oSm2vndJtv",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n  \n  # Initialize and train a model (e.g., Linear Regression)\n  model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror',\n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    \n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200801\"\nend_date_str = \"20200831\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"20200901\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"fc_model_creation.py\", line 112, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 89, in train_model\n    scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\nUnboundLocalError: local variable 'y_train' referenced before assignment\n",
  "history_begin_time" : 1693601326316,
  "history_end_time" : 1693601330845,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "rhI3pCBOLMo9",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y%m%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Initialize and train a model (e.g., Linear Regression)\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror', \n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"20200801\"\nend_date_str = \"20200831\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"20200901\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200802\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200802.txt\n20200801\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200801.txt\n20200731\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200731.txt\n20200730\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200730.txt\n20200729\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200729.txt\n20200728\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200728.txt\n20200727\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200727.txt\noriginal dataframe shape:  (156861, 22)\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 22)\nDF shape 1:  (156861, 22)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1',\n       ' FRP_day2', ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.03533253377831329\nMedian: 0.0\nStandard Deviation: 5.001435622347957\nMinimum: 0.0\nMaximum: 1444.431152\nCount: 156861\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 110, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 100, in train_model\n    model.fit(X_train, y_train, xgb_model=model)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 532, in inner_f\n    return f(**kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 958, in fit\n    model, metric, params, early_stopping_rounds, callbacks = self._configure_fit(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 788, in _configure_fit\n    model: Optional[Union[Booster, str]] = booster.get_booster()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 590, in get_booster\n    raise NotFittedError('need to call fit or load_model beforehand')\nsklearn.exceptions.NotFittedError: need to call fit or load_model beforehand\n",
  "history_begin_time" : 1693601231859,
  "history_end_time" : 1693601243009,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "ha75q5CEVGAS",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data(target_date)\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y-%m-%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Initialize and train a model (e.g., Linear Regression)\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror', \n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"2020-08-01\"\nend_date_str = \"2020-08-31\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"2020-09-01\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_2020-08-02.txt\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 110, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 92, in train_model\n    X, y = prepare_training_data(date_str)\n  File \"fc_model_creation.py\", line 34, in prepare_training_data\n    original_df = get_one_day_time_series_training_data(target_date)\n  File \"/home/zsun/gw-workspace/ha75q5CEVGAS/fc_train_data_preprocess.py\", line 47, in get_one_day_time_series_training_data\n    df = read_original_txt_files(target_day)\n  File \"/home/zsun/gw-workspace/ha75q5CEVGAS/fc_train_data_preprocess.py\", line 29, in read_original_txt_files\n    file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 575, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n    self.handles = get_handle(  # type: ignore[call-overload]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\", line 789, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/groups/ESS3/yli74/data/AI_Emis/firedata/firedata_2020-08-02.txt'\n",
  "history_begin_time" : 1693601200666,
  "history_end_time" : 1693601204789,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "jeXuWjEmbJKX",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data()\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y-%m-%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Initialize and train a model (e.g., Linear Regression)\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror', \n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"2020-08-01\"\nend_date_str = \"2020-08-31\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"2020-09-01\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 110, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 92, in train_model\n    X, y = prepare_training_data(date_str)\n  File \"fc_model_creation.py\", line 34, in prepare_training_data\n    original_df = get_one_day_time_series_training_data()\nTypeError: get_one_day_time_series_training_data() missing 1 required positional argument: 'target_day'\n",
  "history_begin_time" : 1693601158192,
  "history_end_time" : 1693601160432,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "X5Qt6dKJ2US3",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\nfrom datetime import datetime\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data()\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y-%m-%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Initialize and train a model (e.g., Linear Regression)\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror', \n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"2020-08-01\"\nend_date_str = \"2020-08-31\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"2020-09-01\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"fc_model_creation.py\", line 110, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 90, in train_model\n    current_date += timedelta(days=1)\nNameError: name 'timedelta' is not defined\n",
  "history_begin_time" : 1693601133194,
  "history_end_time" : 1693601135474,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "UW465y9HCqBR",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data()\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y-%m-%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Initialize and train a model (e.g., Linear Regression)\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror', \n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n    model.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"2020-08-01\"\nend_date_str = \"2020-08-31\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"2020-09-01\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"fc_model_creation.py\", line 109, in <module>\n    train_model(start_date_str, end_date_str)\n  File \"fc_model_creation.py\", line 79, in train_model\n    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\nNameError: name 'datetime' is not defined\n",
  "history_begin_time" : 1693601110256,
  "history_end_time" : 1693601113461,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "m7jxSasxja09",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nimport pickle\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n# final model path\nmodel_path = \"/groups/ESS3/zsun/firecasting/model/fc_xgb_model_v1.pkl\"\n\ntarget_date = \"20200831\"\n\ndef prepare_training_data(target_date):\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  print(\"target column is \", target_col)\n\n  print(\"reading the original txt files\")\n  #df = read_original_txt_files(\"20210718\")\n  original_df = get_one_day_time_series_training_data()\n  df = original_df\n  print(\"original dataframe shape: \", df.shape)\n  print(\"df head:\", df.head())\n\n  print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n  #for i in range(1, num_previous_days + 1):\n  #    for col in df.columns:\n  #        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n  # remove terrain temporarily\n  #df = original_df.drop(' HT', axis=1)\n  print(\"DF shape 0: \", df.shape)\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  #df.dropna(inplace=True)\n  print(\"DF shape 1: \", df.shape)\n\n  # remove all rows with -999 in any column\n  #df = df[~(df == -999).any(axis=1)]\n  #print(\"DF shape 2: \", df.shape)\n\n  # remove all rows with FRP == 0\n  #df = df[df[target_col] != 0]\n  #print(\"DF shape 3: \", df.shape)\n\n  # Define features and target\n  print(\"current all columns: \", df.columns)\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n\n  print(\"do some quick stats on FRP column\")\n  # Print the statistics\n  print(f\"Mean: {y.mean()}\")\n  print(f\"Median: {y.median()}\")\n  print(f\"Standard Deviation: {y.std()}\")\n  print(f\"Minimum: {y.min()}\")\n  print(f\"Maximum: {y.max()}\")\n  print(f\"Count: {y.count()}\")\n  return X, y\n\ndef train_model(start_date, end_date):\n  # start date and end date define the training period\n  # Convert the date strings to datetime objects\n  start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n  end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n\n  # Initialize a list to store the dates\n  dates_between = []\n\n  # Iterate through the days between start and end dates\n  current_date = start_date\n  while current_date <= end_date:\n    dates_between.append(current_date)\n    current_date += timedelta(days=1)\n    date_str = current_date.strftime(\"%Y-%m-%d\")\n    X, y = prepare_training_data(date_str)\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Initialize and train a model (e.g., Linear Regression)\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,\n                       objective='reg:squarederror', \n                       scale_pos_weight=abs((len(y_train) - y_train.sum()) / y_train.sum()))\n  \tmodel.fit(X_train, y_train, xgb_model=model)\n\n  # Save the model to a file\n  with open(model_path, 'wb') as model_file:\n      pickle.dump(model, model_file)\n\n      \n# Define your start and end dates as strings\nstart_date_str = \"2020-08-01\"\nend_date_str = \"2020-08-31\"\ntrain_model(start_date_str, end_date_str)\n      \n\n# Load the saved model\nwith open(model_path, 'rb') as model_file:\n    loaded_model = pickle.load(model_file)\n\n\ntest_date_str = \"2020-09-01\"\nX, y = prepare_training_data(test_date_str)\n# Make predictions\ny_pred = loaded_model.predict(X)\ny_pred[y_pred < 0] = 0\n\nprint(\"y_pred : \", y_pred)\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X.shape)\ny_pred_df = pd.DataFrame(y_pred, columns=[\"Predicted_FRP\"])\n\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nprint(\"y_pred_df head: \", y_pred_df.head())\n\n#merged_df = X.join(y_pred_df)\n#merged_df = pd.concat([X, y_pred_df], axis=1)\nmerged_df = X\nmerged_df[\"Predicted_FRP\"] = y_pred\n\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n\n\n# Calculate metrics\ny_test = y\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "  File \"fc_model_creation.py\", line 99\n    model.fit(X_train, y_train, xgb_model=model)\n                                               ^\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1693601077211,
  "history_end_time" : 1693601077285,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "VG9xEBXEwoyx",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X_test.shape)\ny_pred_df = pd.DataFrame(y_pred)\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nmerged_df = X_test.join(y_pred_df)\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nX_test shape:  (28, 20)\ny_pred_df shape:  (28, 1)\nmerged_df shape:  (28, 21)\nthe final merged df is:               LAT         LON        FWI  ...   FRP_day5   FRP_day6   0\n94388  40.199997 -122.899994  50.840454  ...        0.0        0.0 NaN\n96914  40.600006 -110.699997  43.610882  ...        0.0        0.0 NaN\n96915  40.600006 -110.599998  45.627563  ...        0.0        0.0 NaN\n97125  40.600006  -89.599998  31.058390  ...        0.0        0.0 NaN\n97515  40.699997 -110.699997  49.625000  ...        0.0        0.0 NaN\n[5 rows x 21 columns]\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693597974393,
  "history_end_time" : 1693597990145,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Nd09ErX9TFH7",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X_test.shape)\ny_pred_df = pd.DataFrame(y_pred)\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nmerged_df = pd.concat([X_test, y_pred_df], axis=1)\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nX_test shape:  (28, 20)\ny_pred_df shape:  (28, 1)\nmerged_df shape:  (56, 21)\nthe final merged df is:               LAT         LON        FWI  ...   FRP_day5   FRP_day6   0\n94388  40.199997 -122.899994  50.840454  ...        0.0        0.0 NaN\n96914  40.600006 -110.699997  43.610882  ...        0.0        0.0 NaN\n96915  40.600006 -110.599998  45.627563  ...        0.0        0.0 NaN\n97125  40.600006  -89.599998  31.058390  ...        0.0        0.0 NaN\n97515  40.699997 -110.699997  49.625000  ...        0.0        0.0 NaN\n[5 rows x 21 columns]\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693597848042,
  "history_end_time" : 1693597858371,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "SRhx7WMx7Ort",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X_test.shape)\ny_pred_df = pd.DataFrame(y_pred)\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nmerged_df = pd.concat([X_test, y_pred_df], axis=0)\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nX_test shape:  (28, 20)\ny_pred_df shape:  (28, 1)\nmerged_df shape:  (56, 21)\nthe final merged df is:               LAT         LON        FWI  ...   FRP_day5   FRP_day6   0\n94388  40.199997 -122.899994  50.840454  ...        0.0        0.0 NaN\n96914  40.600006 -110.699997  43.610882  ...        0.0        0.0 NaN\n96915  40.600006 -110.599998  45.627563  ...        0.0        0.0 NaN\n97125  40.600006  -89.599998  31.058390  ...        0.0        0.0 NaN\n97515  40.699997 -110.699997  49.625000  ...        0.0        0.0 NaN\n[5 rows x 21 columns]\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693597765698,
  "history_end_time" : 1693597776569,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "gvSoi3i8Bpvc",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X_test.shape)\ny_pred_df = pd.DataFrame(y_pred)\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nmerged_df = pd.concat([X_test, y_pred_df], axis=1)\nprint(\"merged_df shape: \", merged_df.shape)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nX_test shape:  (28, 20)\ny_pred_df shape:  (28, 1)\nmerged_df shape:  (56, 21)\nthe final merged df is:               LAT         LON        FWI  ...   FRP_day5   FRP_day6   0\n94388  40.199997 -122.899994  50.840454  ...        0.0        0.0 NaN\n96914  40.600006 -110.699997  43.610882  ...        0.0        0.0 NaN\n96915  40.600006 -110.599998  45.627563  ...        0.0        0.0 NaN\n97125  40.600006  -89.599998  31.058390  ...        0.0        0.0 NaN\n97515  40.699997 -110.699997  49.625000  ...        0.0        0.0 NaN\n[5 rows x 21 columns]\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693597671760,
  "history_end_time" : 1693597685011,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "VTFSUjlxmyR8",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\nprint(\"X_test shape: \", X_test.shape)\ny_pred_df = pd.DataFrame(y_pred)\nprint(\"y_pred_df shape: \", y_pred_df.shape)\nmerged_df = pd.concat([X_test, y_pred_df], axis=1)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nX_test shape:  (28, 20)\ny_pred_df shape:  (28, 1)\nthe final merged df is:               LAT         LON        FWI  ...   FRP_day5   FRP_day6   0\n94388  40.199997 -122.899994  50.840454  ...        0.0        0.0 NaN\n96914  40.600006 -110.699997  43.610882  ...        0.0        0.0 NaN\n96915  40.600006 -110.599998  45.627563  ...        0.0        0.0 NaN\n97125  40.600006  -89.599998  31.058390  ...        0.0        0.0 NaN\n97515  40.699997 -110.699997  49.625000  ...        0.0        0.0 NaN\n[5 rows x 21 columns]\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693597614981,
  "history_end_time" : 1693597627664,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "RI3CE7XJ1YFg",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\ny_pred_df = pd.DataFrame(y_pred)\nmerged_df = pd.concat([X_test, y_pred_df], axis=1)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nthe final merged df is:               LAT         LON        FWI  ...   FRP_day5   FRP_day6   0\n94388  40.199997 -122.899994  50.840454  ...        0.0        0.0 NaN\n96914  40.600006 -110.699997  43.610882  ...        0.0        0.0 NaN\n96915  40.600006 -110.599998  45.627563  ...        0.0        0.0 NaN\n97125  40.600006  -89.599998  31.058390  ...        0.0        0.0 NaN\n97515  40.699997 -110.699997  49.625000  ...        0.0        0.0 NaN\n[5 rows x 21 columns]\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693597490894,
  "history_end_time" : 1693597504550,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "96mvvF54gQBY",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# merge the input and output into one df\nmerged_df = pd.concat([X_test_scaled, y_pred], axis=1)\nprint(\"the final merged df is: \", merged_df.head())\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 85, in <module>\n    merged_df = pd.concat([X_test_scaled, y_pred], axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 436, in __init__\n    raise TypeError(msg)\nTypeError: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid\n",
  "history_begin_time" : 1693597354799,
  "history_end_time" : 1693597378410,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "0BPoJ6KCvTPe",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (156861, 21)\nDF shape 3:  (138, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1693206673377,
  "history_end_time" : 1693206686019,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "rYgJTzSpPBRg",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\ndf = original_df\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (82397, 21)\nDF shape 3:  (115, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 48.05469853913042\nMedian: 9.052997\nStandard Deviation: 109.29507441107424\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 115\nMean Absolute Error (MAE): 5.271915000394738\nMean Squared Error (MSE): 521.3498118891711\nRoot Mean Squared Error (RMSE): 22.833085903775054\nR-squared (R2) Score: 0.9763716966839361\nExplained Variance Score: 0.9772021949521695\nMean Squared Log Error (MSLE): 0.001706330429541936\nMedian Absolute Error (MedAE): 0.05398959977722173\nMax Error: 109.02972387890622\n",
  "history_begin_time" : 1693206448569,
  "history_end_time" : 1693206457192,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ss9AW4A1mFHr",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\noriginal_df = get_one_day_time_series_training_data(\"20200831\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = original_df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200829\n20200828\n20200827\n20200826\n  File \"fc_model_creation.py\", line 28, in <module>\nNameError: name 'df' is not defined\n",
  "history_begin_time" : 1693206409945,
  "history_end_time" : 1693206421639,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "lYU3GFPM2g7s",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20200831\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\nprint(\"DF shape 0: \", df.shape)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\nprint(\"DF shape 1: \", df.shape)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\nprint(\"DF shape 2: \", df.shape)\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\nprint(\"DF shape 3: \", df.shape)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\nDF shape 0:  (156861, 21)\nDF shape 1:  (156861, 21)\nDF shape 2:  (82397, 21)\nDF shape 3:  (115, 21)\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 48.05469853913042\nMedian: 9.052997\nStandard Deviation: 109.29507441107424\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 115\nMean Absolute Error (MAE): 5.271915000394738\nMean Squared Error (MSE): 521.3498118891711\nRoot Mean Squared Error (RMSE): 22.833085903775054\nR-squared (R2) Score: 0.9763716966839361\nExplained Variance Score: 0.9772021949521695\nMean Squared Log Error (MSLE): 0.001706330429541936\nMedian Absolute Error (MedAE): 0.05398959977722173\nMax Error: 109.02972387890622\n",
  "history_begin_time" : 1692995649047,
  "history_end_time" : 1692995657098,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "7rrjasvpIWPM",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20200831\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\n# df = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 41.86266747826087\nMedian: 7.4512645\nStandard Deviation: 100.81250055131753\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 138\nMean Absolute Error (MAE): 4.686589361539296\nMean Squared Error (MSE): 498.43475372467935\nRoot Mean Squared Error (RMSE): 22.32565236952057\nR-squared (R2) Score: 0.9727729452040771\nExplained Variance Score: 0.9736186131612251\nMean Squared Log Error (MSLE): 0.001595979829442648\nMedian Absolute Error (MedAE): 0.06961241852951061\nMax Error: 117.76177954296872\n",
  "history_begin_time" : 1692995413928,
  "history_end_time" : 1692995424414,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "qf6Tkog9b1L6",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20200831\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200831\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200831.txt\n20200830\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200830.txt\n20200829\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200829.txt\n20200828\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200828.txt\n20200827\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200827.txt\n20200826\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200826.txt\n20200825\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20200825.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 48.05469853913042\nMedian: 9.052997\nStandard Deviation: 109.29507441107424\nMinimum: 0.663446\nMaximum: 731.856323\nCount: 115\nMean Absolute Error (MAE): 5.271915000394738\nMean Squared Error (MSE): 521.3498118891711\nRoot Mean Squared Error (RMSE): 22.833085903775054\nR-squared (R2) Score: 0.9763716966839361\nExplained Variance Score: 0.9772021949521695\nMean Squared Log Error (MSLE): 0.001706330429541936\nMedian Absolute Error (MedAE): 0.05398959977722173\nMax Error: 109.02972387890622\n",
  "history_begin_time" : 1692995314226,
  "history_end_time" : 1692995330218,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "CxZ9FapGj7rC",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20210218\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210218.txt\n20210218\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210218.txt\n20210217\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210217.txt\n20210216\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210216.txt\n20210215\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210215.txt\n20210214\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210214.txt\n20210213\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210213.txt\n20210212\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210212.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 36.666039975000004\nMedian: 8.217869499999999\nStandard Deviation: 143.1139189739819\nMinimum: 1.094497\nMaximum: 911.57196\nCount: 40\nMean Absolute Error (MAE): 4.947174662240982\nMean Squared Error (MSE): 83.35387210652895\nRoot Mean Squared Error (RMSE): 9.129834177383998\nR-squared (R2) Score: 0.8742441895127026\nExplained Variance Score: 0.9055395080096791\nMean Squared Log Error (MSLE): 0.5165493718232521\nMedian Absolute Error (MedAE): 0.6575485969161987\nMax Error: 21.456614556518556\n",
  "history_begin_time" : 1692995218542,
  "history_end_time" : 1692995232914,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "vIGKRSau47Bp",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20210718\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210718.txt\n20210718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210718.txt\n20210717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210717.txt\n20210716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210716.txt\n20210715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210715.txt\n20210714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\n20210713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\n20210712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\ndf head:     LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_day0', ' FRP_day1', ' FRP_day2',\n       ' FRP_day3', ' FRP_day4', ' FRP_day5', ' FRP_day6'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 530.6795509732616\nMedian: 25.199823\nStandard Deviation: 1684.3803246506955\nMinimum: 1.549921\nMaximum: 13514.680664\nCount: 187\nMean Absolute Error (MAE): 15.9335517238115\nMean Squared Error (MSE): 2205.2001352060215\nRoot Mean Squared Error (RMSE): 46.95955850735845\nR-squared (R2) Score: 0.9965059261518785\nExplained Variance Score: 0.9965193195935235\nMean Squared Log Error (MSLE): 0.0015996365916858897\nMedian Absolute Error (MedAE): 0.7955913493652336\nMax Error: 211.891113578125\n",
  "history_begin_time" : 1692995157714,
  "history_end_time" : 1692995170474,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "QCmK1BedpRTW",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files, get_one_day_time_series_training_data\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20210718\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210718.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST         SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0   1.25 -999.000000 -999.00000\n...      ...         ...   ...         ...  ...    ...    ...         ...        ...\n156856  50.5  -66.400002   0.0    7.942285  ...    0.0   0.00  288.724976    0.22775\n156857  50.5  -66.299995   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156858  50.5  -66.199997   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156859  50.5  -66.099998   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n156860  50.5  -66.000000   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n[156861 rows x 15 columns]\n20210718\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210718.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST         SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0   1.25 -999.000000 -999.00000\n...      ...         ...   ...         ...  ...    ...    ...         ...        ...\n156856  50.5  -66.400002   0.0    7.942285  ...    0.0   0.00  288.724976    0.22775\n156857  50.5  -66.299995   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156858  50.5  -66.199997   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156859  50.5  -66.099998   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n156860  50.5  -66.000000   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n[156861 rows x 15 columns]\n20210717\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210717.txt\n         LAT         LON   FRP  ...   CAPE          ST        SM\n0       24.5 -126.000000   0.0  ...  11.00 -999.000000 -999.0000\n1       24.5 -125.899994   0.0  ...  11.00 -999.000000 -999.0000\n2       24.5 -125.800003   0.0  ...   7.75 -999.000000 -999.0000\n3       24.5 -125.699997   0.0  ...   7.75 -999.000000 -999.0000\n4       24.5 -125.599998   0.0  ...   6.75 -999.000000 -999.0000\n...      ...         ...   ...  ...    ...         ...       ...\n156856  50.5  -66.400002   0.0  ...  14.00  287.457092    0.2525\n156857  50.5  -66.299995   0.0  ...  11.75  287.657074    0.2545\n156858  50.5  -66.199997   0.0  ...  11.75  287.657074    0.2545\n156859  50.5  -66.099998   0.0  ...  12.50  287.457092    0.2635\n156860  50.5  -66.000000   0.0  ...  12.50  287.457092    0.2635\n[156861 rows x 15 columns]\n20210716\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210716.txt\n         LAT         LON   FRP  ...   CAPE          ST         SM\n0       24.5 -126.000000   0.0  ...   4.50 -999.000000 -999.00000\n1       24.5 -125.899994   0.0  ...   4.50 -999.000000 -999.00000\n2       24.5 -125.800003   0.0  ...   4.25 -999.000000 -999.00000\n3       24.5 -125.699997   0.0  ...   4.25 -999.000000 -999.00000\n4       24.5 -125.599998   0.0  ...   8.25 -999.000000 -999.00000\n...      ...         ...   ...  ...    ...         ...        ...\n156856  50.5  -66.400002   0.0  ...   6.75  289.084656    0.26425\n156857  50.5  -66.299995   0.0  ...   3.75  288.959656    0.26125\n156858  50.5  -66.199997   0.0  ...   3.75  288.959656    0.26125\n156859  50.5  -66.099998   0.0  ...   4.75  288.759644    0.26625\n156860  50.5  -66.000000   0.0  ...   4.75  288.759644    0.26625\n[156861 rows x 15 columns]\n20210715\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210715.txt\n         LAT         LON   FRP  ...   CAPE          ST         SM\n0       24.5 -126.000000   0.0  ...   3.00 -999.000000 -999.00000\n1       24.5 -125.899994   0.0  ...   3.00 -999.000000 -999.00000\n2       24.5 -125.800003   0.0  ...   3.25 -999.000000 -999.00000\n3       24.5 -125.699997   0.0  ...   3.25 -999.000000 -999.00000\n4       24.5 -125.599998   0.0  ...   4.00 -999.000000 -999.00000\n...      ...         ...   ...  ...    ...         ...        ...\n156856  50.5  -66.400002   0.0  ...   4.75  287.614502    0.25250\n156857  50.5  -66.299995   0.0  ...   7.00  287.839508    0.24525\n156858  50.5  -66.199997   0.0  ...   7.00  287.839508    0.24525\n156859  50.5  -66.099998   0.0  ...   9.25  287.914490    0.25500\n156860  50.5  -66.000000   0.0  ...   9.25  287.914490    0.25500\n[156861 rows x 15 columns]\n20210714\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\n         LAT         LON   FRP  ...   CAPE          ST         SM\n0       24.5 -126.000000   0.0  ...   1.25 -999.000000 -999.00000\n1       24.5 -125.899994   0.0  ...   1.25 -999.000000 -999.00000\n2       24.5 -125.800003   0.0  ...   1.00 -999.000000 -999.00000\n3       24.5 -125.699997   0.0  ...   1.00 -999.000000 -999.00000\n4       24.5 -125.599998   0.0  ...   2.25 -999.000000 -999.00000\n...      ...         ...   ...  ...    ...         ...        ...\n156856  50.5  -66.400002   0.0  ...   0.50  288.689514    0.20850\n156857  50.5  -66.299995   0.0  ...   0.50  288.689484    0.20625\n156858  50.5  -66.199997   0.0  ...   0.50  288.689484    0.20625\n156859  50.5  -66.099998   0.0  ...   0.00  288.589508    0.21550\n156860  50.5  -66.000000   0.0  ...   0.00  288.589508    0.21550\n[156861 rows x 15 columns]\n20210713\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\n         LAT         LON   FRP  ...   CAPE          ST         SM\n0       24.5 -126.000000   0.0  ...   2.75 -999.000000 -999.00000\n1       24.5 -125.899994   0.0  ...   2.75 -999.000000 -999.00000\n2       24.5 -125.800003   0.0  ...   2.25 -999.000000 -999.00000\n3       24.5 -125.699997   0.0  ...   2.25 -999.000000 -999.00000\n4       24.5 -125.599998   0.0  ...   2.25 -999.000000 -999.00000\n...      ...         ...   ...  ...    ...         ...        ...\n156856  50.5  -66.400002   0.0  ...   0.00  287.959656    0.21025\n156857  50.5  -66.299995   0.0  ...   0.00  287.909668    0.21025\n156858  50.5  -66.199997   0.0  ...   0.00  287.909668    0.21025\n156859  50.5  -66.099998   0.0  ...   0.00  287.409668    0.22325\n156860  50.5  -66.000000   0.0  ...   0.00  287.409668    0.22325\n[156861 rows x 15 columns]\n20210712\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\n         LAT         LON   FRP  ...   CAPE          ST         SM\n0       24.5 -126.000000   0.0  ...   2.50 -999.000000 -999.00000\n1       24.5 -125.899994   0.0  ...   2.50 -999.000000 -999.00000\n2       24.5 -125.800003   0.0  ...   1.75 -999.000000 -999.00000\n3       24.5 -125.699997   0.0  ...   1.75 -999.000000 -999.00000\n4       24.5 -125.599998   0.0  ...   1.50 -999.000000 -999.00000\n...      ...         ...   ...  ...    ...         ...        ...\n156856  50.5  -66.400002   0.0  ...  25.50  286.714478    0.19900\n156857  50.5  -66.299995   0.0  ...  25.50  286.664490    0.19500\n156858  50.5  -66.199997   0.0  ...  25.50  286.664490    0.19500\n156859  50.5  -66.099998   0.0  ...  21.00  285.964478    0.20625\n156860  50.5  -66.000000   0.0  ...  21.00  285.964478    0.20625\n[156861 rows x 15 columns]\nNew time series dataframe:      LAT         LON   FRP    FWI  ...   FRP_day3   FRP_day4   FRP_day5   FRP_day6\n0  24.5 -126.000000   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n1  24.5 -125.899994   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n2  24.5 -125.800003   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n3  24.5 -125.699997   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n4  24.5 -125.599998   0.0 -999.0  ...        0.0        0.0        0.0        0.0\n[5 rows x 22 columns]\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 28, in <module>\n    print(\"df head:\", df.head())\nAttributeError: 'NoneType' object has no attribute 'head'\n",
  "history_begin_time" : 1692995097247,
  "history_end_time" : 1692995104500,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "lfOnEw1poC1j",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\n#df = read_original_txt_files(\"20210718\")\ndf = get_one_day_time_series_training_data(\"20210718\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 26, in <module>\n    df = get_one_day_time_series_training_data(\"20210718\")\nNameError: name 'get_one_day_time_series_training_data' is not defined\n",
  "history_begin_time" : 1692995075050,
  "history_end_time" : 1692995077087,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "uCqi97jN8wTr",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files(\"20210718\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_pred[y_pred < 0] = 0\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210718.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST         SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0   1.25 -999.000000 -999.00000\n...      ...         ...   ...         ...  ...    ...    ...         ...        ...\n156856  50.5  -66.400002   0.0    7.942285  ...    0.0   0.00  288.724976    0.22775\n156857  50.5  -66.299995   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156858  50.5  -66.199997   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156859  50.5  -66.099998   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n156860  50.5  -66.000000   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0   0.75 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0   0.75 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0   1.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0   1.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0   1.25 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 530.6795509732616\nMedian: 25.199823\nStandard Deviation: 1684.3803246506955\nMinimum: 1.549921\nMaximum: 13514.680664\nCount: 187\nMean Absolute Error (MAE): 396.13433185127985\nMean Squared Error (MSE): 609103.5879448707\nRoot Mean Squared Error (RMSE): 780.4508875931084\nR-squared (R2) Score: 0.03489353031610776\nExplained Variance Score: 0.04466233519385432\nMean Squared Log Error (MSLE): 8.470113886759837\nMedian Absolute Error (MedAE): 158.75452503808594\nMax Error: 3949.305908421875\n",
  "history_begin_time" : 1692994468960,
  "history_end_time" : 1692994479303,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "mglMy7eZ7MJ3",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files(\"20210718\")\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210718.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST         SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0   0.75 -999.000000 -999.00000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0   1.00 -999.000000 -999.00000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0   1.25 -999.000000 -999.00000\n...      ...         ...   ...         ...  ...    ...    ...         ...        ...\n156856  50.5  -66.400002   0.0    7.942285  ...    0.0   0.00  288.724976    0.22775\n156857  50.5  -66.299995   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156858  50.5  -66.199997   0.0    7.675000  ...    0.0   0.00  289.000000    0.22875\n156859  50.5  -66.099998   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n156860  50.5  -66.000000   0.0    7.631380  ...    0.0   0.00  288.499969    0.24050\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0   0.75 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0   0.75 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0   1.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0   1.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0   1.25 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 530.6795509732616\nMedian: 25.199823\nStandard Deviation: 1684.3803246506955\nMinimum: 1.549921\nMaximum: 13514.680664\nCount: 187\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 83, in <module>\n    msle = mean_squared_log_error(y_test, y_pred)\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 521, in mean_squared_log_error\n    raise ValueError(\nValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
  "history_begin_time" : 1692994360977,
  "history_end_time" : 1692994373105,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "TCzhmOM9HBrg",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# remove terrain temporarily\ndf = df.drop(' HT', axis=1)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' T', ' RH', ' U', ' V', ' P',\n       ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 10.92559504232805\nMedian: 4.6991705\nStandard Deviation: 21.966998026788197\nMinimum: 0.965435\nMaximum: 347.776581\nCount: 378\nMean Absolute Error (MAE): 12.799336186072699\nMean Squared Error (MSE): 281.5354821767195\nRoot Mean Squared Error (RMSE): 16.779019106512738\nR-squared (R2) Score: -0.2847023496273453\nExplained Variance Score: -0.284699465243478\nMean Squared Log Error (MSLE): 1.0377558642742204\nMedian Absolute Error (MedAE): 9.37986898965454\nMax Error: 61.46578656231689\n",
  "history_begin_time" : 1692993626935,
  "history_end_time" : 1692993639823,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "vQ5VDoSipi5D",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, median_absolute_error, max_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 17.985333120689653\nMedian: 4.751074\nStandard Deviation: 94.21813114242096\nMinimum: 0.965435\nMaximum: 1646.294556\nCount: 406\nMean Absolute Error (MAE): 11.794470010610627\nMean Squared Error (MSE): 264.47291503063815\nRoot Mean Squared Error (RMSE): 16.26262325182005\nR-squared (R2) Score: -0.2601266873676482\nExplained Variance Score: -0.2548748308648898\nMean Squared Log Error (MSLE): 0.9326069215147905\nMedian Absolute Error (MedAE): 8.603539597595214\nMax Error: 63.44861994778442\n",
  "history_begin_time" : 1692993456785,
  "history_end_time" : 1692993465928,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "KlQQfHpCb8u9",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\nexplained_var = explained_variance_score(y_test, y_pred)\nmsle = mean_squared_log_error(y_test, y_pred)\nmedae = median_absolute_error(y_test, y_pred)\nmax_err = max_error(y_test, y_pred)\n\n# Print the metrics\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-squared (R2) Score: {r2}\")\nprint(f\"Explained Variance Score: {explained_var}\")\nprint(f\"Mean Squared Log Error (MSLE): {msle}\")\nprint(f\"Median Absolute Error (MedAE): {medae}\")\nprint(f\"Max Error: {max_err}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 17.985333120689653\nMedian: 4.751074\nStandard Deviation: 94.21813114242096\nMinimum: 0.965435\nMaximum: 1646.294556\nCount: 406\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 73, in <module>\n    mae = mean_absolute_error(y_test, y_pred)\nNameError: name 'mean_absolute_error' is not defined\n",
  "history_begin_time" : 1692993413399,
  "history_end_time" : 1692993423523,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "CEbCotuSoW7u",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\nReading data from file : /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20201208.txt\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 17.985333120689653\nMedian: 4.751074\nStandard Deviation: 94.21813114242096\nMinimum: 0.965435\nMaximum: 1646.294556\nCount: 406\nMean Squared Error: 264.47291503063815\n",
  "history_begin_time" : 1692993318688,
  "history_end_time" : 1692993327208,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "QsAV1jI8Cj0O",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\n#df = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 17.985333120689653\nMedian: 4.751074\nStandard Deviation: 94.21813114242096\nMinimum: 0.965435\nMaximum: 1646.294556\nCount: 406\nMean Squared Error: 264.47291503063815\n",
  "history_begin_time" : 1692993179093,
  "history_end_time" : 1692993186617,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "WbNzFIEpNaQa",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# remove all rows with -999 in any column\ndf = df[~(df == -999).any(axis=1)]\n\n# remove all rows with FRP == 0\ndf = df[df[target_col] != 0]\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: nan\nMedian: nan\nStandard Deviation: nan\nMinimum: nan\nMaximum: nan\nCount: 0\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 58, in <module>\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2420, in train_test_split\n    n_train, n_test = _validate_shuffle_split(\n  File \"/home/zsun/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2098, in _validate_shuffle_split\n    raise ValueError(\nValueError: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n",
  "history_begin_time" : 1692993150278,
  "history_end_time" : 1692993152556,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "4lEbyWJVpNDW",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\nprint(\"do some quick stats on FRP column\")\n# Print the statistics\nprint(f\"Mean: {y.mean()}\")\nprint(f\"Median: {y.median()}\")\nprint(f\"Standard Deviation: {y.std()}\")\nprint(f\"Minimum: {y.min()}\")\nprint(f\"Maximum: {y.max()}\")\nprint(f\"Count: {y.count()}\")\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\ndo some quick stats on FRP column\nMean: 0.04655105633012667\nMedian: 0.0\nStandard Deviation: 4.873902465653481\nMinimum: 0.0\nMaximum: 1646.294556\nCount: 156861\nMean Squared Error: 0.9566758446781316\n",
  "history_begin_time" : 1692992899256,
  "history_end_time" : 1692992927818,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "vaEFadIBYD7V",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\nMean Squared Error: 0.9566758446781316\n",
  "history_begin_time" : 1692992735081,
  "history_end_time" : 1692992754942,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "6u3leqcajIum",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\nprint(\"df head:\", df.head())\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\n#for i in range(1, num_previous_days + 1):\n#    for col in df.columns:\n#        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "target column is   FRP\nreading the original txt files\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ndf head:     LAT         LON   FRP    FWI  ...   RAIN   CAPE     ST     SM\n0  24.5 -126.000000   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n1  24.5 -125.899994   0.0 -999.0  ...    0.0  17.50 -999.0 -999.0\n2  24.5 -125.800003   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n3  24.5 -125.699997   0.0 -999.0  ...    0.0  18.00 -999.0 -999.0\n4  24.5 -125.599998   0.0 -999.0  ...    0.0  17.75 -999.0 -999.0\n[5 rows x 15 columns]\nLag/Shift the data for previous days' information\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 49, in <module>\n    model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nNameError: name 'XGBRegressor' is not defined\n",
  "history_begin_time" : 1692992537769,
  "history_end_time" : 1692992542416,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "MIGKKlARN3f2",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\n#warnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "fc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\n",
  "history_begin_time" : 1692992453793,
  "history_end_time" : 1692992482323,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "NO8oZH54xxmA",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\nprint(\"target column is \", target_col)\n\nprint(\"reading the original txt files\")\ndf = read_original_txt_files()\n\n\nprint(\"Lag/Shift the data for previous days' information\")\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "",
  "history_begin_time" : 1692992384939,
  "history_end_time" : 1692992410059,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "O2Gv4xIewqWR",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\n\nprint(\"read the txt files into python dataframes\")\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1692988193082,
  "history_end_time" : 1692992221834,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "0GIWHDJLcarH",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = ' FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "",
  "history_begin_time" : 1692389635664,
  "history_end_time" : 1692390046556,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "PQK7nrMSMmLb",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = 'FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nprint(\"current all columns: \", df.columns)\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\ncurrent all columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ...\n       ' HT_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' T_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' RH_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' U_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' V_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' P_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' RAIN_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' CAPE_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' ST_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7',\n       ' SM_lag_1_lag_2_lag_3_lag_4_lag_5_lag_6_lag_7'],\n      dtype='object', length=1920)\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 32, in <module>\n    X = df.drop([target_col], axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 4948, in drop\n    return super().drop(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4279, in drop\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4323, in _drop_axis\n    new_axis = axis.drop(labels, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 6644, in drop\n    raise KeyError(f\"{list(labels[mask])} not found in axis\")\nKeyError: \"['FRP'] not found in axis\"\n",
  "history_begin_time" : 1692389597380,
  "history_end_time" : 1692389607600,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "tsku6bTnS1MO",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = 'FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nX = df.drop([target_col], axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 31, in <module>\n    X = df.drop([target_col], axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 4948, in drop\n    return super().drop(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4279, in drop\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4323, in _drop_axis\n    new_axis = axis.drop(labels, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 6644, in drop\n    raise KeyError(f\"{list(labels[mask])} not found in axis\")\nKeyError: \"['FRP'] not found in axis\"\n",
  "history_begin_time" : 1692389530756,
  "history_end_time" : 1692389541665,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "tagkcP7hmeJd",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = 'FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nX = df.drop(target_col, axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 31, in <module>\n    X = df.drop(target_col, axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 4948, in drop\n    return super().drop(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4279, in drop\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4323, in _drop_axis\n    new_axis = axis.drop(labels, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 6644, in drop\n    raise KeyError(f\"{list(labels[mask])} not found in axis\")\nKeyError: \"['FRP'] not found in axis\"\n",
  "history_begin_time" : 1692389336295,
  "history_end_time" : 1692389347332,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "cGUkMJlAsct0",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = 'FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nX = df.drop(target_col, axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 31, in <module>\n    X = df.drop(target_col, axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 4948, in drop\n    return super().drop(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4279, in drop\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4323, in _drop_axis\n    new_axis = axis.drop(labels, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 6644, in drop\n    raise KeyError(f\"{list(labels[mask])} not found in axis\")\nKeyError: \"['FRP'] not found in axis\"\n",
  "history_begin_time" : 1692389287462,
  "history_end_time" : 1692389308721,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "Zqs0KWMkZn6v",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n# Suppress the specific warning\nwarnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\n\n\n# Assuming 'target' is the column to predict\ntarget_col = 'FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nX = df.drop(target_col, axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 13, in <module>\n    warnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\")\nNameError: name 'warnings' is not defined\n",
  "history_begin_time" : 1692389256429,
  "history_end_time" : 1692389260965,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "kgkZrhMh05ZB",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nfrom fc_train_data_preprocess import read_original_txt_files\n\n\n# Assuming 'target' is the column to predict\ntarget_col = 'FRP'\n\ndf = read_original_txt_files()\n# Lag/Shift the data for previous days' information\nnum_previous_days = 7  # Adjust the number of previous days to consider\nfor i in range(1, num_previous_days + 1):\n    for col in df.columns:\n        df[f'{col}_lag_{i}'] = df[col].shift(i)\n\n# Drop rows with NaN values from the shifted columns\ndf.dropna(inplace=True)\n\n# Define features and target\nX = df.drop(target_col, axis=1)\ny = df[target_col]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n# Standardize the features - not sure about this\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize and train a model (e.g., Linear Regression)\nmodel = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\n",
  "history_output" : "fc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\nfc_model_creation.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[f'{col}_lag_{i}'] = df[col].shift(i)\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\n         LAT         LON   FRP         FWI  ...   RAIN   CAPE          ST       SM\n0       24.5 -126.000000   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n1       24.5 -125.899994   0.0 -999.000000  ...    0.0  17.50 -999.000000 -999.000\n2       24.5 -125.800003   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n3       24.5 -125.699997   0.0 -999.000000  ...    0.0  18.00 -999.000000 -999.000\n4       24.5 -125.599998   0.0 -999.000000  ...    0.0  17.75 -999.000000 -999.000\n...      ...         ...   ...         ...  ...    ...    ...         ...      ...\n156856  50.5  -66.400002   0.0    0.003906  ...    0.0   0.00  268.872772    0.427\n156857  50.5  -66.299995   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156858  50.5  -66.199997   0.0    0.003906  ...    0.0   0.00  269.452759    0.427\n156859  50.5  -66.099998   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n156860  50.5  -66.000000   0.0    0.003906  ...    0.0   0.00  269.645264    0.432\n[156861 rows x 15 columns]\nTraceback (most recent call last):\n  File \"fc_model_creation.py\", line 27, in <module>\n    X = df.drop(target_col, axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 4948, in drop\n    return super().drop(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4279, in drop\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 4323, in _drop_axis\n    new_axis = axis.drop(labels, errors=errors)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 6644, in drop\n    raise KeyError(f\"{list(labels[mask])} not found in axis\")\nKeyError: \"['FRP'] not found in axis\"\n",
  "history_begin_time" : 1692389194072,
  "history_end_time" : 1692389214366,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "v6arpyjo2v8",
  "history_input" : "# create a ML model for wildfire emission forecasting\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1692388306774,
  "history_end_time" : 1692388310312,
  "history_notes" : null,
  "history_process" : "w4lpt8",
  "host_id" : "100001",
  "indicator" : "Done"
},]
