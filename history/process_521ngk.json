[{
  "history_id" : "0eTVa5IVRpwe",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    # print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    #print(\"current index: \", row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str))\n    print(\"row values: \", row)\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    # print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    print(\"partition_df.head = \", partition_df.head())\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        #grid_to_window_mapper_df['Combined_Location'] = grid_to_window_mapper_df['LAT'].astype(str) + '_' + grid_to_window_mapper_df[' LON'].astype(str)\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        #grid_to_window_mapper_df.set_index('Combined_Location', inplace=True)\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"original_df index: \", original_df.index)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        print(\"grid_to_window_mapper_df index: \", grid_to_window_mapper_df.index)\n        new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        #ddf = dd.from_pandas(original_df, npartitions=5)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        #new_df = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df).compute()\n        #new_df = ddf.apply(add_window_grid_cells, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df, axis=1)\n\n        # Convert back to Pandas DataFrame\n        #new_df = new_df.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago'],\n      dtype='object')\noriginal_df index:  RangeIndex(start=0, stop=156861, step=1)\ngrid_to_window_mapper_df columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ngrid_to_window_mapper_df index:  MultiIndex([(24.5,      -126.0),\n            (24.5, -125.899994),\n            (24.5, -125.800003),\n            (24.5, -125.699997),\n            (24.5, -125.599998),\n            (24.5,      -125.5),\n            (24.5, -125.399994),\n            (24.5, -125.300003),\n            (24.5, -125.199997),\n            (24.5, -125.099998),\n            ...\n            (50.5,  -66.900002),\n            (50.5,  -66.799995),\n            (50.5,  -66.699997),\n            (50.5,  -66.599998),\n            (50.5,       -66.5),\n            (50.5,  -66.400002),\n            (50.5,  -66.299995),\n            (50.5,  -66.199997),\n            (50.5,  -66.099998),\n            (50.5,       -66.0)],\n           names=['LAT', ' LON'], length=156861)\nrow values:  LAT                    24.500000\n LON                 -126.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.139282\n RH                    71.974998\n U                     -2.220295\n V                     -5.077804\n P                 101593.296875\n RAIN                   0.000005\n CAPE                   1.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 0, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -125.899994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.139282\n RH                    71.974998\n U                     -2.220295\n V                     -5.077804\n P                 101593.296875\n RAIN                   0.000005\n CAPE                   1.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 1, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -125.800003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.239258\n RH                    66.700005\n U                     -2.145295\n V                     -5.022804\n P                 101584.093750\n RAIN                   0.000004\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 2, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -125.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.239258\n RH                    66.700005\n U                     -2.145295\n V                     -5.022804\n P                 101584.093750\n RAIN                   0.000004\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 3, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -125.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.289276\n RH                    64.350006\n U                     -2.055295\n V                     -4.902804\n P                 101576.898438\n RAIN                   0.000004\n CAPE                   2.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 4, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -125.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.289276\n RH                    64.350006\n U                     -2.055295\n V                     -4.902804\n P                 101576.898438\n RAIN                   0.000004\n CAPE                   2.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 5, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -125.399994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.289276\n RH                    64.350006\n U                     -2.055295\n V                     -4.902804\n P                 101576.898438\n RAIN                   0.000004\n CAPE                   2.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 6, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -125.300003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.464264\n RH                    63.525002\n U                     -1.897795\n V                     -4.802804\n P                 101566.898438\n RAIN                   0.000004\n CAPE                   2.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 7, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -125.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.464264\n RH                    63.525002\n U                     -1.897795\n V                     -4.802804\n P                 101566.898438\n RAIN                   0.000004\n CAPE                   2.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 8, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -125.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.464264\n RH                    64.275002\n U                     -1.757795\n V                     -4.772804\n P                 101558.101562\n RAIN                   0.000005\n CAPE                   2.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 9, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -125.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.464264\n RH                    64.275002\n U                     -1.757795\n V                     -4.772804\n P                 101558.101562\n RAIN                   0.000005\n CAPE                   2.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 10, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -124.899994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.464264\n RH                    64.275002\n U                     -1.757795\n V                     -4.772804\n P                 101558.101562\n RAIN                   0.000005\n CAPE                   2.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 11, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -124.800003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.489258\n RH                    66.375000\n U                     -1.612795\n V                     -4.737804\n P                 101549.296875\n RAIN                   0.000005\n CAPE                   2.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 12, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -124.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.489258\n RH                    66.375000\n U                     -1.612795\n V                     -4.737804\n P                 101549.296875\n RAIN                   0.000005\n CAPE                   2.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 13, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -124.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.539276\n RH                    68.400002\n U                     -1.382795\n V                     -4.655304\n P                 101540.101562\n RAIN                   0.000003\n CAPE                   2.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 14, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -124.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.539276\n RH                    68.400002\n U                     -1.382795\n V                     -4.655304\n P                 101540.101562\n RAIN                   0.000003\n CAPE                   2.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 15, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -124.399994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.539276\n RH                    68.400002\n U                     -1.382795\n V                     -4.655304\n P                 101540.101562\n RAIN                   0.000003\n CAPE                   2.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 16, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -124.300003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.514282\n RH                    69.650002\n U                     -1.162795\n V                     -4.505304\n P                 101531.296875\n RAIN                   0.000004\n CAPE                   2.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 17, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -124.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.514282\n RH                    69.650002\n U                     -1.162795\n V                     -4.505304\n P                 101531.296875\n RAIN                   0.000004\n CAPE                   2.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 18, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -124.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.439270\n RH                    71.625000\n U                     -0.997795\n V                     -4.322804\n P                 101523.703125\n RAIN                   0.000004\n CAPE                   2.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 19, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -124.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.439270\n RH                    71.625000\n U                     -0.997795\n V                     -4.322804\n P                 101523.703125\n RAIN                   0.000004\n CAPE                   2.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 20, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -123.899994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.439270\n RH                    71.625000\n U                     -0.997795\n V                     -4.322804\n P                 101523.703125\n RAIN                   0.000004\n CAPE                   2.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 21, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -123.800003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.464294\n RH                    73.275002\n U                     -0.815295\n V                     -4.137804\n P                 101516.500000\n RAIN                   0.000003\n CAPE                   3.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 22, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -123.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.464294\n RH                    73.275002\n U                     -0.815295\n V                     -4.137804\n P                 101516.500000\n RAIN                   0.000003\n CAPE                   3.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 23, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -123.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.364288\n RH                    71.875000\n U                     -0.590295\n V                     -3.922804\n P                 101510.898438\n RAIN                   0.000004\n CAPE                   2.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 24, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -123.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.364288\n RH                    71.875000\n U                     -0.590295\n V                     -3.922804\n P                 101510.898438\n RAIN                   0.000004\n CAPE                   2.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 25, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -123.399994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.364288\n RH                    71.875000\n U                     -0.590295\n V                     -3.922804\n P                 101510.898438\n RAIN                   0.000004\n CAPE                   2.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 26, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -123.300003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.364288\n RH                    69.724998\n U                     -0.352795\n V                     -3.697804\n P                 101505.296875\n RAIN                   0.000003\n CAPE                   2.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 27, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -123.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.364288\n RH                    69.724998\n U                     -0.352795\n V                     -3.697804\n P                 101505.296875\n RAIN                   0.000003\n CAPE                   2.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 28, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -123.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.289276\n RH                    69.275002\n U                     -0.090295\n V                     -3.460304\n P                 101498.898438\n RAIN                   0.000002\n CAPE                   1.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 29, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -123.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.289276\n RH                    69.275002\n U                     -0.090295\n V                     -3.460304\n P                 101498.898438\n RAIN                   0.000002\n CAPE                   1.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 30, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -122.899994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.289276\n RH                    69.275002\n U                     -0.090295\n V                     -3.460304\n P                 101498.898438\n RAIN                   0.000002\n CAPE                   1.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 31, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -122.800003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.239288\n RH                    67.725006\n U                      0.049705\n V                     -3.180304\n P                 101493.296875\n RAIN                   0.000002\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 32, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -122.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.239288\n RH                    67.725006\n U                      0.049705\n V                     -3.180304\n P                 101493.296875\n RAIN                   0.000002\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 33, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -122.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.314270\n RH                    66.900002\n U                      0.294705\n V                     -2.892804\n P                 101487.703125\n RAIN                   0.000002\n CAPE                   0.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 34, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -122.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.314270\n RH                    66.900002\n U                      0.294705\n V                     -2.892804\n P                 101487.703125\n RAIN                   0.000002\n CAPE                   0.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 35, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -122.399994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.314270\n RH                    66.900002\n U                      0.294705\n V                     -2.892804\n P                 101487.703125\n RAIN                   0.000002\n CAPE                   0.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 36, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -122.300003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.389282\n RH                    67.574997\n U                      0.532205\n V                     -2.485304\n P                 101483.703125\n RAIN                   0.000002\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 37, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -122.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.389282\n RH                    67.574997\n U                      0.532205\n V                     -2.485304\n P                 101483.703125\n RAIN                   0.000002\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 38, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -122.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.389282\n RH                    64.525002\n U                      0.679705\n V                     -1.987804\n P                 101480.500000\n RAIN                   0.000001\n CAPE                   0.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 39, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -122.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.389282\n RH                    64.525002\n U                      0.679705\n V                     -1.987804\n P                 101480.500000\n RAIN                   0.000001\n CAPE                   0.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 40, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -121.899994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.389282\n RH                    64.525002\n U                      0.679705\n V                     -1.987804\n P                 101480.500000\n RAIN                   0.000001\n CAPE                   0.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 41, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -121.800003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.389282\n RH                    62.150002\n U                      0.909705\n V                     -1.547804\n P                 101477.304688\n RAIN                   0.000001\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 42, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -121.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.389282\n RH                    62.150002\n U                      0.909705\n V                     -1.547804\n P                 101477.304688\n RAIN                   0.000001\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 43, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -121.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.414276\n RH                    65.950005\n U                      1.117205\n V                     -1.132804\n P                 101472.898438\n RAIN                   0.000001\n CAPE                   1.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 44, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -121.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.414276\n RH                    65.950005\n U                      1.117205\n V                     -1.132804\n P                 101472.898438\n RAIN                   0.000001\n CAPE                   1.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 45, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -121.399994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.414276\n RH                    65.950005\n U                      1.117205\n V                     -1.132804\n P                 101472.898438\n RAIN                   0.000001\n CAPE                   1.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 46, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -121.300003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.464264\n RH                    67.775002\n U                      1.362205\n V                     -0.907804\n P                 101468.898438\n RAIN                   0.000000\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 47, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -121.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.464264\n RH                    67.775002\n U                      1.362205\n V                     -0.907804\n P                 101468.898438\n RAIN                   0.000000\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 48, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -121.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.514282\n RH                    66.825005\n U                      1.392205\n V                     -0.895304\n P                 101466.898438\n RAIN                   0.000000\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 49, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -121.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.514282\n RH                    66.825005\n U                      1.392205\n V                     -0.895304\n P                 101466.898438\n RAIN                   0.000000\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 50, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -120.899994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.514282\n RH                    66.825005\n U                      1.392205\n V                     -0.895304\n P                 101466.898438\n RAIN                   0.000000\n CAPE                   1.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 51, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -120.800003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.564270\n RH                    67.925003\n U                      1.359705\n V                     -1.070304\n P                 101464.500000\n RAIN                   0.000000\n CAPE                   0.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 52, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -120.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.564270\n RH                    67.925003\n U                      1.359705\n V                     -1.070304\n P                 101464.500000\n RAIN                   0.000000\n CAPE                   0.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 53, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -120.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.564270\n RH                    69.025002\n U                      1.237205\n V                     -1.155304\n P                 101462.898438\n RAIN                   0.000000\n CAPE                   0.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 54, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -120.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.564270\n RH                    69.025002\n U                      1.237205\n V                     -1.155304\n P                 101462.898438\n RAIN                   0.000000\n CAPE                   0.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 55, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -120.399994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.564270\n RH                    69.025002\n U                      1.237205\n V                     -1.155304\n P                 101462.898438\n RAIN                   0.000000\n CAPE                   0.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 56, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -120.300003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.764282\n RH                    67.925003\n U                      1.144705\n V                     -1.137804\n P                 101460.898438\n RAIN                   0.000000\n CAPE                   0.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 57, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -120.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.764282\n RH                    67.925003\n U                      1.144705\n V                     -1.137804\n P                 101460.898438\n RAIN                   0.000000\n CAPE                   0.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 58, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -120.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.789276\n RH                    69.250000\n U                      1.119705\n V                     -0.957804\n P                 101458.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 59, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -120.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.789276\n RH                    69.250000\n U                      1.119705\n V                     -0.957804\n P                 101458.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 60, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -119.899994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.789276\n RH                    69.250000\n U                      1.119705\n V                     -0.957804\n P                 101458.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 61, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -119.800003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.739258\n RH                    70.350006\n U                      0.912205\n V                     -0.762804\n P                 101459.296875\n RAIN                   0.000000\n CAPE                   0.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 62, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -119.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.739258\n RH                    70.350006\n U                      0.912205\n V                     -0.762804\n P                 101459.296875\n RAIN                   0.000000\n CAPE                   0.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 63, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -119.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.964264\n RH                    72.199997\n U                      0.767205\n V                     -0.525304\n P                 101461.296875\n RAIN                   0.000000\n CAPE                   0.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 64, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -119.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.964264\n RH                    72.199997\n U                      0.767205\n V                     -0.525304\n P                 101461.296875\n RAIN                   0.000000\n CAPE                   0.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 65, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -119.399994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    293.964264\n RH                    72.199997\n U                      0.767205\n V                     -0.525304\n P                 101461.296875\n RAIN                   0.000000\n CAPE                   0.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 66, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -119.300003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.064270\n RH                    72.375000\n U                      0.842205\n V                     -0.287804\n P                 101460.500000\n RAIN                   0.000000\n CAPE                   0.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 67, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -119.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.064270\n RH                    72.375000\n U                      0.842205\n V                     -0.287804\n P                 101460.500000\n RAIN                   0.000000\n CAPE                   0.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 68, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -119.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.214294\n RH                    71.225006\n U                      0.929705\n V                     -0.215304\n P                 101460.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 69, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -119.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.214294\n RH                    71.225006\n U                      0.929705\n V                     -0.215304\n P                 101460.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 70, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -118.899994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.214294\n RH                    71.225006\n U                      0.929705\n V                     -0.215304\n P                 101460.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 71, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -118.800003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.439270\n RH                    69.349998\n U                      0.974705\n V                     -0.257804\n P                 101461.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 72, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -118.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.439270\n RH                    69.349998\n U                      0.974705\n V                     -0.257804\n P                 101461.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 73, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -118.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.564270\n RH                    66.175003\n U                      1.099705\n V                     -0.322804\n P                 101461.296875\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 74, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -118.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.564270\n RH                    66.175003\n U                      1.099705\n V                     -0.322804\n P                 101461.296875\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 75, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -118.399994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.564270\n RH                    66.175003\n U                      1.099705\n V                     -0.322804\n P                 101461.296875\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 76, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -118.300003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.664276\n RH                    68.825005\n U                      1.187205\n V                     -0.445304\n P                 101460.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 77, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -118.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.664276\n RH                    68.825005\n U                      1.187205\n V                     -0.445304\n P                 101460.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 78, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -118.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.664276\n RH                    70.275002\n U                      1.124705\n V                     -0.597804\n P                 101462.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 79, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -118.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.664276\n RH                    70.275002\n U                      1.124705\n V                     -0.597804\n P                 101462.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 80, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -117.899994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.664276\n RH                    70.275002\n U                      1.124705\n V                     -0.597804\n P                 101462.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 81, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -117.800003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.789276\n RH                    68.200005\n U                      1.087205\n V                     -0.697804\n P                 101464.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 82, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -117.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.789276\n RH                    68.200005\n U                      1.087205\n V                     -0.697804\n P                 101464.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 83, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -117.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.889282\n RH                    65.900002\n U                      1.087205\n V                     -0.750304\n P                 101464.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 84, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -117.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.889282\n RH                    65.900002\n U                      1.087205\n V                     -0.750304\n P                 101464.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 85, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -117.399994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.889282\n RH                    65.900002\n U                      1.087205\n V                     -0.750304\n P                 101464.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 86, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -117.300003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.964264\n RH                    65.750000\n U                      1.094705\n V                     -0.805304\n P                 101462.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 87, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -117.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.964264\n RH                    65.750000\n U                      1.094705\n V                     -0.805304\n P                 101462.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 88, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -117.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.939270\n RH                    61.300003\n U                      1.067205\n V                     -0.910304\n P                 101460.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 89, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -117.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.939270\n RH                    61.300003\n U                      1.067205\n V                     -0.910304\n P                 101460.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 90, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -116.899994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    294.939270\n RH                    61.300003\n U                      1.067205\n V                     -0.910304\n P                 101460.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 91, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -116.800003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.089294\n RH                    57.575001\n U                      1.029705\n V                     -1.047804\n P                 101457.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 92, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -116.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.089294\n RH                    57.575001\n U                      1.029705\n V                     -1.047804\n P                 101457.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 93, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -116.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.114288\n RH                    58.125000\n U                      1.004705\n V                     -1.165304\n P                 101456.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 94, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -116.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.114288\n RH                    58.125000\n U                      1.004705\n V                     -1.165304\n P                 101456.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 95, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -116.399994\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.114288\n RH                    58.125000\n U                      1.004705\n V                     -1.165304\n P                 101456.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 96, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -116.300003\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.114288\n RH                    63.100002\n U                      1.034705\n V                     -1.265304\n P                 101454.906250\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 97, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -116.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.114288\n RH                    63.100002\n U                      1.034705\n V                     -1.265304\n P                 101454.906250\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 98, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -116.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.139282\n RH                    64.349998\n U                      1.152205\n V                     -1.315304\n P                 101452.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 99, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -116.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.139282\n RH                    64.349998\n U                      1.152205\n V                     -1.315304\n P                 101452.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 100, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -115.900002\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.139282\n RH                    64.349998\n U                      1.152205\n V                     -1.315304\n P                 101452.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 101, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -115.799995\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.164276\n RH                    62.125000\n U                      1.274705\n V                     -1.362804\n P                 101450.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 102, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -115.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.164276\n RH                    62.125000\n U                      1.274705\n V                     -1.362804\n P                 101450.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 103, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -115.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.239288\n RH                    59.474998\n U                      1.367205\n V                     -1.447804\n P                 101446.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 104, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -115.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.239288\n RH                    59.474998\n U                      1.367205\n V                     -1.447804\n P                 101446.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 105, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -115.400002\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.239288\n RH                    59.474998\n U                      1.367205\n V                     -1.447804\n P                 101446.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 106, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -115.299995\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.214294\n RH                    59.075001\n U                      1.439705\n V                     -1.555304\n P                 101443.296875\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 107, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -115.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.214294\n RH                    59.075001\n U                      1.439705\n V                     -1.555304\n P                 101443.296875\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 108, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -115.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.164276\n RH                    61.675003\n U                      1.544705\n V                     -1.677804\n P                 101440.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 109, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -115.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.164276\n RH                    61.675003\n U                      1.544705\n V                     -1.677804\n P                 101440.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 110, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -114.900002\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.164276\n RH                    61.675003\n U                      1.544705\n V                     -1.677804\n P                 101440.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 111, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -114.799995\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.064270\n RH                    65.449997\n U                      1.567205\n V                     -1.845304\n P                 101437.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 112, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -114.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.064270\n RH                    65.449997\n U                      1.567205\n V                     -1.845304\n P                 101437.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 113, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -114.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.139282\n RH                    66.925003\n U                      1.659705\n V                     -2.022804\n P                 101434.898438\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 114, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -114.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.139282\n RH                    66.925003\n U                      1.659705\n V                     -2.022804\n P                 101434.898438\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 115, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -114.400002\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.139282\n RH                    66.925003\n U                      1.659705\n V                     -2.022804\n P                 101434.898438\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 116, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -114.299995\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.139282\n RH                    67.525002\n U                      1.814705\n V                     -2.182804\n P                 101431.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 117, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -114.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.139282\n RH                    67.525002\n U                      1.814705\n V                     -2.182804\n P                 101431.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 118, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -114.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.114288\n RH                    68.349998\n U                      1.919705\n V                     -2.347804\n P                 101428.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 119, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -114.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.114288\n RH                    68.349998\n U                      1.919705\n V                     -2.347804\n P                 101428.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 120, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -113.900002\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.114288\n RH                    68.349998\n U                      1.919705\n V                     -2.347804\n P                 101428.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 121, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -113.799995\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.264282\n RH                    69.600006\n U                      2.062205\n V                     -2.487804\n P                 101425.296875\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 122, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -113.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.264282\n RH                    69.600006\n U                      2.062205\n V                     -2.487804\n P                 101425.296875\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 123, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -113.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.414276\n RH                    70.800003\n U                      2.209705\n V                     -2.567804\n P                 101419.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 124, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -113.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.414276\n RH                    70.800003\n U                      2.209705\n V                     -2.567804\n P                 101419.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 125, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -113.400002\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.414276\n RH                    70.800003\n U                      2.209705\n V                     -2.567804\n P                 101419.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 126, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -113.299995\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.614258\n RH                    71.625000\n U                      2.364705\n V                     -2.655304\n P                 101412.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 127, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -113.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.614258\n RH                    71.625000\n U                      2.364705\n V                     -2.655304\n P                 101412.500000\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 128, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -113.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.664276\n RH                    75.375000\n U                      2.489705\n V                     -2.707804\n P                 101406.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 129, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -113.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.664276\n RH                    75.375000\n U                      2.489705\n V                     -2.707804\n P                 101406.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 130, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -112.900002\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.664276\n RH                    75.375000\n U                      2.489705\n V                     -2.707804\n P                 101406.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 131, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -112.799995\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.639282\n RH                    76.325005\n U                      2.532205\n V                     -2.737804\n P                 101400.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 132, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -112.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.639282\n RH                    76.325005\n U                      2.532205\n V                     -2.737804\n P                 101400.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 133, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -112.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.589294\n RH                    74.275002\n U                      2.544705\n V                     -2.820304\n P                 101393.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 134, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -112.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.589294\n RH                    74.275002\n U                      2.544705\n V                     -2.820304\n P                 101393.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 135, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -112.400002\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    295.589294\n RH                    74.275002\n U                      2.544705\n V                     -2.820304\n P                 101393.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 136, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -112.299995\n FRP                    0.000000\n FWI                   13.035156\n VPD                 -999.000000\n HT                     0.000000\n T                    295.464264\n RH                    72.200005\n U                      3.044705\n V                     -2.847804\n P                 101383.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 137, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -112.199997\n FRP                    0.000000\n FWI                   13.035156\n VPD                 -999.000000\n HT                     0.000000\n T                    295.464264\n RH                    72.200005\n U                      3.044705\n V                     -2.847804\n P                 101383.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 138, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -112.099998\n FRP                    0.000000\n FWI                   19.214844\n VPD                 -999.000000\n HT                     0.000000\n T                    295.514282\n RH                    70.500000\n U                      3.852205\n V                     -2.262804\n P                 101353.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 139, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -112.000000\n FRP                    0.000000\n FWI                   19.214844\n VPD                 -999.000000\n HT                     0.000000\n T                    295.514282\n RH                    70.500000\n U                      3.852205\n V                     -2.262804\n P                 101353.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 140, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -111.900002\n FRP                    0.000000\n FWI                   19.214844\n VPD                 -999.000000\n HT                     0.000000\n T                    295.514282\n RH                    70.500000\n U                      3.852205\n V                     -2.262804\n P                 101353.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 141, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -111.799995\n FRP                    0.000000\n FWI                   41.079834\n VPD                 -999.000000\n HT                     0.000000\n T                    295.664276\n RH                    70.525002\n U                      4.159705\n V                     -1.255304\n P                 101319.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 142, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -111.699997\n FRP                    0.000000\n FWI                   41.079834\n VPD                 -999.000000\n HT                     0.000000\n T                    295.664276\n RH                    70.525002\n U                      4.159705\n V                     -1.255304\n P                 101319.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 143, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -111.599998\n FRP                    0.000000\n FWI                   49.583984\n VPD                 -999.000000\n HT                     0.000000\n T                    306.439270\n RH                    70.525002\n U                      3.864705\n V                     -0.690304\n P                 100987.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                   306.439514\n SM                     0.065000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 144, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -111.500000\n FRP                    0.000000\n FWI                   49.583984\n VPD                 -999.000000\n HT                     0.000000\n T                    306.439270\n RH                    70.525002\n U                      3.864705\n V                     -0.690304\n P                 100987.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                   306.439514\n SM                     0.065000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 145, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -111.400002\n FRP                    0.000000\n FWI                   49.583984\n VPD                 -999.000000\n HT                     0.000000\n T                    306.439270\n RH                    70.525002\n U                      3.864705\n V                     -0.690304\n P                 100987.703125\n RAIN                   0.000000\n CAPE                   0.000000\n ST                   306.439514\n SM                     0.065000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 146, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -111.299995\n FRP                    0.000000\n FWI                   49.583984\n VPD                 -999.000000\n HT                     0.000000\n T                    309.664276\n RH                    71.725006\n U                      3.449705\n V                     -0.362804\n P                 100264.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                   307.839508\n SM                     0.110250\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 147, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -111.199997\n FRP                    0.000000\n FWI                   49.583984\n VPD                 -999.000000\n HT                    14.800000\n T                    309.664276\n RH                    71.725006\n U                      3.449705\n V                     -0.362804\n P                 100264.101562\n RAIN                   0.000000\n CAPE                   0.000000\n ST                   307.839508\n SM                     0.110250\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 148, dtype: float64\nrow values:  LAT                   24.500000\n LON                -111.099998\n FRP                   0.000000\n FWI                  41.778564\n VPD                -999.000000\n HT                   14.800000\n T                   309.989258\n RH                   72.349998\n U                     3.039705\n V                     0.562196\n P                 99191.703125\n RAIN                  0.000000\n CAPE                  1.500000\n ST                  308.614502\n SM                    0.121000\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 149, dtype: float64\nrow values:  LAT                   24.500000\n LON                -111.000000\n FRP                   0.000000\n FWI                  41.778564\n VPD                -999.000000\n HT                   14.800000\n T                   309.989258\n RH                   72.349998\n U                     3.039705\n V                     0.562196\n P                 99191.703125\n RAIN                  0.000000\n CAPE                  1.500000\n ST                  308.614502\n SM                    0.121000\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 150, dtype: float64\nrow values:  LAT                   24.500000\n LON                -110.900002\n FRP                   0.000000\n FWI                  41.778564\n VPD                -999.000000\n HT                   94.700005\n T                   309.989258\n RH                   72.349998\n U                     3.039705\n V                     0.562196\n P                 99191.703125\n RAIN                  0.000000\n CAPE                  1.500000\n ST                  308.614502\n SM                    0.121000\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 151, dtype: float64\nrow values:  LAT                   24.500000\n LON                -110.799995\n FRP                   0.000000\n FWI                  26.979980\n VPD                -999.000000\n HT                   94.700005\n T                   312.564270\n RH                   71.950005\n U                     0.449705\n V                     0.672196\n P                 99384.500000\n RAIN                  0.000000\n CAPE                 56.250000\n ST                  311.539490\n SM                    0.125500\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 152, dtype: float64\nrow values:  LAT                   24.500000\n LON                -110.699997\n FRP                   0.000000\n FWI                  26.979980\n VPD                -999.000000\n HT                    0.000000\n T                   312.564270\n RH                   71.950005\n U                     0.449705\n V                     0.672196\n P                 99384.500000\n RAIN                  0.000000\n CAPE                 56.250000\n ST                  311.539490\n SM                    0.125500\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 153, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -110.599998\n FRP                    0.000000\n FWI                   19.782471\n VPD                 -999.000000\n HT                     0.000000\n T                    300.489288\n RH                    72.725006\n U                     -0.000295\n V                      2.044696\n P                 101246.500000\n RAIN                   0.000000\n CAPE                 434.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 154, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -110.500000\n FRP                    0.000000\n FWI                   19.782471\n VPD                 -999.000000\n HT                     0.000000\n T                    300.489288\n RH                    72.725006\n U                     -0.000295\n V                      2.044696\n P                 101246.500000\n RAIN                   0.000000\n CAPE                 434.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 155, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -110.400002\n FRP                    0.000000\n FWI                   19.782471\n VPD                 -999.000000\n HT                     0.000000\n T                    300.489288\n RH                    72.725006\n U                     -0.000295\n V                      2.044696\n P                 101246.500000\n RAIN                   0.000000\n CAPE                 434.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 156, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -110.299995\n FRP                    0.000000\n FWI                   19.175781\n VPD                 -999.000000\n HT                     0.000000\n T                    300.689270\n RH                    72.750000\n U                     -0.462795\n V                      3.267196\n P                 101236.101562\n RAIN                   0.000000\n CAPE                 677.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 157, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -110.199997\n FRP                    0.000000\n FWI                   19.175781\n VPD                 -999.000000\n HT                     0.000000\n T                    300.689270\n RH                    72.750000\n U                     -0.462795\n V                      3.267196\n P                 101236.101562\n RAIN                   0.000000\n CAPE                 677.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 158, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -110.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.114258\n RH                    74.575005\n U                      0.584705\n V                      3.074696\n P                 101270.898438\n RAIN                   0.000000\n CAPE                 600.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 159, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -110.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.114258\n RH                    74.575005\n U                      0.584705\n V                      3.074696\n P                 101270.898438\n RAIN                   0.000000\n CAPE                 600.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 160, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -109.900002\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.114258\n RH                    74.575005\n U                      0.584705\n V                      3.074696\n P                 101270.898438\n RAIN                   0.000000\n CAPE                 600.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 161, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -109.799995\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.489258\n RH                    79.600006\n U                     -0.617795\n V                      2.319696\n P                 101276.898438\n RAIN                   0.000000\n CAPE                 813.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 162, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -109.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.489258\n RH                    79.600006\n U                     -0.617795\n V                      2.319696\n P                 101276.898438\n RAIN                   0.000000\n CAPE                 813.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 163, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -109.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.539276\n RH                    83.450005\n U                     -1.065295\n V                      2.579696\n P                 101280.898438\n RAIN                   0.000000\n CAPE                 833.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 164, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -109.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.539276\n RH                    83.450005\n U                     -1.065295\n V                      2.579696\n P                 101280.898438\n RAIN                   0.000000\n CAPE                 833.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 165, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -109.400002\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.539276\n RH                    83.450005\n U                     -1.065295\n V                      2.579696\n P                 101280.898438\n RAIN                   0.000000\n CAPE                 833.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 166, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -109.299995\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.539276\n RH                    84.150002\n U                     -1.145295\n V                      3.144696\n P                 101284.898438\n RAIN                   0.000000\n CAPE                 720.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 167, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -109.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.539276\n RH                    84.150002\n U                     -1.145295\n V                      3.144696\n P                 101284.898438\n RAIN                   0.000000\n CAPE                 720.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 168, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -109.099998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.639282\n RH                    83.375000\n U                     -1.377795\n V                      3.439696\n P                 101290.101562\n RAIN                   0.000000\n CAPE                 570.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 169, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -109.000000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.639282\n RH                    83.375000\n U                     -1.377795\n V                      3.439696\n P                 101290.101562\n RAIN                   0.000000\n CAPE                 570.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 170, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -108.900002\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.639282\n RH                    83.375000\n U                     -1.377795\n V                      3.439696\n P                 101290.101562\n RAIN                   0.000000\n CAPE                 570.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 171, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -108.799995\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.764282\n RH                    84.775002\n U                     -1.062795\n V                      3.437196\n P                 101294.101562\n RAIN                   0.000000\n CAPE                 509.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 172, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -108.699997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    301.764282\n RH                    84.775002\n U                     -1.062795\n V                      3.437196\n P                 101294.101562\n RAIN                   0.000000\n CAPE                 509.000000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 173, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -108.599998\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    302.064270\n RH                    88.750000\n U                     -0.560295\n V                      3.267196\n P                 101297.703125\n RAIN                   0.000000\n CAPE                 537.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 174, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -108.500000\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    302.064270\n RH                    88.750000\n U                     -0.560295\n V                      3.267196\n P                 101297.703125\n RAIN                   0.000000\n CAPE                 537.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 175, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -108.400002\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    302.064270\n RH                    88.750000\n U                     -0.560295\n V                      3.267196\n P                 101297.703125\n RAIN                   0.000000\n CAPE                 537.250000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 176, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -108.299995\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    302.339264\n RH                    91.100006\n U                     -0.370295\n V                      2.934696\n P                 101299.703125\n RAIN                   0.000000\n CAPE                 654.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 177, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -108.199997\n FRP                    0.000000\n FWI                 -999.000000\n VPD                 -999.000000\n HT                     0.000000\n T                    302.339264\n RH                    91.100006\n U                     -0.370295\n V                      2.934696\n P                 101299.703125\n RAIN                   0.000000\n CAPE                 654.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 178, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -108.099998\n FRP                    0.000000\n FWI                   19.699219\n VPD                 -999.000000\n HT                     0.000000\n T                    302.464264\n RH                    92.750000\n U                     -0.140295\n V                      2.424696\n P                 101300.898438\n RAIN                   0.000000\n CAPE                 795.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 179, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -108.000000\n FRP                    0.000000\n FWI                   19.699219\n VPD                 -999.000000\n HT                     0.000000\n T                    302.464264\n RH                    92.750000\n U                     -0.140295\n V                      2.424696\n P                 101300.898438\n RAIN                   0.000000\n CAPE                 795.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 180, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -107.900002\n FRP                    0.000000\n FWI                   19.699219\n VPD                 -999.000000\n HT                     0.000000\n T                    302.464264\n RH                    92.750000\n U                     -0.140295\n V                      2.424696\n P                 101300.898438\n RAIN                   0.000000\n CAPE                 795.750000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 181, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -107.799995\n FRP                    0.000000\n FWI                   28.821533\n VPD                 -999.000000\n HT                     0.000000\n T                    302.314270\n RH                    94.600006\n U                      0.052205\n V                      1.667196\n P                 101291.296875\n RAIN                   0.000000\n CAPE                 689.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago        13.945765\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 182, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -107.699997\n FRP                    0.000000\n FWI                   28.821533\n VPD                 -999.000000\n HT                     0.000000\n T                    302.314270\n RH                    94.600006\n U                      0.052205\n V                      1.667196\n P                 101291.296875\n RAIN                   0.000000\n CAPE                 689.500000\n ST                  -999.000000\n SM                  -999.000000\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 183, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -107.599998\n FRP                    0.000000\n FWI                   26.042480\n VPD                 -999.000000\n HT                     0.000000\n T                    301.014282\n RH                    98.150002\n U                      0.332205\n V                      0.729696\n P                 101235.703125\n RAIN                   0.000000\n CAPE                 372.000000\n ST                   301.914490\n SM                     0.090500\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 184, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -107.500000\n FRP                    0.000000\n FWI                   26.042480\n VPD                 -999.000000\n HT                     0.000000\n T                    301.014282\n RH                    98.150002\n U                      0.332205\n V                      0.729696\n P                 101235.703125\n RAIN                   0.000000\n CAPE                 372.000000\n ST                   301.914490\n SM                     0.090500\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         0.000000\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 185, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -107.400002\n FRP                    8.389288\n FWI                   26.042480\n VPD                 -999.000000\n HT                     0.000000\n T                    301.014282\n RH                    98.150002\n U                      0.332205\n V                      0.729696\n P                 101235.703125\n RAIN                   0.000000\n CAPE                 372.000000\n ST                   301.914490\n SM                     0.090500\n FRP_1_days_ago         0.000000\n FRP_2_days_ago         7.364495\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago        34.050766\n FRP_7_days_ago         0.000000\nName: 186, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -107.299995\n FRP                    0.000000\n FWI                   11.939697\n VPD                 -999.000000\n HT                     0.000000\n T                    302.764282\n RH                    95.300003\n U                      0.012205\n V                      0.062196\n P                 100539.703125\n RAIN                   0.000109\n CAPE                 267.250000\n ST                   300.814514\n SM                     0.181750\n FRP_1_days_ago         0.000000\n FRP_2_days_ago        21.129374\n FRP_3_days_ago         0.000000\n FRP_4_days_ago        45.287445\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 187, dtype: float64\nrow values:  LAT                    24.500000\n LON                 -107.199997\n FRP                    0.000000\n FWI                   11.939697\n VPD                 -999.000000\n HT                    43.400002\n T                    302.764282\n RH                    95.300003\n U                      0.012205\n V                      0.062196\n P                 100539.703125\n RAIN                   0.000109\n CAPE                 267.250000\n ST                   300.814514\n SM                     0.181750\n FRP_1_days_ago         0.000000\n FRP_2_days_ago        12.998542\n FRP_3_days_ago         0.000000\n FRP_4_days_ago         0.000000\n FRP_5_days_ago         0.000000\n FRP_6_days_ago         0.000000\n FRP_7_days_ago         0.000000\nName: 188, dtype: float64\nrow values:  LAT                   24.500000\n LON                -107.099998\n FRP                   0.000000\n FWI                   2.782227\n VPD                -999.000000\n HT                   43.400002\n T                   300.014282\n RH                   95.500000\n U                    -0.000295\n V                    -0.295304\n P                 98322.500000\n RAIN                  0.000134\n CAPE                296.250000\n ST                  298.239502\n SM                    0.295500\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 189, dtype: float64\nrow values:  LAT                   24.500000\n LON                -107.000000\n FRP                   0.000000\n FWI                   2.782227\n VPD                -999.000000\n HT                   43.400002\n T                   300.014282\n RH                   95.500000\n U                    -0.000295\n V                    -0.295304\n P                 98322.500000\n RAIN                  0.000134\n CAPE                296.250000\n ST                  298.239502\n SM                    0.295500\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 190, dtype: float64\nrow values:  LAT                   24.500000\n LON                -106.900002\n FRP                   0.000000\n FWI                   2.782227\n VPD                -999.000000\n HT                   81.500000\n T                   300.014282\n RH                   95.500000\n U                    -0.000295\n V                    -0.295304\n P                 98322.500000\n RAIN                  0.000134\n CAPE                296.250000\n ST                  298.239502\n SM                    0.295500\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 191, dtype: float64\nrow values:  LAT                   24.500000\n LON                -106.799995\n FRP                   0.000000\n FWI                   2.782227\n VPD                -999.000000\n HT                   81.500000\n T                   300.439270\n RH                   95.875000\n U                    -0.147795\n V                    -0.462804\n P                 96268.500000\n RAIN                  0.000119\n CAPE                154.000000\n ST                  298.239502\n SM                    0.318750\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 192, dtype: float64\nrow values:  LAT                   24.500000\n LON                -106.699997\n FRP                   0.000000\n FWI                   2.782227\n VPD                -999.000000\n HT                  157.500000\n T                   300.439270\n RH                   95.875000\n U                    -0.147795\n V                    -0.462804\n P                 96268.500000\n RAIN                  0.000119\n CAPE                154.000000\n ST                  298.239502\n SM                    0.318750\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 193, dtype: float64\nrow values:  LAT                   24.500000\n LON                -106.599998\n FRP                   0.000000\n FWI                   0.465820\n VPD                -999.000000\n HT                  157.500000\n T                   297.189270\n RH                   95.875000\n U                    -0.035295\n V                    -0.247804\n P                 92087.296875\n RAIN                  0.000012\n CAPE                 58.750000\n ST                  295.714478\n SM                    0.342250\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 194, dtype: float64\nrow values:  LAT                   24.500000\n LON                -106.500000\n FRP                   0.000000\n FWI                   0.465820\n VPD                -999.000000\n HT                  157.500000\n T                   297.189270\n RH                   95.875000\n U                    -0.035295\n V                    -0.247804\n P                 92087.296875\n RAIN                  0.000012\n CAPE                 58.750000\n ST                  295.714478\n SM                    0.342250\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 195, dtype: float64\nrow values:  LAT                   24.500000\n LON                -106.400002\n FRP                   0.000000\n FWI                   0.465820\n VPD                -999.000000\n HT                  286.100006\n T                   297.189270\n RH                   95.875000\n U                    -0.035295\n V                    -0.247804\n P                 92087.296875\n RAIN                  0.000012\n CAPE                 58.750000\n ST                  295.714478\n SM                    0.342250\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 196, dtype: float64\nrow values:  LAT                   24.500000\n LON                -106.299995\n FRP                   0.000000\n FWI                   0.175293\n VPD                -999.000000\n HT                  286.100006\n T                   292.889282\n RH                   93.599998\n U                    -0.922795\n V                    -0.062804\n P                 84898.898438\n RAIN                  0.000047\n CAPE                 82.750000\n ST                  291.339508\n SM                    0.334000\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 197, dtype: float64\nrow values:  LAT                   24.500000\n LON                -106.199997\n FRP                   0.000000\n FWI                   0.175293\n VPD                -999.000000\n HT                  326.100006\n T                   292.889282\n RH                   93.599998\n U                    -0.922795\n V                    -0.062804\n P                 84898.898438\n RAIN                  0.000047\n CAPE                 82.750000\n ST                  291.339508\n SM                    0.334000\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 198, dtype: float64\nrow values:  LAT                   24.500000\n LON                -106.099998\n FRP                   0.000000\n FWI                   0.085938\n VPD                -999.000000\n HT                  326.100006\n T                   288.689270\n RH                   95.575005\n U                    -1.062795\n V                    -0.205304\n P                 79510.500000\n RAIN                  0.000071\n CAPE                 72.000000\n ST                  287.989502\n SM                    0.333250\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 199, dtype: float64\nrow values:  LAT                   24.500000\n LON                -106.000000\n FRP                   0.000000\n FWI                   0.085938\n VPD                -999.000000\n HT                  326.100006\n T                   288.689270\n RH                   95.575005\n U                    -1.062795\n V                    -0.205304\n P                 79510.500000\n RAIN                  0.000071\n CAPE                 72.000000\n ST                  287.989502\n SM                    0.333250\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 200, dtype: float64\nrow values:  LAT                   24.500000\n LON                -105.900002\n FRP                   0.000000\n FWI                   0.085938\n VPD                -999.000000\n HT                 1177.400024\n T                   288.689270\n RH                   95.575005\n U                    -1.062795\n V                    -0.205304\n P                 79510.500000\n RAIN                  0.000071\n CAPE                 72.000000\n ST                  287.989502\n SM                    0.333250\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 201, dtype: float64\nrow values:  LAT                   24.500000\n LON                -105.799995\n FRP                   0.000000\n FWI                   0.054688\n VPD                -999.000000\n HT                 1177.400024\n T                   288.164276\n RH                   95.300003\n U                    -0.942795\n V                    -0.380304\n P                 77070.500000\n RAIN                  0.000086\n CAPE                 72.750000\n ST                  286.339508\n SM                    0.309250\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 202, dtype: float64\nrow values:  LAT                   24.500000\n LON                -105.699997\n FRP                   0.000000\n FWI                   0.054688\n VPD                -999.000000\n HT                 1905.900024\n T                   288.164276\n RH                   95.300003\n U                    -0.942795\n V                    -0.380304\n P                 77070.500000\n RAIN                  0.000086\n CAPE                 72.750000\n ST                  286.339508\n SM                    0.309250\n FRP_1_days_ago        0.000000\n FRP_2_days_ago        0.000000\n FRP_3_days_ago        0.000000\n FRP_4_days_ago        0.000000\n FRP_5_days_ago        0.000000\n FRP_6_days_ago        0.000000\n FRP_7_days_ago        0.000000\nName: 203, dtype: float64\nrow values:  LAT                   24.500000\n LON                -105.599998\n FRP                   0.000000\n FWI                   0.030273\n VPD                -999.000000\n HT                 1905.900024\n T                   287.589264\n RH                   95.825005\n U                    -1.215295\n V                    -0.605304\n\nStream closed",
  "history_begin_time" : 1705881681930,
  "history_end_time" : 1705881690136,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "GKqnYZgyQGO0",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    # print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    #print(\"current index: \", row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str))\n    print(\"row values: \", row)\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    # print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    print(\"partition_df.head = \", partition_df.head())\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        #grid_to_window_mapper_df['Combined_Location'] = grid_to_window_mapper_df['LAT'].astype(str) + '_' + grid_to_window_mapper_df[' LON'].astype(str)\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        #grid_to_window_mapper_df.set_index('Combined_Location', inplace=True)\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"original_df index: \", original_df.index)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        print(\"grid_to_window_mapper_df index: \", grid_to_window_mapper_df.index)\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=5)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        #new_df = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df).compute()\n        new_df = ddf.apply(add_window_grid_cells, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df, axis=1)\n\n        # Convert back to Pandas DataFrame\n        new_df = new_df.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago'],\n      dtype='object')\noriginal_df index:  RangeIndex(start=0, stop=156861, step=1)\ngrid_to_window_mapper_df columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ngrid_to_window_mapper_df index:  MultiIndex([(24.5,      -126.0),\n            (24.5, -125.899994),\n            (24.5, -125.800003),\n            (24.5, -125.699997),\n            (24.5, -125.599998),\n            (24.5,      -125.5),\n            (24.5, -125.399994),\n            (24.5, -125.300003),\n            (24.5, -125.199997),\n            (24.5, -125.099998),\n            ...\n            (50.5,  -66.900002),\n            (50.5,  -66.799995),\n            (50.5,  -66.699997),\n            (50.5,  -66.599998),\n            (50.5,       -66.5),\n            (50.5,  -66.400002),\n            (50.5,  -66.299995),\n            (50.5,  -66.199997),\n            (50.5,  -66.099998),\n            (50.5,       -66.0)],\n           names=['LAT', ' LON'], length=156861)\nrow values:  LAT                1.0\n LON               1.0\n FRP               1.0\n FWI               1.0\n VPD               1.0\n HT                1.0\n T                 1.0\n RH                1.0\n U                 1.0\n V                 1.0\n P                 1.0\n RAIN              1.0\n CAPE              1.0\n ST                1.0\n SM                1.0\n FRP_1_days_ago    1.0\n FRP_2_days_ago    1.0\n FRP_3_days_ago    1.0\n FRP_4_days_ago    1.0\n FRP_5_days_ago    1.0\n FRP_6_days_ago    1.0\n FRP_7_days_ago    1.0\nName: 0, dtype: float64\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1533, in pandas._libs.hashtable.Float64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1542, in pandas._libs.hashtable.Float64HashTable.get_item\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/utils.py\", line 893, in __call__\n    return getattr(obj, self.method)(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 95, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 213, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 187, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 158, in get_one_day_time_series_for_2_weeks_testing_data\n    new_df = ddf.apply(add_window_grid_cells, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df, axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 4335, in apply\n    meta = _emulate(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError(1.0)\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/utils.py\", line 893, in __call__\n    return getattr(obj, self.method)(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 95, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705881386364,
  "history_end_time" : 1705881389840,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "bsaXal6yIrQ7",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    # print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    #print(\"current index: \", row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str))\n    print(\"row values: \", row)\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    # print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    print(\"partition_df.head = \", partition_df.head())\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        #grid_to_window_mapper_df['Combined_Location'] = grid_to_window_mapper_df['LAT'].astype(str) + '_' + grid_to_window_mapper_df[' LON'].astype(str)\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        #grid_to_window_mapper_df.set_index('Combined_Location', inplace=True)\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"original_df index: \", original_df.index)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        print(\"grid_to_window_mapper_df index: \", grid_to_window_mapper_df.index)\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=5)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        #new_df = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df).compute()\n        new_df = ddf.map(add_window_grid_cells, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df, axis=1)\n\n        # Convert back to Pandas DataFrame\n        new_df = new_df.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago'],\n      dtype='object')\noriginal_df index:  RangeIndex(start=0, stop=156861, step=1)\ngrid_to_window_mapper_df columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ngrid_to_window_mapper_df index:  MultiIndex([(24.5,      -126.0),\n            (24.5, -125.899994),\n            (24.5, -125.800003),\n            (24.5, -125.699997),\n            (24.5, -125.599998),\n            (24.5,      -125.5),\n            (24.5, -125.399994),\n            (24.5, -125.300003),\n            (24.5, -125.199997),\n            (24.5, -125.099998),\n            ...\n            (50.5,  -66.900002),\n            (50.5,  -66.799995),\n            (50.5,  -66.699997),\n            (50.5,  -66.599998),\n            (50.5,       -66.5),\n            (50.5,  -66.400002),\n            (50.5,  -66.299995),\n            (50.5,  -66.199997),\n            (50.5,  -66.099998),\n            (50.5,       -66.0)],\n           names=['LAT', ' LON'], length=156861)\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 213, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 187, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 158, in get_one_day_time_series_for_2_weeks_testing_data\n    new_df = ddf.map(add_window_grid_cells, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df, axis=1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 3621, in __getattr__\n    raise AttributeError(\"'DataFrame' object has no attribute %r\" % key)\nAttributeError: 'DataFrame' object has no attribute 'map'\n",
  "history_begin_time" : 1705881372469,
  "history_end_time" : 1705881376102,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "pXBgFJSdnjFW",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    # print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    #print(\"current index: \", row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str))\n    print(\"row values: \", row)\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    # print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    print(\"partition_df.head = \", partition_df.head())\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        #grid_to_window_mapper_df['Combined_Location'] = grid_to_window_mapper_df['LAT'].astype(str) + '_' + grid_to_window_mapper_df[' LON'].astype(str)\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        #grid_to_window_mapper_df.set_index('Combined_Location', inplace=True)\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"original_df index: \", original_df.index)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        print(\"grid_to_window_mapper_df index: \", grid_to_window_mapper_df.index)\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        #new_df = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df).compute()\n        new_df = ddf.apply(add_window_grid_cells, axis=1, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        # new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago'],\n      dtype='object')\noriginal_df index:  RangeIndex(start=0, stop=156861, step=1)\ngrid_to_window_mapper_df columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ngrid_to_window_mapper_df index:  MultiIndex([(24.5,      -126.0),\n            (24.5, -125.899994),\n            (24.5, -125.800003),\n            (24.5, -125.699997),\n            (24.5, -125.599998),\n            (24.5,      -125.5),\n            (24.5, -125.399994),\n            (24.5, -125.300003),\n            (24.5, -125.199997),\n            (24.5, -125.099998),\n            ...\n            (50.5,  -66.900002),\n            (50.5,  -66.799995),\n            (50.5,  -66.699997),\n            (50.5,  -66.599998),\n            (50.5,       -66.5),\n            (50.5,  -66.400002),\n            (50.5,  -66.299995),\n            (50.5,  -66.199997),\n            (50.5,  -66.099998),\n            (50.5,       -66.0)],\n           names=['LAT', ' LON'], length=156861)\nrow values:  LAT                1.0\n LON               1.0\n FRP               1.0\n FWI               1.0\n VPD               1.0\n HT                1.0\n T                 1.0\n RH                1.0\n U                 1.0\n V                 1.0\n P                 1.0\n RAIN              1.0\n CAPE              1.0\n ST                1.0\n SM                1.0\n FRP_1_days_ago    1.0\n FRP_2_days_ago    1.0\n FRP_3_days_ago    1.0\n FRP_4_days_ago    1.0\n FRP_5_days_ago    1.0\n FRP_6_days_ago    1.0\n FRP_7_days_ago    1.0\nName: 0, dtype: float64\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1533, in pandas._libs.hashtable.Float64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1542, in pandas._libs.hashtable.Float64HashTable.get_item\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/utils.py\", line 893, in __call__\n    return getattr(obj, self.method)(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 95, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 213, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 187, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 158, in get_one_day_time_series_for_2_weeks_testing_data\n    new_df = ddf.apply(add_window_grid_cells, axis=1, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 4335, in apply\n    meta = _emulate(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError(1.0)\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/utils.py\", line 893, in __call__\n    return getattr(obj, self.method)(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 95, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705881042638,
  "history_end_time" : 1705881045920,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "aLCfkRiYBLKp",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    # print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    #print(\"current index: \", row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str))\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    # print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    print(\"partition_df.head = \", partition_df.head())\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        #grid_to_window_mapper_df['Combined_Location'] = grid_to_window_mapper_df['LAT'].astype(str) + '_' + grid_to_window_mapper_df[' LON'].astype(str)\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        #grid_to_window_mapper_df.set_index('Combined_Location', inplace=True)\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"original_df index: \", original_df.index)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        print(\"grid_to_window_mapper_df index: \", grid_to_window_mapper_df.index)\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        #new_df = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df).compute()\n        new_df = ddf.apply(add_window_grid_cells, axis=1, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        # new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago'],\n      dtype='object')\noriginal_df index:  RangeIndex(start=0, stop=156861, step=1)\ngrid_to_window_mapper_df columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ngrid_to_window_mapper_df index:  MultiIndex([(24.5,      -126.0),\n            (24.5, -125.899994),\n            (24.5, -125.800003),\n            (24.5, -125.699997),\n            (24.5, -125.599998),\n            (24.5,      -125.5),\n            (24.5, -125.399994),\n            (24.5, -125.300003),\n            (24.5, -125.199997),\n            (24.5, -125.099998),\n            ...\n            (50.5,  -66.900002),\n            (50.5,  -66.799995),\n            (50.5,  -66.699997),\n            (50.5,  -66.599998),\n            (50.5,       -66.5),\n            (50.5,  -66.400002),\n            (50.5,  -66.299995),\n            (50.5,  -66.199997),\n            (50.5,  -66.099998),\n            (50.5,       -66.0)],\n           names=['LAT', ' LON'], length=156861)\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1533, in pandas._libs.hashtable.Float64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1542, in pandas._libs.hashtable.Float64HashTable.get_item\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/utils.py\", line 893, in __call__\n    return getattr(obj, self.method)(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 94, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 212, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 186, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 157, in get_one_day_time_series_for_2_weeks_testing_data\n    new_df = ddf.apply(add_window_grid_cells, axis=1, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 4335, in apply\n    meta = _emulate(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError(1.0)\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/utils.py\", line 893, in __call__\n    return getattr(obj, self.method)(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 94, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705880996378,
  "history_end_time" : 1705880999953,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "8c7R9KnTeVLN",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    # print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    #print(\"current index: \", row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str))\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    # print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    print(\"partition_df.head = \", partition_df.head())\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        #grid_to_window_mapper_df['Combined_Location'] = grid_to_window_mapper_df['LAT'].astype(str) + '_' + grid_to_window_mapper_df[' LON'].astype(str)\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        #grid_to_window_mapper_df.set_index('Combined_Location', inplace=True)\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"original_df index: \", original_df.index)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        print(\"grid_to_window_mapper_df index: \", grid_to_window_mapper_df.index)\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        #new_df = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df).compute()\n        new_df = ddf.apply(add_window_grid_cells, axis=1, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df).compute()\n\n        # Convert back to Pandas DataFrame\n        # new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago'],\n      dtype='object')\noriginal_df index:  RangeIndex(start=0, stop=156861, step=1)\ngrid_to_window_mapper_df columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ngrid_to_window_mapper_df index:  MultiIndex([(24.5,      -126.0),\n            (24.5, -125.899994),\n            (24.5, -125.800003),\n            (24.5, -125.699997),\n            (24.5, -125.599998),\n            (24.5,      -125.5),\n            (24.5, -125.399994),\n            (24.5, -125.300003),\n            (24.5, -125.199997),\n            (24.5, -125.099998),\n            ...\n            (50.5,  -66.900002),\n            (50.5,  -66.799995),\n            (50.5,  -66.699997),\n            (50.5,  -66.599998),\n            (50.5,       -66.5),\n            (50.5,  -66.400002),\n            (50.5,  -66.299995),\n            (50.5,  -66.199997),\n            (50.5,  -66.099998),\n            (50.5,       -66.0)],\n           names=['LAT', ' LON'], length=156861)\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1533, in pandas._libs.hashtable.Float64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1542, in pandas._libs.hashtable.Float64HashTable.get_item\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/utils.py\", line 893, in __call__\n    return getattr(obj, self.method)(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 94, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 212, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 186, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 157, in get_one_day_time_series_for_2_weeks_testing_data\n    new_df = ddf.apply(add_window_grid_cells, axis=1, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df).compute()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 4335, in apply\n    meta = _emulate(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError(1.0)\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/utils.py\", line 893, in __call__\n    return getattr(obj, self.method)(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 94, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705880912926,
  "history_end_time" : 1705880916419,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "8ZcirRBOh0nF",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    # print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    print(\"current index: \", row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str))\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    # print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    print(\"partition_df.head = \", partition_df.head())\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df['Combined_Location'] = grid_to_window_mapper_df['LAT'].astype(str) + '_' + grid_to_window_mapper_df[' LON'].astype(str)\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df.set_index('Combined_Location', inplace=True)\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"original_df index: \", original_df.index)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        print(\"grid_to_window_mapper_df index: \", grid_to_window_mapper_df.index)\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago'],\n      dtype='object')\noriginal_df index:  RangeIndex(start=0, stop=156861, step=1)\ngrid_to_window_mapper_df columns:  Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ngrid_to_window_mapper_df index:  Index(['24.5_-126.0', '24.5_-125.899994', '24.5_-125.800003',\n       '24.5_-125.699997', '24.5_-125.599998', '24.5_-125.5',\n       '24.5_-125.399994', '24.5_-125.300003', '24.5_-125.199997',\n       '24.5_-125.099998',\n       ...\n       '50.5_-66.900002', '50.5_-66.799995', '50.5_-66.699997',\n       '50.5_-66.599998', '50.5_-66.5', '50.5_-66.400002', '50.5_-66.299995',\n       '50.5_-66.199997', '50.5_-66.099998', '50.5_-66.0'],\n      dtype='object', name='Combined_Location', length=156861)\npartition_df.head =     LAT   LON   FRP  ...   FRP_5_days_ago   FRP_6_days_ago   FRP_7_days_ago\n0  1.0   1.0   1.0  ...              1.0              1.0              1.0\n1  1.0   1.0   1.0  ...              1.0              1.0              1.0\n[2 rows x 22 columns]\ncurrent index:  1.0_1.0\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: '1.0_1.0'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 107, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 94, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 967, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3876, in xs\n    loc = index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: '1.0_1.0'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 211, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 185, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 156, in get_one_day_time_series_for_2_weeks_testing_data\n    ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 643, in map_partitions\n    return map_partitions(func, self, *args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5215, in map_partitions\n    meta = _emulate(func, *args, udf=True, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply_dask_partition`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError('1.0_1.0')\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 107, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 94, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 967, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3876, in xs\n    loc = index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705875338535,
  "history_end_time" : 1705875343934,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "bnwiq90iFv4o",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    # print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    print(\"current index: \", row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str))\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    # print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df['Combined_Location'] = grid_to_window_mapper_df['LAT'].astype(str) + '_' + grid_to_window_mapper_df[' LON'].astype(str)\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df.set_index('Combined_Location', inplace=True)\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"original_df index: \", original_df.index)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        print(\"grid_to_window_mapper_df index: \", grid_to_window_mapper_df.index)\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago'],\n      dtype='object')\noriginal_df index:  RangeIndex(start=0, stop=156861, step=1)\ngrid_to_window_mapper_df columns:  Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ngrid_to_window_mapper_df index:  Index(['24.5_-126.0', '24.5_-125.899994', '24.5_-125.800003',\n       '24.5_-125.699997', '24.5_-125.599998', '24.5_-125.5',\n       '24.5_-125.399994', '24.5_-125.300003', '24.5_-125.199997',\n       '24.5_-125.099998',\n       ...\n       '50.5_-66.900002', '50.5_-66.799995', '50.5_-66.699997',\n       '50.5_-66.599998', '50.5_-66.5', '50.5_-66.400002', '50.5_-66.299995',\n       '50.5_-66.199997', '50.5_-66.099998', '50.5_-66.0'],\n      dtype='object', name='Combined_Location', length=156861)\ncurrent index:  1.0_1.0\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: '1.0_1.0'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 106, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 94, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 967, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3876, in xs\n    loc = index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: '1.0_1.0'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 210, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 184, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 155, in get_one_day_time_series_for_2_weeks_testing_data\n    ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 643, in map_partitions\n    return map_partitions(func, self, *args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5215, in map_partitions\n    meta = _emulate(func, *args, udf=True, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply_dask_partition`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError('1.0_1.0')\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 106, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 94, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 967, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3876, in xs\n    loc = index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705875011842,
  "history_end_time" : 1705875016727,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "sbK4MkgCFKNo",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    print(\"current index: \", row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str))\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    # print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df['Combined_Location'] = grid_to_window_mapper_df['LAT'].astype(str) + '_' + grid_to_window_mapper_df[' LON'].astype(str)\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df.set_index('Combined_Location', inplace=True)\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"original_df index: \", original_df.index)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        print(\"grid_to_window_mapper_df index: \", grid_to_window_mapper_df.index)\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago'],\n      dtype='object')\noriginal_df index:  RangeIndex(start=0, stop=156861, step=1)\ngrid_to_window_mapper_df columns:  Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ngrid_to_window_mapper_df index:  Index(['24.5_-126.0', '24.5_-125.899994', '24.5_-125.800003',\n       '24.5_-125.699997', '24.5_-125.599998', '24.5_-125.5',\n       '24.5_-125.399994', '24.5_-125.300003', '24.5_-125.199997',\n       '24.5_-125.099998',\n       ...\n       '50.5_-66.900002', '50.5_-66.799995', '50.5_-66.699997',\n       '50.5_-66.599998', '50.5_-66.5', '50.5_-66.400002', '50.5_-66.299995',\n       '50.5_-66.199997', '50.5_-66.099998', '50.5_-66.0'],\n      dtype='object', name='Combined_Location', length=156861)\nadd_window_grid_cells grid_to_window_mapper_df.columns =  Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ncurrent index:  1.0_1.0\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: '1.0_1.0'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 106, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 94, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 967, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3876, in xs\n    loc = index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: '1.0_1.0'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 210, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 184, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 155, in get_one_day_time_series_for_2_weeks_testing_data\n    ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 643, in map_partitions\n    return map_partitions(func, self, *args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5215, in map_partitions\n    meta = _emulate(func, *args, udf=True, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply_dask_partition`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError('1.0_1.0')\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 106, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 94, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 967, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3876, in xs\n    loc = index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705874944748,
  "history_end_time" : 1705874948577,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "g2doAEEJ8t6H",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    # print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df['Combined_Location'] = grid_to_window_mapper_df['LAT'].astype(str) + '_' + grid_to_window_mapper_df[' LON'].astype(str)\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df.set_index('Combined_Location', inplace=True)\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"original_df index: \", original_df.index)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        print(\"grid_to_window_mapper_df index: \", grid_to_window_mapper_df.index)\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago'],\n      dtype='object')\noriginal_df index:  RangeIndex(start=0, stop=156861, step=1)\ngrid_to_window_mapper_df columns:  Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ngrid_to_window_mapper_df index:  Index(['24.5_-126.0', '24.5_-125.899994', '24.5_-125.800003',\n       '24.5_-125.699997', '24.5_-125.599998', '24.5_-125.5',\n       '24.5_-125.399994', '24.5_-125.300003', '24.5_-125.199997',\n       '24.5_-125.099998',\n       ...\n       '50.5_-66.900002', '50.5_-66.799995', '50.5_-66.699997',\n       '50.5_-66.599998', '50.5_-66.5', '50.5_-66.400002', '50.5_-66.299995',\n       '50.5_-66.199997', '50.5_-66.099998', '50.5_-66.0'],\n      dtype='object', name='Combined_Location', length=156861)\nadd_window_grid_cells grid_to_window_mapper_df.columns =  Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: '1.0_1.0'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 105, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 93, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 967, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3876, in xs\n    loc = index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: '1.0_1.0'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 209, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 183, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 154, in get_one_day_time_series_for_2_weeks_testing_data\n    ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 643, in map_partitions\n    return map_partitions(func, self, *args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5215, in map_partitions\n    meta = _emulate(func, *args, udf=True, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply_dask_partition`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError('1.0_1.0')\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 105, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 93, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 967, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3876, in xs\n    loc = index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705874898300,
  "history_end_time" : 1705874901939,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "k3vpA3UK916k",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'].astype(str) + \"_\" + row[' LON'].astype(str)]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    # print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df['Combined_Location'] = grid_to_window_mapper_df['LAT'].astype(str) + '_' + grid_to_window_mapper_df['LON'].astype(str)\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df.set_index('Combined_Location', inplace=True)\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"original_df index: \", original_df.index)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        print(\"grid_to_window_mapper_df index: \", grid_to_window_mapper_df.index)\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'LON'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 209, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 183, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 141, in get_one_day_time_series_for_2_weeks_testing_data\n    grid_to_window_mapper_df['Combined_Location'] = grid_to_window_mapper_df['LAT'].astype(str) + '_' + grid_to_window_mapper_df['LON'].astype(str)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3505, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 'LON'\n",
  "history_begin_time" : 1705874883012,
  "history_end_time" : 1705874887125,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "LDJ60wj90YWZ",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    # print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"original_df index: \", original_df.index)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        print(\"grid_to_window_mapper_df index: \", grid_to_window_mapper_df.index)\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago'],\n      dtype='object')\noriginal_df index:  RangeIndex(start=0, stop=156861, step=1)\ngrid_to_window_mapper_df columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\ngrid_to_window_mapper_df index:  MultiIndex([(24.5,      -126.0),\n            (24.5, -125.899994),\n            (24.5, -125.800003),\n            (24.5, -125.699997),\n            (24.5, -125.599998),\n            (24.5,      -125.5),\n            (24.5, -125.399994),\n            (24.5, -125.300003),\n            (24.5, -125.199997),\n            (24.5, -125.099998),\n            ...\n            (50.5,  -66.900002),\n            (50.5,  -66.799995),\n            (50.5,  -66.699997),\n            (50.5,  -66.599998),\n            (50.5,       -66.5),\n            (50.5,  -66.400002),\n            (50.5,  -66.299995),\n            (50.5,  -66.199997),\n            (50.5,  -66.099998),\n            (50.5,       -66.0)],\n           names=['LAT', ' LON'], length=156861)\nadd_window_grid_cells grid_to_window_mapper_df.columns =  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1533, in pandas._libs.hashtable.Float64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1542, in pandas._libs.hashtable.Float64HashTable.get_item\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 105, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 93, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 207, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 181, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 152, in get_one_day_time_series_for_2_weeks_testing_data\n    ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 643, in map_partitions\n    return map_partitions(func, self, *args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5215, in map_partitions\n    meta = _emulate(func, *args, udf=True, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply_dask_partition`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError(1.0)\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 105, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 93, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705874151954,
  "history_end_time" : 1705874155597,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "GZoky6MkBCeC",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        print(\"original_df columns: \", original_df.columns)\n        print(\"grid_to_window_mapper_df columns: \", grid_to_window_mapper_df.columns)\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  Index(['LAT', ' LON', ' FRP', ' FWI', ' VPD', ' HT', ' T', ' RH', ' U', ' V',\n       ' P', ' RAIN', ' CAPE', ' ST', ' SM', ' FRP_1_days_ago',\n       ' FRP_2_days_ago', ' FRP_3_days_ago', ' FRP_4_days_ago',\n       ' FRP_5_days_ago', ' FRP_6_days_ago', ' FRP_7_days_ago'],\n      dtype='object')\ngrid_to_window_mapper_df columns:  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\napply_dask_partition grid_to_window_mapper_df.columns =  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\nadd_window_grid_cells grid_to_window_mapper_df.columns =  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1533, in pandas._libs.hashtable.Float64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1542, in pandas._libs.hashtable.Float64HashTable.get_item\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 105, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 93, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 205, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 179, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 150, in get_one_day_time_series_for_2_weeks_testing_data\n    ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 643, in map_partitions\n    return map_partitions(func, self, *args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5215, in map_partitions\n    meta = _emulate(func, *args, udf=True, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply_dask_partition`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError(1.0)\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 105, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 93, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705874032538,
  "history_end_time" : 1705874036127,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "3hgkhON48zqA",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        print(\"original_df columns: \", len(original_df.columns))\n        print(\"grid_to_window_mapper_df columns: \", len(grid_to_window_mapper_df.columns))\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\noriginal_df columns:  22\ngrid_to_window_mapper_df columns:  24\napply_dask_partition grid_to_window_mapper_df.columns =  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\nadd_window_grid_cells grid_to_window_mapper_df.columns =  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1533, in pandas._libs.hashtable.Float64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1542, in pandas._libs.hashtable.Float64HashTable.get_item\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 105, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 93, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 205, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 179, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 150, in get_one_day_time_series_for_2_weeks_testing_data\n    ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 643, in map_partitions\n    return map_partitions(func, self, *args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5215, in map_partitions\n    meta = _emulate(func, *args, udf=True, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply_dask_partition`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError(1.0)\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 105, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 93, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705873966032,
  "history_end_time" : 1705873969630,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "CilsfV04uYZ9",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    print(\"add_window_grid_cells grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        \n        print(\"nearest_columns length: \", len(grid_to_window_mapper_df.columns))\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\nnearest_columns length:  26\napply_dask_partition grid_to_window_mapper_df.columns =  Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\nadd_window_grid_cells grid_to_window_mapper_df.columns =  Index(['Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4', 'Nearest_5',\n       'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9', 'Nearest_10',\n       'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14', 'Nearest_15',\n       'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19', 'Nearest_20',\n       'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1533, in pandas._libs.hashtable.Float64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1542, in pandas._libs.hashtable.Float64HashTable.get_item\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 106, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 93, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 205, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 179, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 150, in get_one_day_time_series_for_2_weeks_testing_data\n    ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 643, in map_partitions\n    return map_partitions(func, self, *args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5215, in map_partitions\n    meta = _emulate(func, *args, udf=True, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply_dask_partition`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError(1.0)\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 106, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 93, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3869, in xs\n    loc, new_index = index._get_loc_level(key, level=0)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3115, in _get_loc_level\n    indexer = self._get_level_indexer(key, level=level)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 3224, in _get_level_indexer\n    idx = self._get_loc_single_level_index(level_index, key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\", line 2804, in _get_loc_single_level_index\n    return level_index.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705873850401,
  "history_end_time" : 1705873854016,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "9lJ3LljDK8Jw",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    print(\"apply_dask_partition grid_to_window_mapper_df.columns = \", grid_to_window_mapper_df.columns)\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        \n        print(\"nearest_columns length: \", len(grid_to_window_mapper_df.columns))\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\nnearest_columns length:  26\napply_dask_partition grid_to_window_mapper_df.columns =  Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\napply_dask_partition grid_to_window_mapper_df.columns =  Index(['LAT', ' LON', 'Nearest_1', 'Nearest_2', 'Nearest_3', 'Nearest_4',\n       'Nearest_5', 'Nearest_6', 'Nearest_7', 'Nearest_8', 'Nearest_9',\n       'Nearest_10', 'Nearest_11', 'Nearest_12', 'Nearest_13', 'Nearest_14',\n       'Nearest_15', 'Nearest_16', 'Nearest_17', 'Nearest_18', 'Nearest_19',\n       'Nearest_20', 'Nearest_21', 'Nearest_22', 'Nearest_23', 'Nearest_24'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 1\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 105, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 93, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 960, in __getitem__\n    return self.obj._get_value(*key, takeable=self._takeable)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3615, in _get_value\n    series = self._get_item_cache(col)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3931, in _get_item_cache\n    loc = self.columns.get_loc(item)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 204, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 178, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 149, in get_one_day_time_series_for_2_weeks_testing_data\n    ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 643, in map_partitions\n    return map_partitions(func, self, *args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5215, in map_partitions\n    meta = _emulate(func, *args, udf=True, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply_dask_partition`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError(1.0)\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 105, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 93, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 960, in __getitem__\n    return self.obj._get_value(*key, takeable=self._takeable)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3615, in _get_value\n    series = self._get_item_cache(col)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3931, in _get_item_cache\n    loc = self.columns.get_loc(item)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705873721972,
  "history_end_time" : 1705873725355,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "fkSVEciUqfe3",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        \n        print(\"nearest_columns length: \", len(grid_to_window_mapper_df.columns))\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\nnearest_columns length:  26\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 1\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 103, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 92, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 960, in __getitem__\n    return self.obj._get_value(*key, takeable=self._takeable)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3615, in _get_value\n    series = self._get_item_cache(col)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3931, in _get_item_cache\n    loc = self.columns.get_loc(item)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 202, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 176, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 147, in get_one_day_time_series_for_2_weeks_testing_data\n    ddf = ddf.map_partitions(apply_dask_partition, original_df = original_df, grid_to_window_mapper_df = grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 643, in map_partitions\n    return map_partitions(func, self, *args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5215, in map_partitions\n    meta = _emulate(func, *args, udf=True, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply_dask_partition`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError(1.0)\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 103, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 92, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 960, in __getitem__\n    return self.obj._get_value(*key, takeable=self._takeable)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3615, in _get_value\n    series = self._get_item_cache(col)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3931, in _get_item_cache\n    loc = self.columns.get_loc(item)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705873676510,
  "history_end_time" : 1705873680089,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "NIkJURL3WFtU",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        \n        print(\"nearest_columns length: \", len(grid_to_window_mapper_df.columns))\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)\n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df, grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\nnearest_columns length:  26\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 1\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 103, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 92, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 960, in __getitem__\n    return self.obj._get_value(*key, takeable=self._takeable)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3615, in _get_value\n    series = self._get_item_cache(col)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3931, in _get_item_cache\n    loc = self.columns.get_loc(item)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 1.0\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 202, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 176, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 147, in get_one_day_time_series_for_2_weeks_testing_data\n    ddf = ddf.map_partitions(apply_dask_partition, original_df, grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 643, in map_partitions\n    return map_partitions(func, self, *args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5215, in map_partitions\n    meta = _emulate(func, *args, udf=True, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/home/zsun/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n    raise ValueError(msg) from e\nValueError: Metadata inference failed in `apply_dask_partition`.\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\nOriginal error is below:\n------------------------\nKeyError(1.0)\nTraceback:\n---------\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 174, in raise_on_meta_error\n    yield\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5165, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"fc_test_data_preparation.py\", line 103, in apply_dask_partition\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 92, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 960, in __getitem__\n    return self.obj._get_value(*key, takeable=self._takeable)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3615, in _get_value\n    series = self._get_item_cache(col)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3931, in _get_item_cache\n    loc = self.columns.get_loc(item)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\n",
  "history_begin_time" : 1705873508862,
  "history_end_time" : 1705873512450,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "9pcIYhTKfngI",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    \n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\ndef apply_dask_partition(partition_df, original_df, grid_to_window_mapper_df):\n    return partition_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        \n        print(\"nearest_columns length: \", len(grid_to_window_mapper_df.columns))\n        # new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        ddf = dd.from_pandas(original_df, npartitions=10)  \n        # Adjust the number of partitions as needed\n        # Use the map function\n        ddf = ddf.map_partitions(apply_dask_partition, original_df, grid_to_window_mapper_df)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\nnearest_columns length:  24\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 202, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 176, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 147, in get_one_day_time_series_for_2_weeks_testing_data\n    ddf = ddf.map_partitions(apply_dask_partition, original_df, grid_to_window_mapper_df)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 643, in map_partitions\n    return map_partitions(func, self, *args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5207, in map_partitions\n    args = _maybe_from_pandas(args)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 4880, in _maybe_from_pandas\n    dfs = [\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 4881, in <listcomp>\n    from_pandas(df, 1)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/io/io.py\", line 195, in from_pandas\n    raise NotImplementedError(\"Dask does not support MultiIndex Dataframes.\")\nNotImplementedError: Dask does not support MultiIndex Dataframes.\n",
  "history_begin_time" : 1705873279139,
  "history_end_time" : 1705873282791,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "Zitb0xKRpKO5",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df):\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        \n        print(\"nearest_columns length: \", len(grid_to_window_mapper_df.columns))\n        new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        #ddf = dd.from_pandas(original_df, npartitions=10)  # Adjust the number of partitions as needed\n        # Use the map function\n        #ddf = ddf.map(apply_window_grid_cells, original_df=original_df, grid_to_window_mapper_df=grid_to_window_mapper_df, nearest_columns=nearest_columns)\n\n        # Convert back to Pandas DataFrame\n        #new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\nnearest_columns length:  24\n",
  "history_begin_time" : 1705872804974,
  "history_end_time" : 1705872852772,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "NmxPJwRgfz3k",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df, nearest_columns):\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        \n        print(\"nearest_columns length: \", len(grid_to_window_mapper_df.columns))\n        new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        #ddf = dd.from_pandas(original_df, npartitions=10)  # Adjust the number of partitions as needed\n        # Use the map function\n        #ddf = ddf.map(apply_window_grid_cells, original_df=original_df, grid_to_window_mapper_df=grid_to_window_mapper_df, nearest_columns=nearest_columns)\n\n        # Convert back to Pandas DataFrame\n        #new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\nnearest_columns length:  24\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 198, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 172, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 139, in get_one_day_time_series_for_2_weeks_testing_data\n    new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\nTypeError: add_window_grid_cells() missing 1 required positional argument: 'nearest_columns'\n",
  "history_begin_time" : 1705872786559,
  "history_end_time" : 1705872789832,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "7tTMZrDsT1bC",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df, nearest_columns):\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in grid_to_window_mapper_df.columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = read_original_txt_files(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = read_txt_from_predicted_folder(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = read_original_txt_files(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df[f' FRP_{i+1}_days_ago'] = column_to_append\n\n        original_df = df\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        \n        print(\"nearest_columns length: \", len(nearest_columns))\n        new_df = original_df.apply(add_window_grid_cells, axis=1, args=(original_df, grid_to_window_mapper_df))\n        # Assuming df is a Dask DataFrame\n        #ddf = dd.from_pandas(original_df, npartitions=10)  # Adjust the number of partitions as needed\n        # Use the map function\n        #ddf = ddf.map(apply_window_grid_cells, original_df=original_df, grid_to_window_mapper_df=grid_to_window_mapper_df, nearest_columns=nearest_columns)\n\n        # Convert back to Pandas DataFrame\n        #new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n  print(\"Original df is created: \", original_df.shape)\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n  print(\"Original df filled the na with -9999 \")\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txt\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txt\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txt\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 198, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 172, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 138, in get_one_day_time_series_for_2_weeks_testing_data\n    print(\"nearest_columns length: \", len(nearest_columns))\nNameError: name 'nearest_columns' is not defined\n",
  "history_begin_time" : 1705872762964,
  "history_end_time" : 1705872766465,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "N5ZKDjrcdegf",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n@delayed\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n@delayed\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df, nearest_columns):\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = pd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = delayed(read_original_txt_files)(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = delayed(read_txt_from_predicted_folder)(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = delayed(read_original_txt_files)(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df = df.assign(**{f' FRP_{i+1}_days_ago': delayed(column_to_append)})\n\n        original_df = df.compute()\n        print(\"original_df.describe\", original_df.describe())\n        \n        # Reset the index before using set_index\n        #grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        nearest_columns = grid_to_window_mapper_df.columns\n        print(\"nearest_columns length: \", len(nearest_columns))\n        new_df = original_df.apply(add_window_grid_cells, axis=1, original_df=original_df, grid_to_window_mapper_df=grid_to_window_mapper_df, nearest_columns=nearest_columns)\n        # Assuming df is a Dask DataFrame\n        #ddf = dd.from_pandas(original_df, npartitions=10)  # Adjust the number of partitions as needed\n        # Use the map function\n        #ddf = ddf.map(apply_window_grid_cells, original_df=original_df, grid_to_window_mapper_df=grid_to_window_mapper_df, nearest_columns=nearest_columns)\n\n        # Convert back to Pandas DataFrame\n        #new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txtReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txtReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txt\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txtReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\noriginal_df.describe                  LAT            LON  ...   FRP_6_days_ago   FRP_7_days_ago\ncount  156861.000000  156861.000000  ...    156861.000000    156861.000000\nmean       37.500002     -95.999998  ...         0.163110         0.227513\nstd         7.534390      17.349407  ...        18.545293        34.938262\nmin        24.500000    -126.000000  ...         0.000000         0.000000\n25%        31.000000    -111.000000  ...         0.000000         0.000000\n50%        37.500000     -96.000000  ...         0.000000         0.000000\n75%        44.000000     -81.000000  ...         0.000000         0.000000\nmax        50.500000     -66.000000  ...      5464.172363     11733.906250\n[8 rows x 22 columns]\nnearest_columns length:  24\n",
  "history_begin_time" : 1705868281177,
  "history_end_time" : 1705868300745,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "uTKRw3bo3EOh",
  "history_input" : "\n\n# Step 1: read and prepare the txt files by yunyao\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nimport dask\nfrom dask import delayed\nimport dask.dataframe as dd\n\n# Folder path containing the text files\nfolder_path = '/groups/ESS3/yli74/data/AI_Emis/firedata'  # The folder yunyao provided with two years of txt files\nmy_file_path = \"/groups/ESS3/zsun/firecasting/data/others/\"\ngrid_to_window_mapper_csv = f\"{my_file_path}/grid_cell_nearest_neight_mapper.csv\"\ntraining_data_folder = \"/groups/ESS3/zsun/firecasting/data/train/\"\n\nstart_date = \"20200107\"\nend_date = \"20211231\"\n\n@delayed\ndef read_original_txt_files(datestr):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n  df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  # firedata_20201208.txt\n  file_path = os.path.join(folder_path, f\"firedata_{datestr}.txt\")\n  print(f\"Reading {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n  df_list.append(file_df)\n  # Concatenate all chunks into a single DataFrame\n  final_df = pd.concat(df_list, ignore_index=True)\n  \n  \n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n@delayed\ndef read_txt_from_predicted_folder(target_datestr, current_prediction_output_folder):\n  # time range: 2020-01-01 to 2021-12-31\n  # Specify chunk size\n  #chunk_size = 1000\n  #row_limit = 1000\n\n  # Initialize an empty DataFrame\n#   df_list = []\n  #total_rows = 0\n\n  # Traverse through files in the folder\n  \n  # firedata_20201208.txt\n  file_path = os.path.join(current_prediction_output_folder, f\"firedata_{target_datestr}_predicted.txt\")\n  if not os.path.exists(file_path):\n    raise ValueError(f\"File {file_path} does not exist.\")\n  \n  #print(f\"Reading data from file : {file_path}\")\n  file_df = pd.read_csv(file_path)  # Adjust separator if needed\n  #for chunk in chunk_generator:\n#   df_list.append(file_df)\n  #total_rows += len(file_df)\n\n  #if total_rows >= row_limit:\n  #    break  # Stop reading files if row limit is reached\n  \n  \n  # Concatenate all chunks into a single DataFrame\n  #final_df = pd.concat(df_list, ignore_index=True)\n  final_df = file_df\n  print(\"current final_df head: \", final_df.head())\n  print(\"renaming Predicted_FRP to FRP\")\n  final_df[' FRP'] = final_df['Predicted_FRP']\n  # Remove the original column 'A'\n  print(\"remove the current predicted_frp\")\n  final_df.drop(columns=['Predicted_FRP'], inplace=True)\n\n\n  # Display the DataFrame\n  #print(final_df)\n  return final_df\n\n\ndef add_window_grid_cells(row, original_df, grid_to_window_mapper_df, nearest_columns):\n    # Implement your logic for adding window grid cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n    values = []\n    for column in nearest_columns:\n        nearest_index = result[column]\n        values.append(original_df.iloc[nearest_index][\" FRP_1_days_ago\"])\n    if len(values) != 24:\n        raise ValueError(\"The nearest values are not 24.\")\n    return pd.Series(values)\n\n\ndef get_one_day_time_series_for_2_weeks_testing_data(target_day, current_start_day, current_prediction_output_folder):\n    if current_start_day == None or current_prediction_output_folder == None:\n        print(\"just get one day time series\")\n        return get_one_day_time_series_training_data(target_day)\n    else:\n        # get grid to window mapper csv\n        grid_to_window_mapper_df = dd.read_csv(grid_to_window_mapper_csv)\n\n        target_dt = datetime.strptime(target_day, '%Y%m%d')\n        current_start_dt = datetime.strptime(current_start_day, '%Y%m%d')\n\n        print(f\"Read from original folder for current date: {target_day}\")\n        df = delayed(read_original_txt_files)(target_day)\n        \n        # go back 7 days to get all the history FRP and attach to the df with matched coordinates\n        for i in range(7):\n            past_dt = target_dt - timedelta(days=i+1)\n            print(f\"reading past files for {past_dt}\")\n            if past_dt >= current_start_dt and past_dt < target_dt:\n                print(f\"reading from predicted folder\")\n                past_df = delayed(read_txt_from_predicted_folder)(past_dt.strftime('%Y%m%d'), current_prediction_output_folder)\n            else:\n                print(f\"reading from original folder\")\n                past_df = delayed(read_original_txt_files)(past_dt.strftime('%Y%m%d'))\n            column_to_append = past_df[\" FRP\"]\n            df = df.assign(**{f' FRP_{i+1}_days_ago': delayed(column_to_append)})\n\n        original_df = df.compute()\n        \n        \n        # Reset the index before using set_index\n        grid_to_window_mapper_df = grid_to_window_mapper_df.reset_index()\n        # adding the neighbor cell values of yesterday to the inputs\n        # grid_to_window_mapper_df = grid_to_window_mapper_df.set_index(['LAT', ' LON'])\n\n        nearest_columns = grid_to_window_mapper_df.columns\n\n        print(\"nearest_columns length: \", len(nearest_columns))\n        new_df = original_df.apply(add_window_grid_cells, axis=1, original_df=original_df, grid_to_window_mapper_df=grid_to_window_mapper_df, nearest_columns=nearest_columns)\n        # Assuming df is a Dask DataFrame\n        #ddf = dd.from_pandas(original_df, npartitions=10)  # Adjust the number of partitions as needed\n        # Use the map function\n        #ddf = ddf.map(apply_window_grid_cells, original_df=original_df, grid_to_window_mapper_df=grid_to_window_mapper_df, nearest_columns=nearest_columns)\n\n        # Convert back to Pandas DataFrame\n        new_df = ddf.compute()\n        print(\"new_df.shape = \", new_df.shape)\n        print(\"df.shape = \", df.shape)\n        df[nearest_columns] = new_df\n\n        print(\"New time series dataframe: \", df.head())\n        return df\n\ndef prepare_testing_data_for_2_weeks_forecasting(target_date, current_start_day, current_prediction_output_folder):\n  \"\"\"\n  Prepare testing data for a 2-week forecasting model.\n\n  Parameters:\n    - target_date (str): The target date for forecasting.\n    - current_start_day (str): The current start day for fetching time series data.\n    - current_prediction_output_folder (str): The folder path for the prediction output.\n\n  Returns:\n    - X (pd.DataFrame): Features DataFrame for model input.\n    - y (pd.Series): Target Series for model output (prediction).\n\n  Assumes the existence of a function get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n    to fetch time series data for the given target date and start day.\n  \"\"\"\n  # Assuming 'target' is the column to predict\n  target_col = ' FRP'\n  original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  df = original_df\n\n  #print(\"Lag/Shift the data for previous days' information\")\n  num_previous_days = 7  # Adjust the number of previous days to consider\n\n  # Drop rows with NaN values from the shifted columns\n  df_filled = df.fillna(-9999)\n\n  # Define features and target\n  X = df.drop([target_col], axis=1)\n  y = df[target_col]\n  return X, y\n  \n\n\n# target column is current day's FRP, previous days' FRP and all the other columns are inputs\n\n#read_original_txt_files()\n\nif __name__ == \"__main__\":\n  #training_end_date = \"20200715\"\n  #prepare_training_data(training_end_date)\n  output_folder_full_path = f'/groups/ESS3/zsun/firecasting/data/output/test_if_predicted_frp_used/20210718/'\n  prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n",
  "history_output" : "/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\nRead from original folder for current date: 20210714\nreading past files for 2021-07-13 00:00:00\nreading from original folder\nreading past files for 2021-07-12 00:00:00\nreading from original folder\nreading past files for 2021-07-11 00:00:00\nreading from original folder\nreading past files for 2021-07-10 00:00:00\nreading from original folder\nreading past files for 2021-07-09 00:00:00\nreading from original folder\nreading past files for 2021-07-08 00:00:00\nreading from original folder\nreading past files for 2021-07-07 00:00:00\nreading from original folder\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210713.txtReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210714.txtReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210712.txt\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210711.txtReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210710.txt\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210709.txtReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210708.txt\nReading /groups/ESS3/yli74/data/AI_Emis/firedata/firedata_20210707.txt\nnearest_columns length:  27\nTraceback (most recent call last):\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: -126\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"fc_test_data_preparation.py\", line 199, in <module>\n    prepare_testing_data_for_2_weeks_forecasting(\"20210714\", \"20210714\", output_folder_full_path)\n  File \"fc_test_data_preparation.py\", line 175, in prepare_testing_data_for_2_weeks_forecasting\n    original_df = get_one_day_time_series_for_2_weeks_testing_data(target_date, current_start_day, current_prediction_output_folder)\n  File \"fc_test_data_preparation.py\", line 142, in get_one_day_time_series_for_2_weeks_testing_data\n    new_df = original_df.apply(add_window_grid_cells, axis=1, original_df=original_df, grid_to_window_mapper_df=grid_to_window_mapper_df, nearest_columns=nearest_columns)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 8833, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 727, in apply\n    return self.apply_standard()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 851, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 867, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\", line 138, in f\n    return func(x, *args, **kwargs)\n  File \"fc_test_data_preparation.py\", line 94, in add_window_grid_cells\n    result = grid_to_window_mapper_df.loc[row['LAT'], row[' LON']]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/indexing.py\", line 98, in __getitem__\n    return self._loc(iindexer, cindexer)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/indexing.py\", line 128, in _loc\n    meta = self._make_meta(iindexer, cindexer)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/dask/dataframe/indexing.py\", line 35, in _make_meta\n    return self._meta_indexer[:, cindexer]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 961, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1140, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 867, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1202, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1153, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3861, in xs\n    return self[key]\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3505, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: -126.0\n",
  "history_begin_time" : 1705867994823,
  "history_end_time" : 1705868009834,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "8qvctxvhqwo",
  "history_input" : "#  prepare testing data for the wildfire emission forecasting\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1692388306774,
  "history_end_time" : 1692388310312,
  "history_notes" : null,
  "history_process" : "521ngk",
  "host_id" : "100001",
  "indicator" : "Done"
},]
